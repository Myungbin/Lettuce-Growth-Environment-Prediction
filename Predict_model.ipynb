{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_FEPJs4wwYC"
      },
      "outputs": [],
      "source": [
        "!pip install AutoGluon\n",
        "!pip install filterpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZTIwkIthw6bl"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from filterpy.common import Q_discrete_white_noise\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.signal import butter, lfilter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf-uK_X46Kvd"
      },
      "source": [
        "# F.E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW-QWP5sxDIa"
      },
      "outputs": [],
      "source": [
        "def preprocessing(input_path):\n",
        "  all_input_list = sorted(glob.glob(input_path))\n",
        "  train = pd.DataFrame()\n",
        "  for datapath in all_input_list:\n",
        "    data = pd.read_csv(datapath) # 이게 지금 28일치 * 24시\n",
        "    data['obs_time'] = data.index % 24 # 시간통일\n",
        "    data = abs(data)\n",
        "    col_list = data.columns\n",
        "    for i in range(0,len(col_list)):\n",
        "      col = col_list[i]    \n",
        "      if '누적' in col :\n",
        "        data[col] = data.groupby((data.obs_time == 0).cumsum()).agg(col_list[i-1]).cumsum()\n",
        "    data.to_csv(datapath,index=False)\n",
        "    train = pd.concat([train,data])\n",
        "  return train\n",
        "input_path_train = '/content/drive/MyDrive/상추/original_data/train_input/*.csv'\n",
        "input_path_test = '/content/drive/MyDrive/상추/original_data/test_input/*.csv'\n",
        "\n",
        "preprocessing(input_path_train)\n",
        "preprocessing(input_path_test)\n",
        "\n",
        "train_input_list = sorted(glob.glob('/content/drive/MyDrive/상추/original_data/train_input/*.csv'))\n",
        "train_target_list = sorted(glob.glob('/content/drive/MyDrive/상추/original_data/train_target/*.csv'))\n",
        "\n",
        "test_input_list = sorted(glob.glob('/content/drive/MyDrive/상추/original_data/test_input/*.csv'))\n",
        "test_target_list = sorted(glob.glob('/content/drive/MyDrive/상추/original_data/test_target/*.csv'))\n",
        "def make_dataset(all_input_list, all_target_list):\n",
        "    df_all = pd.DataFrame()\n",
        "    length = len(all_input_list)\n",
        "    for idx in range(length):\n",
        "        X = pd.read_csv(all_input_list[idx])\n",
        "        y = pd.read_csv(all_target_list[idx])\n",
        "        y['DAT'] = y['DAT']-1\n",
        "        df_concat = pd.merge(X, y, on='DAT', how='left')\n",
        "        df_concat['Case'] = idx+1\n",
        "        df_all = pd.concat([df_all, df_concat])\n",
        "    return df_all\n",
        "\n",
        "train = make_dataset(train_input_list, train_target_list)\n",
        "test = make_dataset(test_input_list, test_target_list)\n",
        "\n",
        "train = train.sort_values(by=['Case','DAT'], axis=0).reset_index(drop=True)\n",
        "test = test.sort_values(by=['Case','DAT'], axis=0).reset_index(drop=True)\n",
        "\n",
        "def filtering(df):\n",
        "\n",
        "    f1 = df[df['co2관측치']>578]['Case'].unique().tolist()\n",
        "    f2 = df[((df['내부습도관측치']<74.4)&(df['내부습도관측치']>73.6))|((df['내부습도관측치']<30)&(df['내부습도관측치']>27))|((df['내부습도관측치']<54.5)&(df['내부습도관측치']>54.4)) ]['Case'].unique().tolist()\n",
        "    f3 = df[(df['일간누적분무량']<150)]['Case'].unique().tolist()\n",
        "    \n",
        "    d1 = df[(df['시간당분무량']>2100)]['Case'].unique().tolist()\n",
        "    d2 = df[(df['내부온도관측치']>31.124)&(df['내부온도관측치']<31.126)]['Case'].unique().tolist()\n",
        "    d3 = df[(df['co2관측치']<510.1)&(df['co2관측치']>=510)]['Case'].unique().tolist()\n",
        "    d4 = df[(df['시간당백색광량']>3094.0)&(df['시간당백색광량']<3094.2)]['Case'].unique().tolist()\n",
        "    d5 = df[(df['시간당백색광량']>13400)&(df['시간당백색광량']<13400.5472)]['Case'].unique().tolist()\n",
        "\n",
        "    return_arr = list(set(f1)&set(f2)&set(f3))\n",
        "    for i in set(d1+d2+d3+d4+d5):\n",
        "        if i in return_arr :\n",
        "            return_arr.remove(i)\n",
        "\n",
        "    return return_arr\n",
        "\n",
        "trainfilter = filtering(train)\n",
        "testfilter = filtering(test)\n",
        "\n",
        "train['내부온도관측치'][train['내부온도관측치'] == 0] = train['내부온도관측치'].mean()\n",
        "train['내부습도관측치'][train['내부습도관측치'] == 0] = train['내부습도관측치'].mean()\n",
        "train['05시내부온도관측치누적'] = 0\n",
        "train['19시내부온도관측치누적'] = 0\n",
        "train['23시내부온도관측치누적'] = 0\n",
        "train['05시내부습도관측치누적'] = 0\n",
        "train['19시내부습도관측치누적'] = 0\n",
        "train['23시내부습도관측치누적'] = 0\n",
        "train['05시co2관측치누적'] = 0\n",
        "train['19시co2관측치누적'] = 0\n",
        "train['23시co2관측치누적'] = 0\n",
        "train['05시ec관측치누적'] = 0\n",
        "train['19시ec관측치누적'] = 0\n",
        "train['23시ec관측치누적'] = 0\n",
        "train['05시분무량누적'] = 0\n",
        "train['19시분무량누적'] = 0\n",
        "train['23시분무량누적'] = 0\n",
        "train['05시백색광누적'] = 0\n",
        "train['19시백색광누적'] = 0\n",
        "train['23시백색광누적'] = 0\n",
        "train['05시적색광누적'] = 0\n",
        "train['19시적색광누적'] = 0\n",
        "train['23시적색광누적'] = 0\n",
        "train['05시청색광누적'] = 0\n",
        "train['19시청색광누적'] = 0\n",
        "train['23시청색광누적'] = 0\n",
        "train['05시총광량누적'] = 0\n",
        "train['19시총광량누적'] = 0\n",
        "train['23시총광량누적'] = 0\n",
        "test['05시내부온도관측치누적'] = 0\n",
        "test['19시내부온도관측치누적'] = 0\n",
        "test['23시내부온도관측치누적'] = 0\n",
        "test['05시내부습도관측치누적'] = 0\n",
        "test['19시내부습도관측치누적'] = 0\n",
        "test['23시내부습도관측치누적'] = 0\n",
        "test['05시co2관측치누적'] = 0\n",
        "test['19시co2관측치누적'] = 0\n",
        "test['23시co2관측치누적'] = 0\n",
        "test['05시ec관측치누적'] = 0\n",
        "test['19시ec관측치누적'] = 0\n",
        "test['23시ec관측치누적'] = 0\n",
        "test['05시분무량누적'] = 0\n",
        "test['19시분무량누적'] = 0\n",
        "test['23시분무량누적'] = 0\n",
        "test['05시백색광누적'] = 0\n",
        "test['19시백색광누적'] = 0\n",
        "test['23시백색광누적'] = 0\n",
        "test['05시적색광누적'] = 0\n",
        "test['19시적색광누적'] = 0\n",
        "test['23시적색광누적'] = 0\n",
        "test['05시청색광누적'] = 0\n",
        "test['19시청색광누적'] = 0\n",
        "test['23시청색광누적'] = 0\n",
        "test['05시총광량누적'] = 0\n",
        "test['19시총광량누적'] = 0\n",
        "test['23시총광량누적'] = 0\n",
        "\n",
        "train = train.drop(train.filter(regex='일간누적').columns, axis=1)\n",
        "test = test.drop(test.filter(regex='일간누적').columns, axis=1)\n",
        "\n",
        "train_new = train\n",
        "test_new = test\n",
        "\n",
        "train['시간대'] = 0\n",
        "train['시간대'][(train['obs_time'] >= 0) & (train['obs_time'] <= 5)] = 1\n",
        "train['시간대'][(train['obs_time'] > 5) & (train['obs_time'] < 20)] = 2\n",
        "train['시간대'][(train['obs_time'] >= 20) & (train['obs_time'] <= 23)] = 3\n",
        "test['시간대'] = 0\n",
        "test['시간대'][(test['obs_time'] >= 0) & (test['obs_time'] <= 5)] = 1\n",
        "test['시간대'][(test['obs_time'] > 5) & (test['obs_time'] < 20)] = 2\n",
        "test['시간대'][(test['obs_time'] >= 20) & (test['obs_time'] <= 23)] = 3\n",
        "\n",
        "train['hypothesis1'] = 0\n",
        "for i in range(22,len(train),24):\n",
        "  s = train.iloc[i,6] + train.iloc[i+1,6] * ((train.iloc[i, 3] + train.iloc[i+1,3]) / 2)\n",
        "  train.iloc[i, 41] = s\n",
        "test['hypothesis1'] = 0\n",
        "for i in range(22,len(test),24):\n",
        "  s = test.iloc[i,6] + test.iloc[i+1,6] * ((test.iloc[i, 3] + test.iloc[i+1,3]) / 2)\n",
        "  test.iloc[i, 41] = s\n",
        "train['hypothesis2'] = 0\n",
        "for i in range(22,len(train),24):\n",
        "  s = train.iloc[i+1,6] * (train.iloc[i+1,3])\n",
        "  train.iloc[i, 42] = s\n",
        "test['hypothesis2'] = 0\n",
        "for i in range(22,len(test),24):\n",
        "  s = test.iloc[i+1,6] * (test.iloc[i+1,3])\n",
        "  test.iloc[i, 42] = s\n",
        "train['hypothesis3'] = 0\n",
        "for i in range(22,len(train),24):\n",
        "  s = (train.iloc[i,6] + train.iloc[i+1,6]) * ((train.iloc[i, 3] + train.iloc[i+1,3]) / 2)\n",
        "  train.iloc[i, 43] = s\n",
        "test['hypothesis3'] = 0\n",
        "for i in range(22,len(test),24):\n",
        "  s = (test.iloc[i,6] + test.iloc[i+1,6]) * ((test.iloc[i, 3] + test.iloc[i+1,3]) / 2)\n",
        "  test.iloc[i, 43] = s\n",
        "\n",
        "case_list = train['Case'].unique()\n",
        "for c in case_list : \n",
        "    if c in trainfilter :\n",
        "        continue\n",
        "    train.loc[(train['Case'] == c ), 'hypothesis1'] = 0\n",
        "    train.loc[(train['Case'] == c ), 'hypothesis2'] = 0\n",
        "    train.loc[(train['Case'] == c ), 'hypothesis3'] = 0\n",
        "case_list = test['Case'].unique()\n",
        "for c in case_list : \n",
        "    if c in testfilter :\n",
        "        continue\n",
        "    test.loc[(test['Case'] == c ), 'hypothesis1'] = 0\n",
        "    test.loc[(test['Case'] == c ), 'hypothesis2'] = 0\n",
        "    test.loc[(test['Case'] == c ), 'hypothesis3'] = 0\n",
        "\n",
        "train_x = train.drop(['predicted_weight_g'], axis = 1)\n",
        "train_y = train['predicted_weight_g']\n",
        "test_x = test.drop(['predicted_weight_g'], axis=1)\n",
        "train_x = train_x.groupby(['DAT','Case','시간대']).sum().reset_index()\n",
        "train_y_ready = train.groupby(['DAT','Case','시간대']).mean().reset_index()\n",
        "test_x = test_x.groupby(['DAT','Case','시간대']).sum().reset_index()\n",
        "train_x = train_x.sort_values(by=['Case','DAT','시간대'], axis=0).reset_index()\n",
        "train_y_ready = train_y_ready.sort_values(by=['Case','DAT','시간대'], axis=0).reset_index()\n",
        "test_x = test_x.sort_values(by=['Case','DAT','시간대'], axis=0).reset_index()\n",
        "train_x.drop(['index'], axis = 1, inplace=True)\n",
        "test_x.drop(['index'], axis = 1, inplace=True)\n",
        "x = train_x.groupby(['Case'])['내부온도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['내부온도관측치'] = x\n",
        "x2 = train_x.groupby(['Case'])['내부습도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x2.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['내부습도관측치'] = x2\n",
        "x3 = train_x.groupby(['Case'])['co2관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x3.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['co2관측치'] = x3\n",
        "x4 = train_x.groupby(['Case'])['ec관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x4.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['ec관측치'] = x4\n",
        "x5 = train_x.groupby(['Case'])['시간당분무량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x5.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['시간당분무량'] = x5\n",
        "x6 = train_x.groupby(['Case'])['시간당백색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x6.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['시간당백색광량'] = x6\n",
        "x7 = train_x.groupby(['Case'])['시간당적색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x7.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['시간당적색광량'] = x7\n",
        "x8 = train_x.groupby(['Case'])['시간당청색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x8.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['시간당청색광량'] = x8\n",
        "x9 = train_x.groupby(['Case'])['시간당총광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "x9.drop(['level_1'], axis = 1, inplace = True)\n",
        "train_x['시간당총광량'] = x9\n",
        "t = test_x.groupby(['Case'])['내부온도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['내부온도관측치'] = t\n",
        "t2 = test_x.groupby(['Case'])['내부습도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t2.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['내부습도관측치'] = t2\n",
        "t3 = test_x.groupby(['Case'])['co2관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t3.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['co2관측치'] = t3\n",
        "t4 = test_x.groupby(['Case'])['ec관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t4.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['ec관측치'] = t4\n",
        "t5 = test_x.groupby(['Case'])['시간당분무량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t5.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['시간당분무량'] = t5\n",
        "t6 = test_x.groupby(['Case'])['시간당백색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t6.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['시간당백색광량'] = t6\n",
        "t7 = test_x.groupby(['Case'])['시간당적색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t7.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['시간당적색광량'] = t7\n",
        "t8 = test_x.groupby(['Case'])['시간당청색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t8.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['시간당청색광량'] = t8\n",
        "t9 = test_x.groupby(['Case'])['시간당총광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "t9.drop(['level_1'], axis = 1, inplace = True)\n",
        "test_x['시간당총광량'] = t9\n",
        "train_new_x = train_new.drop(['predicted_weight_g'], axis = 1)\n",
        "train_new_y = train_new['predicted_weight_g']\n",
        "test_new_x = test_new.drop(['predicted_weight_g'], axis=1)\n",
        "train_new_x = train_new_x.groupby(['DAT','Case']).sum().reset_index()\n",
        "train_new_y_ready = train_new.groupby(['DAT','Case']).mean().reset_index()\n",
        "test_new_x = test_new_x.groupby(['DAT','Case']).sum().reset_index()\n",
        "train_new_x = train_new_x.sort_values(by=['Case','DAT'], axis=0).reset_index()\n",
        "train_new_y_ready = train_new_y_ready.sort_values(by=['Case','DAT',], axis=0).reset_index()\n",
        "test_new_x = test_new_x.sort_values(by=['Case','DAT'], axis=0).reset_index()\n",
        "train_new_x.drop(['index'], axis = 1, inplace=True)\n",
        "test_new_x.drop(['index'], axis = 1, inplace=True)\n",
        "for i in range(len(train_new_x)):\n",
        "  train_new_x.iloc[i,12] = train_x.iloc[0 + (3*i),4]\n",
        "  train_new_x.iloc[i,13] = train_x.iloc[1 + (3*i),4]\n",
        "  train_new_x.iloc[i,14] = train_x.iloc[2 + (3*i),4]\n",
        "  train_new_x.iloc[i,15] = train_x.iloc[0 + (3*i),5]\n",
        "  train_new_x.iloc[i,16] = train_x.iloc[1 + (3*i),5]\n",
        "  train_new_x.iloc[i,17] = train_x.iloc[2 + (3*i),5]\n",
        "  train_new_x.iloc[i,18] = train_x.iloc[0 + (3*i),6]\n",
        "  train_new_x.iloc[i,19] = train_x.iloc[1 + (3*i),6]\n",
        "  train_new_x.iloc[i,20] = train_x.iloc[2 + (3*i),6]\n",
        "  train_new_x.iloc[i,21] = train_x.iloc[0 + (3*i),7]\n",
        "  train_new_x.iloc[i,22] = train_x.iloc[1 + (3*i),7]\n",
        "  train_new_x.iloc[i,23] = train_x.iloc[2 + (3*i),7]\n",
        "  train_new_x.iloc[i,24] = train_x.iloc[0 + (3*i),8]\n",
        "  train_new_x.iloc[i,25] = train_x.iloc[1 + (3*i),8]\n",
        "  train_new_x.iloc[i,26] = train_x.iloc[2 + (3*i),8]\n",
        "  train_new_x.iloc[i,27] = train_x.iloc[0 + (3*i),9]\n",
        "  train_new_x.iloc[i,28] = train_x.iloc[1 + (3*i),9]\n",
        "  train_new_x.iloc[i,29] = train_x.iloc[2 + (3*i),9]\n",
        "  train_new_x.iloc[i,30] = train_x.iloc[0 + (3*i),10]\n",
        "  train_new_x.iloc[i,31] = train_x.iloc[1 + (3*i),10]\n",
        "  train_new_x.iloc[i,32] = train_x.iloc[2 + (3*i),10]\n",
        "  train_new_x.iloc[i,33] = train_x.iloc[0 + (3*i),11]\n",
        "  train_new_x.iloc[i,34] = train_x.iloc[1 + (3*i),11]\n",
        "  train_new_x.iloc[i,35] = train_x.iloc[2 + (3*i),11]\n",
        "  train_new_x.iloc[i,36] = train_x.iloc[0 + (3*i),12]\n",
        "  train_new_x.iloc[i,37] = train_x.iloc[1 + (3*i),12]\n",
        "  train_new_x.iloc[i,38] = train_x.iloc[2 + (3*i),12]\n",
        "for i in range(len(test_new_x)):\n",
        "  test_new_x.iloc[i,12] = test_x.iloc[0 + (3*i),4]\n",
        "  test_new_x.iloc[i,13] = test_x.iloc[1 + (3*i),4]\n",
        "  test_new_x.iloc[i,14] = test_x.iloc[2 + (3*i),4]\n",
        "  test_new_x.iloc[i,15] = test_x.iloc[0 + (3*i),5]\n",
        "  test_new_x.iloc[i,16] = test_x.iloc[1 + (3*i),5]\n",
        "  test_new_x.iloc[i,17] = test_x.iloc[2 + (3*i),5]\n",
        "  test_new_x.iloc[i,18] = test_x.iloc[0 + (3*i),6]\n",
        "  test_new_x.iloc[i,19] = test_x.iloc[1 + (3*i),6]\n",
        "  test_new_x.iloc[i,20] = test_x.iloc[2 + (3*i),6]\n",
        "  test_new_x.iloc[i,21] = test_x.iloc[0 + (3*i),7]\n",
        "  test_new_x.iloc[i,22] = test_x.iloc[1 + (3*i),7]\n",
        "  test_new_x.iloc[i,23] = test_x.iloc[2 + (3*i),7]\n",
        "  test_new_x.iloc[i,24] = test_x.iloc[0 + (3*i),8]\n",
        "  test_new_x.iloc[i,25] = test_x.iloc[1 + (3*i),8]\n",
        "  test_new_x.iloc[i,26] = test_x.iloc[2 + (3*i),8]\n",
        "  test_new_x.iloc[i,27] = test_x.iloc[0 + (3*i),9]\n",
        "  test_new_x.iloc[i,28] = test_x.iloc[1 + (3*i),9]\n",
        "  test_new_x.iloc[i,29] = test_x.iloc[2 + (3*i),9]\n",
        "  test_new_x.iloc[i,30] = test_x.iloc[0 + (3*i),10]\n",
        "  test_new_x.iloc[i,31] = test_x.iloc[1 + (3*i),10]\n",
        "  test_new_x.iloc[i,32] = test_x.iloc[2 + (3*i),10]\n",
        "  test_new_x.iloc[i,33] = test_x.iloc[0 + (3*i),11]\n",
        "  test_new_x.iloc[i,34] = test_x.iloc[1 + (3*i),11]\n",
        "  test_new_x.iloc[i,35] = test_x.iloc[2 + (3*i),11]\n",
        "  test_new_x.iloc[i,36] = test_x.iloc[0 + (3*i),12]\n",
        "  test_new_x.iloc[i,37] = test_x.iloc[1 + (3*i),12]\n",
        "  test_new_x.iloc[i,38] = test_x.iloc[2 + (3*i),12]\n",
        "train_new_y = train_new_y_ready['predicted_weight_g']\n",
        "train_new_x.drop(['obs_time','시간대','내부온도관측치','내부습도관측치','co2관측치','ec관측치'], axis = 1, inplace = True)\n",
        "test_new_x.drop(['obs_time','시간대','내부온도관측치','내부습도관측치','co2관측치','ec관측치'], axis = 1, inplace = True)\n",
        "train_x = train_new_x\n",
        "train_y = train_new_y\n",
        "test_x = test_new_x\n",
        "train_x = train_x.drop(train_x.filter(regex='시간당').columns, axis=1)\n",
        "test_x = test_x.drop(test_x.filter(regex='시간당').columns, axis=1)\n",
        "\n",
        "train_x['하루평균온도'] = (train_x['05시내부온도관측치누적'] + train_x['19시내부온도관측치누적'] + train_x['23시내부온도관측치누적']) / 3\n",
        "train_x['하루평균습도'] = (train_x['05시내부습도관측치누적'] + train_x['19시내부습도관측치누적'] + train_x['23시내부습도관측치누적']) / 3\n",
        "train_x['하루평균co2'] = (train_x['05시co2관측치누적'] + train_x['19시co2관측치누적'] + train_x['23시co2관측치누적']) / 3\n",
        "train_x['하루평균ec'] = (train_x['05시ec관측치누적'] + train_x['19시ec관측치누적'] + train_x['23시ec관측치누적']) / 3\n",
        "train_x['하루평균분무량'] = (train_x['05시분무량누적'] + train_x['19시분무량누적'] + train_x['23시분무량누적']) / 3\n",
        "train_x['하루평균백색광'] = (train_x['05시백색광누적'] + train_x['19시백색광누적'] + train_x['23시백색광누적']) / 3\n",
        "train_x['하루평균적색광'] = (train_x['05시적색광누적'] + train_x['19시적색광누적'] + train_x['23시적색광누적']) / 3\n",
        "train_x['하루평균청색광'] = (train_x['05시청색광누적'] + train_x['19시청색광누적'] + train_x['23시청색광누적']) / 3\n",
        "train_x['하루평균총광량'] = (train_x['05시총광량누적'] + train_x['19시총광량누적'] + train_x['23시총광량누적']) / 3\n",
        "test_x['하루평균온도'] = (test_x['05시내부온도관측치누적'] + test_x['19시내부온도관측치누적'] + test_x['23시내부온도관측치누적']) / 3\n",
        "test_x['하루평균습도'] = (test_x['05시내부습도관측치누적'] + test_x['19시내부습도관측치누적'] + test_x['23시내부습도관측치누적']) / 3\n",
        "test_x['하루평균co2'] = (test_x['05시co2관측치누적'] + test_x['19시co2관측치누적'] + test_x['23시co2관측치누적']) / 3\n",
        "test_x['하루평균ec'] = (test_x['05시ec관측치누적'] + test_x['19시ec관측치누적'] + test_x['23시ec관측치누적']) / 3\n",
        "test_x['하루평균분무량'] = (test_x['05시분무량누적'] + test_x['19시분무량누적'] + test_x['23시분무량누적']) / 3\n",
        "test_x['하루평균백색광'] = (test_x['05시백색광누적'] + test_x['19시백색광누적'] + test_x['23시백색광누적']) / 3\n",
        "test_x['하루평균적색광'] = (test_x['05시적색광누적'] + test_x['19시적색광누적'] + test_x['23시적색광누적']) / 3\n",
        "test_x['하루평균청색광'] = (test_x['05시청색광누적'] + test_x['19시청색광누적'] + test_x['23시청색광누적']) / 3\n",
        "test_x['하루평균총광량'] = (test_x['05시총광량누적'] + test_x['19시총광량누적'] + test_x['23시총광량누적']) / 3\n",
        "train_x = train_x.drop(train_x.filter(regex = '총광').columns, axis =1)\n",
        "test_x = test_x.drop(test_x.filter(regex = '총광').columns, axis =1)\n",
        "train_x['hypothesis4'] = (train_x['05시ec관측치누적']+1) * (train_x['05시분무량누적']+1)\n",
        "train_x['hypothesis5'] = (train_x['19시ec관측치누적']+1) * (train_x['19시분무량누적']+1)\n",
        "train_x['hypothesis6'] = (train_x['23시ec관측치누적']+1) * (train_x['23시분무량누적']+1)\n",
        "train_x['hypothesis7'] = (train_x['하루평균ec']+1) * (train_x['하루평균분무량']+1)\n",
        "test_x['hypothesis4'] = (test_x['05시ec관측치누적']+1) * (test_x['05시분무량누적']+1)\n",
        "test_x['hypothesis5'] = (test_x['19시ec관측치누적']+1) * (test_x['19시분무량누적']+1)\n",
        "test_x['hypothesis6'] = (test_x['23시ec관측치누적']+1) * (test_x['23시분무량누적']+1)\n",
        "test_x['hypothesis7'] = (test_x['하루평균ec']+1) * (test_x['하루평균분무량']+1)\n",
        "train_x['적색_+_청색05'] = (train_x['05시적색광누적']) + (train_x['05시청색광누적'])\n",
        "train_x['적색_+_청색19'] = (train_x['19시적색광누적']) + (train_x['19시청색광누적'])\n",
        "train_x['적색_+_청색23'] = (train_x['23시적색광누적']) + (train_x['23시청색광누적'])\n",
        "train_x['적색_+_청색평균'] = (train_x['하루평균적색광']) + (train_x['하루평균청색광'])\n",
        "test_x['적색_+_청색05'] = (test_x['05시적색광누적']) + (test_x['05시청색광누적'])\n",
        "test_x['적색_+_청색19'] = (test_x['19시적색광누적']) + (test_x['19시청색광누적'])\n",
        "test_x['적색_+_청색23'] = (test_x['23시적색광누적']) + (test_x['23시청색광누적'])\n",
        "test_x['적색_+_청색평균'] = (test_x['하루평균적색광']) + (test_x['하루평균청색광'])\n",
        "train_x['hypothesis123'] =  train_x['hypothesis1'] + train_x['hypothesis2'] + train_x['hypothesis3']\n",
        "test_x['hypothesis123'] =  test_x['hypothesis1'] + test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "train_x['hypothesis12'] =  train_x['hypothesis2'] + train_x['hypothesis1']\n",
        "test_x['hypothesis12'] =  test_x['hypothesis2'] + test_x['hypothesis1']\n",
        "train_x['hypothesis23'] =  train_x['hypothesis2'] + train_x['hypothesis3']\n",
        "test_x['hypothesis23'] =  test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "train_x['hypothesis13'] = train_x['hypothesis1'] + train_x['hypothesis3']\n",
        "test_x['hypothesis13'] =  test_x['hypothesis1'] + test_x['hypothesis3']\n",
        "train_x.drop(train_x.filter(regex = '백색'), axis = 1, inplace=True)\n",
        "test_x.drop(test_x.filter(regex = '백색'), axis = 1, inplace=True)\n",
        "train_x.drop(train_x.filter(regex = '청색'), axis = 1, inplace=True)\n",
        "test_x.drop(test_x.filter(regex = '청색'), axis = 1, inplace=True)\n",
        "train_x.drop(['hypothesis1','hypothesis2','hypothesis3'],axis=1,inplace=True)\n",
        "test_x.drop(['hypothesis1','hypothesis2','hypothesis3'],axis=1,inplace=True)\n",
        "basic_col = train_x.columns\n",
        "kal_train = train_x\n",
        "for i in range(2,34):\n",
        "  train_x['kf_X_'+str(i)]=0\n",
        "case_list = train_x['Case'].unique()\n",
        "for j in case_list:\n",
        "  kal = train_x[train_x['Case'] == j]\n",
        "  for i in (range(len(basic_col))):\n",
        "      if((i == 0) | (i == 1)):\n",
        "        continue\n",
        "      current=0\n",
        "      sum_c=[]\n",
        "      z = kal.loc[:, kal.columns[i]]\n",
        "      a = []        \n",
        "      b = []     \n",
        "      my_filter = KalmanFilter(dim_x=2,dim_z=1) \n",
        "      my_filter.x = np.array([[2.],[0.]])       \n",
        "      my_filter.F = np.array([[1.,1.], [0.,1.]])   \n",
        "      my_filter.H = np.array([[1.,0.]])\n",
        "      my_filter.P *= 1000.                \n",
        "      my_filter.R = 5                     \n",
        "      my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.5) \n",
        "      for k in z.values:\n",
        "          my_filter.predict()\n",
        "          my_filter.update(k)\n",
        "          x = my_filter.x\n",
        "          a.extend(x[0])\n",
        "          b.append(k)\n",
        "      sum_c=sum_c+a\n",
        "      train_x['kf_X_'+str(i)][train_x['Case'] == j] = sum_c\n",
        "\n",
        "basic_col = test_x.columns\n",
        "kal_test = test_x\n",
        "for i in range(2,34):\n",
        "  test_x['kf_X_'+str(i)]=0\n",
        "case_list = test_x['Case'].unique()\n",
        "for j in case_list:\n",
        "  kal = test_x[test_x['Case'] == j]\n",
        "  for i in (range(len(basic_col))):\n",
        "      if((i == 0) | (i == 1)):\n",
        "        continue\n",
        "      current=0\n",
        "      sum_c=[]\n",
        "      z = kal.loc[:, kal.columns[i]]\n",
        "      a = []           \n",
        "      b = []           \n",
        "      my_filter = KalmanFilter(dim_x=2,dim_z=1) \n",
        "      my_filter.x = np.array([[2.],[0.]])      \n",
        "      my_filter.F = np.array([[1.,1.], [0.,1.]])   \n",
        "      my_filter.H = np.array([[1.,0.]])  \n",
        "      my_filter.P *= 1000.              \n",
        "      my_filter.R = 5                   \n",
        "      my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.5)\n",
        "      for k in z.values:\n",
        "          my_filter.predict()\n",
        "          my_filter.update(k)\n",
        "          x = my_filter.x\n",
        "          a.extend(x[0])\n",
        "          b.append(k)\n",
        "      sum_c=sum_c+a\n",
        "      test_x['kf_X_'+str(i)][test_x['Case'] == j] = sum_c\n",
        "\n",
        "copy_train_x = train_x.copy()\n",
        "copy_test_x = test_x.copy()\n",
        "copy_train_x.drop(copy_train_x.filter(regex = 'kf').columns, axis = 1, inplace = True)\n",
        "copy_test_x.drop(copy_test_x.filter(regex = 'kf').columns, axis = 1, inplace = True)\n",
        "raw_cols_tr = copy_train_x.columns\n",
        "raw_cols_te = copy_test_x.columns\n",
        "new_train_x = pd.DataFrame()\n",
        "\n",
        "case_list = copy_train_x['Case'].unique()\n",
        "for i in case_list:\n",
        "  target = copy_train_x[copy_train_x['Case'] == i]\n",
        "  mean_arr = []\n",
        "  median_arr = []\n",
        "  pbar = (target.columns[:])\n",
        "  for column in pbar:\n",
        "      column_list = target[column].to_list()\n",
        "      for i in range(7):\n",
        "        if((i) == (len(column_list))):\n",
        "            break\n",
        "        mean_arr.append(column_list[i])\n",
        "        median_arr.append(column_list[i])\n",
        "      for i in range(7, len(column_list)):\n",
        "          mean_arr.append(float(np.mean(column_list[i-7:i])))\n",
        "          median_arr.append(float(np.median(column_list[i-7:i])))\n",
        "      target[f'{column}_mean_7'] = mean_arr\n",
        "      target[f'{column}_median_7'] = median_arr\n",
        "      mean_arr = []\n",
        "      median_arr = []\n",
        "  new_train_x = pd.concat([new_train_x, target], axis=0)\n",
        "train_x_moving_7 = new_train_x.drop(raw_cols_tr, axis=1)\n",
        "\n",
        "new_test_x = pd.DataFrame()\n",
        "case_list = copy_test_x['Case'].unique()\n",
        "for i in case_list:\n",
        "  target = copy_test_x[copy_test_x['Case'] == i]\n",
        "  mean_arr = []\n",
        "  median_arr = []\n",
        "  pbar = (target.columns[:])\n",
        "  for column in pbar:\n",
        "      column_list = target[column].to_list()\n",
        "      for i in range(7):\n",
        "        if((i) == (len(column_list))):\n",
        "            break\n",
        "        mean_arr.append(column_list[i])\n",
        "        median_arr.append(column_list[i])\n",
        "      for i in range(7, len(column_list)):\n",
        "          mean_arr.append(float(np.mean(column_list[i-7:i])))\n",
        "          median_arr.append(float(np.median(column_list[i-7:i])))\n",
        "      target[f'{column}_mean_7'] = mean_arr\n",
        "      target[f'{column}_median_7'] = median_arr\n",
        "      mean_arr = []\n",
        "      median_arr = []\n",
        "  new_test_x = pd.concat([new_test_x, target], axis=0)\n",
        "test_x_moving_7 = new_test_x.drop(raw_cols_te, axis=1)\n",
        "train_x = pd.concat([train_x, train_x_moving_7], axis=1)\n",
        "test_x = pd.concat([test_x, test_x_moving_7], axis=1)\n",
        "\n",
        "raw_cols_tr = copy_train_x.columns\n",
        "raw_cols_te = copy_test_x.columns\n",
        "new_train_x = pd.DataFrame()\n",
        "case_list = copy_train_x['Case'].unique()\n",
        "for i in case_list:\n",
        "  target = copy_train_x[copy_train_x['Case'] == i]\n",
        "  mean_arr = []\n",
        "  median_arr = []\n",
        "  pbar = (target.columns[:])\n",
        "  for column in pbar:\n",
        "      column_list = target[column].to_list()\n",
        "      for i in range(14):\n",
        "        if((i) == (len(column_list))):\n",
        "            break\n",
        "        mean_arr.append(column_list[i])\n",
        "        median_arr.append(column_list[i])\n",
        "      for i in range(14, len(column_list)):\n",
        "          mean_arr.append(float(np.mean(column_list[i-14:i])))\n",
        "          median_arr.append(float(np.median(column_list[i-14:i])))\n",
        "      target[f'{column}_mean_14'] = mean_arr\n",
        "      target[f'{column}_median_14'] = median_arr\n",
        "      mean_arr = []\n",
        "      median_arr = []\n",
        "  new_train_x = pd.concat([new_train_x, target], axis=0)\n",
        "train_x_moving_14 = new_train_x.drop(raw_cols_tr, axis=1)\n",
        "new_test_x = pd.DataFrame()\n",
        "case_list = copy_test_x['Case'].unique()\n",
        "for i in case_list:\n",
        "  target = copy_test_x[copy_test_x['Case'] == i]\n",
        "  mean_arr = []\n",
        "  median_arr = []\n",
        "  pbar = (target.columns[:])\n",
        "  for column in pbar:\n",
        "      column_list = target[column].to_list()\n",
        "      for i in range(14):\n",
        "        if((i) == (len(column_list))):\n",
        "            break\n",
        "        mean_arr.append(column_list[i])\n",
        "        median_arr.append(column_list[i])\n",
        "      for i in range(14, len(column_list)):\n",
        "          mean_arr.append(float(np.mean(column_list[i-14:i])))\n",
        "          median_arr.append(float(np.median(column_list[i-14:i])))\n",
        "      target[f'{column}_mean_14'] = mean_arr\n",
        "      target[f'{column}_median_14'] = median_arr\n",
        "      mean_arr = []\n",
        "      median_arr = []\n",
        "  new_test_x = pd.concat([new_test_x, target], axis=0)\n",
        "test_x_moving_14 = new_test_x.drop(raw_cols_te, axis=1)\n",
        "train_x = pd.concat([train_x, train_x_moving_14], axis=1)\n",
        "test_x = pd.concat([test_x, test_x_moving_14], axis=1)\n",
        "train_x_fil = train_x.iloc[:,1:34]\n",
        "test_x_fil = test_x.iloc[:,1:34]\n",
        "def LPF(series, low, order=1):\n",
        "    b, a = butter(\n",
        "                  N = order,\n",
        "                  Wn = low,\n",
        "                  btype = 'low',\n",
        "                  )\n",
        "    lpf_series = lfilter(b, a, series)\n",
        "    return lpf_series\n",
        "new_train_x = pd.DataFrame()\n",
        "case_list = train_x_fil['Case'].unique()\n",
        "for i in case_list:\n",
        "  target = train_x_fil[train_x_fil['Case'] == i]\n",
        "  train_merge = LPF(target,0.1,1)\n",
        "  train_merge = pd.DataFrame(train_merge)\n",
        "  new_train_x = pd.concat([new_train_x, train_merge], axis=0)\n",
        "new_train_x = new_train_x.add_suffix('_LPF')\n",
        "new_train_x = new_train_x.reset_index(drop = True)\n",
        "train_x = pd.concat([train_x,new_train_x], axis = 1)\n",
        "new_test_x = pd.DataFrame()\n",
        "case_list = test_x_fil['Case'].unique()\n",
        "for i in case_list:\n",
        "  target = test_x_fil[test_x_fil['Case'] == i]\n",
        "  test_merge = LPF(target,0.1,1)\n",
        "  test_merge = pd.DataFrame(test_merge)\n",
        "  new_test_x = pd.concat([new_test_x, test_merge], axis=0)\n",
        "new_test_x = new_test_x.add_suffix('_LPF')\n",
        "new_test_x = new_test_x.reset_index(drop = True)\n",
        "test_x = pd.concat([test_x,new_test_x], axis = 1)\n",
        "\n",
        "\n",
        "train_x.drop(['0_LPF'],axis = 1, inplace=True)\n",
        "test_x.drop(['0_LPF'],axis = 1, inplace=True)\n",
        "\n",
        "train_x.drop(train_x.filter(regex = 'Case'),axis=1, inplace=True)\n",
        "test_x.drop(test_x.filter(regex = 'Case'),axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBIOiFjW6HGD"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L8mP3Wi0AcE"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([train_x,train_y], axis = 1)\n",
        "train_data = TabularDataset(train)\n",
        "test_data = TabularDataset(test_x)\n",
        "\n",
        "predictor = TabularPredictor(label='predicted_weight_g',  eval_metric='root_mean_squared_error',path='/content/drive/MyDrive/상추/models').fit(train_data, presets='high_quality',  ag_args_fit={'num_gpus': 0})\n",
        "y_pred = predictor.predict(test_data)\n",
        "\n",
        "y_pred = pd.DataFrame(y_pred, columns=['predicted_weight_g'])\n",
        "\n",
        "test_target_path = '/content/drive/MyDrive/상추/test_target/*.csv'\n",
        "all_target_list = sorted(glob.glob(test_target_path))\n",
        "i=0\n",
        "for test_path in all_target_list:\n",
        "    submit_df = pd.read_csv(test_path)\n",
        "    submit_df['predicted_weight_g'] = y_pred[i*28:i*28+28].values\n",
        "    submit_df.to_csv(test_path, index=False)\n",
        "    i+=1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
