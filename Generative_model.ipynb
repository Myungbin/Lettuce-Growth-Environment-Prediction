{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c7YIQhDoWoU"
      },
      "source": [
        "# install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-29Sw_LJoSQL",
        "outputId": "87510365-3674-4fea-b9ed-d4567499a260"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "ixJ9Wl64suDW",
        "outputId": "29453295-2c02-4e2e-ba6d-bee18c00cdd2"
      },
      "outputs": [],
      "source": [
        "!pip install ctgan==0.6.0\n",
        "!pip install filterpy\n",
        "!pip install Autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q__PiDX6w_5j",
        "outputId": "3879693a-3d65-4369-efcf-3d3fd3db5ef3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.6.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import ctgan\n",
        "ctgan.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M5omgh3FrIsp"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import joblib\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import glob\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from filterpy.common import Q_discrete_white_noise\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTDVgNPeodoL"
      },
      "source": [
        "# def"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dffqBS21ofvT"
      },
      "outputs": [],
      "source": [
        "def LPF(series, low, order=1):\n",
        "   \n",
        "    b, a = butter(\n",
        "                  N = order,\n",
        "                  Wn = low,\n",
        "                  btype = 'low',\n",
        "                  )\n",
        "    lpf_series = lfilter(b, a, series)\n",
        "    \n",
        "    return lpf_series\n",
        "\n",
        "def preprocessing_2(data):\n",
        "    data['obs_time'] = data.index % 24  # 시간통일\n",
        "    col_list = data.columns\n",
        "    for i in range(0, len(col_list)):\n",
        "        col = col_list[i]\n",
        "        if '누적' in col:\n",
        "            data[col] = data.groupby((data.obs_time == 0).cumsum()).agg(\n",
        "                col_list[i-1]).cumsum()\n",
        "    return data\n",
        "\n",
        "def filtering(df):\n",
        "\n",
        "    f1 = df[df['co2관측치']>578]['Case'].unique().tolist()\n",
        "    f2 = df[((df['내부습도관측치']<74.4)&(df['내부습도관측치']>73.6))|((df['내부습도관측치']<30)&(df['내부습도관측치']>27))|((df['내부습도관측치']<54.5)&(df['내부습도관측치']>54.4)) ]['Case'].unique().tolist()\n",
        "    f3 = df[(df['일간누적분무량']<150)]['Case'].unique().tolist()\n",
        "    \n",
        "    d1 = df[(df['시간당분무량']>2100)]['Case'].unique().tolist()\n",
        "    d2 = df[(df['내부온도관측치']>31.124)&(df['내부온도관측치']<31.126)]['Case'].unique().tolist()\n",
        "    d3 = df[(df['co2관측치']<510.1)&(df['co2관측치']>=510)]['Case'].unique().tolist()\n",
        "    d4 = df[(df['시간당백색광량']>3094.0)&(df['시간당백색광량']<3094.2)]['Case'].unique().tolist()\n",
        "    d5 = df[(df['시간당백색광량']>13400)&(df['시간당백색광량']<13400.5472)]['Case'].unique().tolist()\n",
        "\n",
        "    return_arr = list(set(f1)&set(f2)&set(f3))\n",
        "    for i in set(d1+d2+d3+d4+d5):\n",
        "        if i in return_arr :\n",
        "            return_arr.remove(i)\n",
        "\n",
        "    return return_arr\n",
        "\n",
        "def makedatasets(input_path):\n",
        "\n",
        "    test = preprocessing_2(input_path) #input_path : 생성될 데이터셋 path\n",
        "    print(test)\n",
        "    test['05시내부온도관측치누적'] = 0\n",
        "    test['19시내부온도관측치누적'] = 0\n",
        "    test['23시내부온도관측치누적'] = 0\n",
        "\n",
        "    test['05시내부습도관측치누적'] = 0\n",
        "    test['19시내부습도관측치누적'] = 0\n",
        "    test['23시내부습도관측치누적'] = 0\n",
        "\n",
        "    test['05시co2관측치누적'] = 0\n",
        "    test['19시co2관측치누적'] = 0\n",
        "    test['23시co2관측치누적'] = 0\n",
        "\n",
        "    test['05시ec관측치누적'] = 0\n",
        "    test['19시ec관측치누적'] = 0\n",
        "    test['23시ec관측치누적'] = 0\n",
        "\n",
        "    test['05시분무량누적'] = 0\n",
        "    test['19시분무량누적'] = 0\n",
        "    test['23시분무량누적'] = 0\n",
        "\n",
        "    test['05시백색광누적'] = 0\n",
        "    test['19시백색광누적'] = 0\n",
        "    test['23시백색광누적'] = 0\n",
        "\n",
        "    test['05시적색광누적'] = 0\n",
        "    test['19시적색광누적'] = 0\n",
        "    test['23시적색광누적'] = 0\n",
        "\n",
        "    test['05시청색광누적'] = 0\n",
        "    test['19시청색광누적'] = 0\n",
        "    test['23시청색광누적'] = 0\n",
        "\n",
        "    test['05시총광량누적'] = 0\n",
        "    test['19시총광량누적'] = 0\n",
        "    test['23시총광량누적'] = 0\n",
        "    \n",
        "    testfilter = filtering(test)\n",
        "\n",
        "    test = test.drop(test.filter(regex='일간누적').columns, axis=1)\n",
        "\n",
        "    test_new = test\n",
        "\n",
        "    test['시간대'] = 0\n",
        "    test['시간대'][(test['obs_time'] >= 0) & (test['obs_time'] <= 5)] = 1\n",
        "    test['시간대'][(test['obs_time'] > 5) & (test['obs_time'] < 20)] = 2\n",
        "    test['시간대'][(test['obs_time'] >= 20) & (test['obs_time'] <= 23)] = 3\n",
        "\n",
        "    #########################################################교체#####################\n",
        "\n",
        "    test['hypothesis1'] = 0\n",
        "    print(test.shape)\n",
        "    for i in range(22,len(test),24):\n",
        "        s = test.iloc[i,6] + test.iloc[i+1,6] * ((test.iloc[i, 3] + test.iloc[i+1,3]) / 2)\n",
        "        test.iloc[i, 40] = s\n",
        "\n",
        "\n",
        "\n",
        "    test['hypothesis2'] = 0\n",
        "    for i in range(22,len(test),24):\n",
        "        s = test.iloc[i+1,6] * (test.iloc[i+1,3])\n",
        "        test.iloc[i, 41] = s\n",
        "\n",
        "\n",
        "\n",
        "    test['hypothesis3'] = 0\n",
        "    for i in range(22,len(test),24):\n",
        "        s = (test.iloc[i,6] + test.iloc[i+1,6]) * ((test.iloc[i, 3] + test.iloc[i+1,3]) / 2)\n",
        "        test.iloc[i, 42] = s\n",
        "\n",
        "    ###################################################################################################################\n",
        "\n",
        "    test_x = test\n",
        "    test_x = test_x.groupby(['DAT','Case','시간대']).sum().reset_index()\n",
        "\n",
        "\n",
        "    test_x = test_x.sort_values(by=['Case','DAT','시간대'], axis=0).reset_index()\n",
        "    test_x.drop(['index'], axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "    t = test_x.groupby(['Case'])['내부온도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['내부온도관측치'] = t\n",
        "\n",
        "    t2 = test_x.groupby(['Case'])['내부습도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t2.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['내부습도관측치'] = t2\n",
        "\n",
        "    t3 = test_x.groupby(['Case'])['co2관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t3.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['co2관측치'] = t3\n",
        "\n",
        "    t4 = test_x.groupby(['Case'])['ec관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t4.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['ec관측치'] = t4\n",
        "\n",
        "    t5 = test_x.groupby(['Case'])['시간당분무량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t5.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당분무량'] = t5\n",
        "\n",
        "    t6 = test_x.groupby(['Case'])['시간당백색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t6.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당백색광량'] = t6\n",
        "\n",
        "    t7 = test_x.groupby(['Case'])['시간당적색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t7.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당적색광량'] = t7\n",
        "\n",
        "    t8 = test_x.groupby(['Case'])['시간당청색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t8.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당청색광량'] = t8\n",
        "\n",
        "    t9 = test_x.groupby(['Case'])['시간당총광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t9.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당총광량'] = t9\n",
        "\n",
        "    test_new_x = test_new\n",
        "    test_new_x = test_new_x.groupby(['DAT','Case']).sum().reset_index()\n",
        "\n",
        "    test_new_x = test_new_x.sort_values(by=['Case','DAT'], axis=0).reset_index()\n",
        "    test_new_x.drop(['index'], axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "    case_list = test_x['Case'].unique()\n",
        "\n",
        "    for c in case_list : \n",
        "        if c in testfilter :\n",
        "            continue\n",
        "        test_x.loc[(test_x['Case'] == c ), 'hypothesis1'] = 0\n",
        "        test_x.loc[(test_x['Case'] == c ), 'hypothesis2'] = 0\n",
        "        test_x.loc[(test_x['Case'] == c ), 'hypothesis3'] = 0\n",
        "\n",
        "    for i in range(len(test_new_x)):\n",
        "        #온도\n",
        "        test_new_x.iloc[i,12] = test_x.iloc[0 + (3*i),4]\n",
        "        test_new_x.iloc[i,13] = test_x.iloc[1 + (3*i),4]\n",
        "        test_new_x.iloc[i,14] = test_x.iloc[2 + (3*i),4]\n",
        "        #습도\n",
        "        test_new_x.iloc[i,15] = test_x.iloc[0 + (3*i),5]\n",
        "        test_new_x.iloc[i,16] = test_x.iloc[1 + (3*i),5]\n",
        "        test_new_x.iloc[i,17] = test_x.iloc[2 + (3*i),5]\n",
        "        #co2\n",
        "        test_new_x.iloc[i,18] = test_x.iloc[0 + (3*i),6]\n",
        "        test_new_x.iloc[i,19] = test_x.iloc[1 + (3*i),6]\n",
        "        test_new_x.iloc[i,20] = test_x.iloc[2 + (3*i),6]\n",
        "        #ec\n",
        "        test_new_x.iloc[i,21] = test_x.iloc[0 + (3*i),7]\n",
        "        test_new_x.iloc[i,22] = test_x.iloc[1 + (3*i),7]\n",
        "        test_new_x.iloc[i,23] = test_x.iloc[2 + (3*i),7]\n",
        "        #분무\n",
        "        test_new_x.iloc[i,24] = test_x.iloc[0 + (3*i),8]\n",
        "        test_new_x.iloc[i,25] = test_x.iloc[1 + (3*i),8]\n",
        "        test_new_x.iloc[i,26] = test_x.iloc[2 + (3*i),8]\n",
        "        #백색\n",
        "        test_new_x.iloc[i,27] = test_x.iloc[0 + (3*i),9]\n",
        "        test_new_x.iloc[i,28] = test_x.iloc[1 + (3*i),9]\n",
        "        test_new_x.iloc[i,29] = test_x.iloc[2 + (3*i),9]\n",
        "        #적색\n",
        "        test_new_x.iloc[i,30] = test_x.iloc[0 + (3*i),10]\n",
        "        test_new_x.iloc[i,31] = test_x.iloc[1 + (3*i),10]\n",
        "        test_new_x.iloc[i,32] = test_x.iloc[2 + (3*i),10]\n",
        "        #청색\n",
        "        test_new_x.iloc[i,33] = test_x.iloc[0 + (3*i),11]\n",
        "        test_new_x.iloc[i,34] = test_x.iloc[1 + (3*i),11]\n",
        "        test_new_x.iloc[i,35] = test_x.iloc[2 + (3*i),11]\n",
        "        #총광\n",
        "        test_new_x.iloc[i,36] = test_x.iloc[0 + (3*i),12]\n",
        "        test_new_x.iloc[i,37] = test_x.iloc[1 + (3*i),12]\n",
        "        test_new_x.iloc[i,38] = test_x.iloc[2 + (3*i),12]\n",
        "\n",
        "\n",
        "\n",
        "    test_new_x.drop(['obs_time','시간대','내부온도관측치','내부습도관측치','co2관측치','ec관측치'], axis = 1, inplace = True)\n",
        "\n",
        "    test_x = test_new_x\n",
        "\n",
        "    test_x = test_x.drop(test_x.filter(regex='시간당').columns, axis=1)\n",
        "\n",
        "\n",
        "    test_x['하루평균온도'] = (test_x['05시내부온도관측치누적'] + test_x['19시내부온도관측치누적'] + test_x['23시내부온도관측치누적']) / 3\n",
        "    test_x['하루평균습도'] = (test_x['05시내부습도관측치누적'] + test_x['19시내부습도관측치누적'] + test_x['23시내부습도관측치누적']) / 3\n",
        "    test_x['하루평균co2'] = (test_x['05시co2관측치누적'] + test_x['19시co2관측치누적'] + test_x['23시co2관측치누적']) / 3\n",
        "    test_x['하루평균ec'] = (test_x['05시ec관측치누적'] + test_x['19시ec관측치누적'] + test_x['23시ec관측치누적']) / 3\n",
        "    test_x['하루평균분무량'] = (test_x['05시분무량누적'] + test_x['19시분무량누적'] + test_x['23시분무량누적']) / 3\n",
        "    test_x['하루평균백색광'] = (test_x['05시백색광누적'] + test_x['19시백색광누적'] + test_x['23시백색광누적']) / 3\n",
        "    test_x['하루평균적색광'] = (test_x['05시적색광누적'] + test_x['19시적색광누적'] + test_x['23시적색광누적']) / 3\n",
        "    test_x['하루평균청색광'] = (test_x['05시청색광누적'] + test_x['19시청색광누적'] + test_x['23시청색광누적']) / 3\n",
        "    test_x['하루평균총광량'] = (test_x['05시총광량누적'] + test_x['19시총광량누적'] + test_x['23시총광량누적']) / 3\n",
        "\n",
        "    test_x = test_x.drop(test_x.filter(regex = '총광').columns, axis =1)\n",
        "\n",
        "\n",
        "    test_x['hypothesis4'] = (test_x['05시ec관측치누적']+1) * (test_x['05시분무량누적']+1)\n",
        "    test_x['hypothesis5'] = (test_x['19시ec관측치누적']+1) * (test_x['19시분무량누적']+1)\n",
        "    test_x['hypothesis6'] = (test_x['23시ec관측치누적']+1) * (test_x['23시분무량누적']+1)\n",
        "    test_x['hypothesis7'] = (test_x['하루평균ec']+1) * (test_x['하루평균분무량']+1)\n",
        "\n",
        "    test_x['적색_+_청색05'] = (test_x['05시적색광누적']) + (test_x['05시청색광누적'])\n",
        "    test_x['적색_+_청색19'] = (test_x['19시적색광누적']) + (test_x['19시청색광누적'])\n",
        "    test_x['적색_+_청색23'] = (test_x['23시적색광누적']) + (test_x['23시청색광누적'])\n",
        "    test_x['적색_+_청색평균'] = (test_x['하루평균적색광']) + (test_x['하루평균청색광'])\n",
        "\n",
        "\n",
        "    test_x['hypothesis123'] =  test_x['hypothesis1'] + test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "    test_x['hypothesis12'] =  test_x['hypothesis2'] + test_x['hypothesis1']\n",
        "    test_x['hypothesis23'] =  test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "    test_x['hypothesis13'] =  test_x['hypothesis1'] + test_x['hypothesis3']\n",
        "    test_x['hypothesis123'] =  test_x['hypothesis1'] + test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "    \n",
        "    test_x.drop(test_x.filter(regex = '백색'), axis = 1, inplace=True)\n",
        "\n",
        "    test_x.drop(test_x.filter(regex = '청색'), axis = 1, inplace=True)\n",
        "\n",
        "    test_x.drop(['hypothesis1', 'hypothesis2', 'hypothesis3'],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "    basic_col = test_x.columns\n",
        "    kal_test = test_x\n",
        "\n",
        "    for i in range(2,34):\n",
        "        test_x['kf_X_'+str(i)]=0\n",
        "\n",
        "    for j in range(0,len(test_x.Case.unique())): \n",
        "        kal = test_x[test_x['Case'] == j]\n",
        "        for i in (range(len(basic_col))):\n",
        "            if((i == 0) | (i == 1)):\n",
        "                continue\n",
        "            current=0\n",
        "            sum_c=[]\n",
        "            z = kal.loc[:, kal.columns[i]]\n",
        "            a = []           \n",
        "            b = []         \n",
        "            my_filter = KalmanFilter(dim_x=2,dim_z=1)\n",
        "            my_filter.x = np.array([[2.],[0.]])     \n",
        "            my_filter.F = np.array([[1.,1.], [0.,1.]])   \n",
        "            my_filter.H = np.array([[1.,0.]])\n",
        "            my_filter.P *= 1000.              \n",
        "            my_filter.R = 5                     \n",
        "            my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.5) \n",
        "            for k in z.values:\n",
        "                my_filter.predict()\n",
        "                my_filter.update(k)\n",
        "                x = my_filter.x\n",
        "                a.extend(x[0])\n",
        "                b.append(k)\n",
        "            sum_c=sum_c+a\n",
        "            test_x['kf_X_'+str(i)][test_x['Case'] == j] = sum_c\n",
        "    copy_test_x = test_x.copy()\n",
        "\n",
        "    copy_test_x.drop(copy_test_x.filter(regex = 'kf').columns, axis = 1, inplace = True)\n",
        "    print(copy_test_x)\n",
        "\n",
        "    raw_cols_te = copy_test_x.columns\n",
        "    new_test_x = pd.DataFrame()\n",
        "    for i in range(0,len(copy_test_x.Case.unique())):\n",
        "        target = copy_test_x[copy_test_x['Case'] == i]\n",
        "        mean_arr = []\n",
        "        median_arr = []\n",
        "        pbar = (target.columns[:])\n",
        "        for column in pbar:\n",
        "            column_list = target[column].to_list()\n",
        "            for i in range(7):\n",
        "                if((i) == (len(column_list))):\n",
        "                    break\n",
        "                mean_arr.append(column_list[i])\n",
        "                median_arr.append(column_list[i])\n",
        "            for i in range(7, len(column_list)):\n",
        "                mean_arr.append(float(np.mean(column_list[i-7:i])))\n",
        "                median_arr.append(float(np.median(column_list[i-7:i])))\n",
        "            target[f'{column}_mean_7'] = mean_arr\n",
        "            target[f'{column}_median_7'] = median_arr\n",
        "            mean_arr = []\n",
        "            median_arr = []\n",
        "        \n",
        "        new_test_x = pd.concat([new_test_x, target], axis=0)\n",
        "    test_x_moving_7 = new_test_x.drop(raw_cols_te, axis=1)\n",
        "\n",
        "    test_x = pd.concat([test_x, test_x_moving_7], axis=1)\n",
        "\n",
        "    raw_cols_te = copy_test_x.columns\n",
        "\n",
        "    new_test_x = pd.DataFrame()\n",
        "\n",
        "    for i in range(0,len(copy_test_x.Case.unique())):\n",
        "        target = copy_test_x[copy_test_x['Case'] == i]\n",
        "        mean_arr = []\n",
        "        median_arr = []\n",
        "        pbar = (target.columns[:])\n",
        "        for column in pbar:\n",
        "            column_list = target[column].to_list()\n",
        "            for i in range(14):\n",
        "                if((i) == (len(column_list))):\n",
        "                    break\n",
        "                mean_arr.append(column_list[i])\n",
        "                median_arr.append(column_list[i])\n",
        "            for i in range(14, len(column_list)):\n",
        "                mean_arr.append(float(np.mean(column_list[i-14:i])))\n",
        "                median_arr.append(float(np.median(column_list[i-14:i])))\n",
        "            target[f'{column}_mean_14'] = mean_arr\n",
        "            target[f'{column}_median_14'] = median_arr\n",
        "            mean_arr = []\n",
        "            median_arr = []\n",
        "        \n",
        "        new_test_x = pd.concat([new_test_x, target], axis=0)\n",
        "    test_x_moving_14 = new_test_x.drop(raw_cols_te, axis=1)\n",
        "\n",
        "    test_x = pd.concat([test_x, test_x_moving_14], axis=1)\n",
        "\n",
        "    test_x_fil = test_x.iloc[:,1:34]\n",
        "\n",
        "    new_test_x = pd.DataFrame()\n",
        "    for i in range(0,len(copy_test_x.Case.unique())):\n",
        "        target = test_x_fil[test_x_fil['Case'] == i]\n",
        "        test_merge = LPF(target,0.1,1)\n",
        "        test_merge = pd.DataFrame(test_merge)\n",
        "        \n",
        "        new_test_x = pd.concat([new_test_x, test_merge], axis=0)\n",
        "    new_test_x = new_test_x.add_suffix('_LPF')\n",
        "    new_test_x = new_test_x.reset_index(drop = True)\n",
        "    test_x = pd.concat([test_x,new_test_x], axis = 1)\n",
        "\n",
        "    test_x.drop(['0_LPF'],axis = 1, inplace=True)\n",
        "    test_x.drop(test_x.filter(regex = 'Case'),axis=1, inplace=True)\n",
        "\n",
        "    return test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t9l36shB2ADK"
      },
      "outputs": [],
      "source": [
        "def make_data(input_path, fix_path, day):\n",
        "    test = preprocessing_2(input_path) \n",
        "\n",
        "    if day != 0 : \n",
        "        test = pd.concat([test,fix_path],axis=0)\n",
        "    test = test.reset_index(drop = True)\n",
        "\n",
        "    test['05시내부온도관측치누적'] = 0\n",
        "    test['19시내부온도관측치누적'] = 0\n",
        "    test['23시내부온도관측치누적'] = 0\n",
        "\n",
        "    test['05시내부습도관측치누적'] = 0\n",
        "    test['19시내부습도관측치누적'] = 0\n",
        "    test['23시내부습도관측치누적'] = 0\n",
        "\n",
        "    test['05시co2관측치누적'] = 0\n",
        "    test['19시co2관측치누적'] = 0\n",
        "    test['23시co2관측치누적'] = 0\n",
        "\n",
        "    test['05시ec관측치누적'] = 0\n",
        "    test['19시ec관측치누적'] = 0\n",
        "    test['23시ec관측치누적'] = 0\n",
        "\n",
        "    test['05시분무량누적'] = 0\n",
        "    test['19시분무량누적'] = 0\n",
        "    test['23시분무량누적'] = 0\n",
        "\n",
        "    test['05시백색광누적'] = 0\n",
        "    test['19시백색광누적'] = 0\n",
        "    test['23시백색광누적'] = 0\n",
        "\n",
        "    test['05시적색광누적'] = 0\n",
        "    test['19시적색광누적'] = 0\n",
        "    test['23시적색광누적'] = 0\n",
        "\n",
        "    test['05시청색광누적'] = 0\n",
        "    test['19시청색광누적'] = 0\n",
        "    test['23시청색광누적'] = 0\n",
        "\n",
        "    test['05시총광량누적'] = 0\n",
        "    test['19시총광량누적'] = 0\n",
        "    test['23시총광량누적'] = 0\n",
        "\n",
        "    testfilter = filtering(test)\n",
        "\n",
        "    test = test.drop(test.filter(regex='일간누적').columns, axis=1)\n",
        "\n",
        "    test_new = test\n",
        "\n",
        "    test['시간대'] = 0\n",
        "    test['시간대'][(test['obs_time'] >= 0) & (test['obs_time'] <= 5)] = 1\n",
        "    test['시간대'][(test['obs_time'] > 5) & (test['obs_time'] < 20)] = 2\n",
        "    test['시간대'][(test['obs_time'] >= 20) & (test['obs_time'] <= 23)] = 3\n",
        "\n",
        "    test['hypothesis1'] = 0\n",
        "    for i in range(22,len(test),24):\n",
        "        s = test.iloc[i,6] + test.iloc[i+1,6] * ((test.iloc[i, 3] + test.iloc[i+1,3]) / 2)\n",
        "        test.iloc[i, 40] = s\n",
        "\n",
        "    test['hypothesis2'] = 0\n",
        "    for i in range(22,len(test),24):\n",
        "        s = test.iloc[i+1,6] * (test.iloc[i+1,3])\n",
        "        test.iloc[i, 41] = s\n",
        "\n",
        "\n",
        "    test['hypothesis3'] = 0\n",
        "    for i in range(22,len(test),24):\n",
        "        s = (test.iloc[i,6] + test.iloc[i+1,6]) * ((test.iloc[i, 3] + test.iloc[i+1,3]) / 2)\n",
        "        test.iloc[i, 42] = s\n",
        "\n",
        "    ###################################################################################################################\n",
        "\n",
        "    case_list = test['Case'].unique()\n",
        "\n",
        "    for c in case_list : \n",
        "        if c in testfilter :\n",
        "            continue\n",
        "        test.loc[(test['Case'] == c ), 'hypothesis1'] = 0\n",
        "        test.loc[(test['Case'] == c ), 'hypothesis2'] = 0\n",
        "        test.loc[(test['Case'] == c ), 'hypothesis3'] = 0\n",
        "\n",
        "    test_x = test\n",
        "    test_x = test_x.groupby(['DAT','Case','시간대']).sum().reset_index()\n",
        "\n",
        "    test_x = test_x.sort_values(by=['Case','DAT','시간대'], axis=0).reset_index()\n",
        "    test_x.drop(['index'], axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "    t = test_x.groupby(['Case'])['내부온도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['내부온도관측치'] = t\n",
        "\n",
        "    t2 = test_x.groupby(['Case'])['내부습도관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t2.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['내부습도관측치'] = t2\n",
        "\n",
        "    t3 = test_x.groupby(['Case'])['co2관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t3.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['co2관측치'] = t3\n",
        "\n",
        "    t4 = test_x.groupby(['Case'])['ec관측치'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t4.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['ec관측치'] = t4\n",
        "\n",
        "    t5 = test_x.groupby(['Case'])['시간당분무량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t5.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당분무량'] = t5\n",
        "\n",
        "    t6 = test_x.groupby(['Case'])['시간당백색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t6.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당백색광량'] = t6\n",
        "\n",
        "    t7 = test_x.groupby(['Case'])['시간당적색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t7.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당적색광량'] = t7\n",
        "\n",
        "    t8 = test_x.groupby(['Case'])['시간당청색광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t8.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당청색광량'] = t8\n",
        "\n",
        "    t9 = test_x.groupby(['Case'])['시간당총광량'].expanding().sum().reset_index().drop(['Case'], axis = 1)\n",
        "    t9.drop(['level_1'], axis = 1, inplace = True)\n",
        "    test_x['시간당총광량'] = t9\n",
        "\n",
        "    test_new_x = test_new\n",
        "    test_new_x = test_new_x.groupby(['DAT','Case']).sum().reset_index()\n",
        "\n",
        "    test_new_x = test_new_x.sort_values(by=['Case','DAT'], axis=0).reset_index()\n",
        "    test_new_x.drop(['index'], axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "    for i in range(len(test_new_x)):\n",
        "        #온도\n",
        "        test_new_x.iloc[i,12] = test_x.iloc[0 + (3*i),4]\n",
        "        test_new_x.iloc[i,13] = test_x.iloc[1 + (3*i),4]\n",
        "        test_new_x.iloc[i,14] = test_x.iloc[2 + (3*i),4]\n",
        "        #습도\n",
        "        test_new_x.iloc[i,15] = test_x.iloc[0 + (3*i),5]\n",
        "        test_new_x.iloc[i,16] = test_x.iloc[1 + (3*i),5]\n",
        "        test_new_x.iloc[i,17] = test_x.iloc[2 + (3*i),5]\n",
        "        #co2\n",
        "        test_new_x.iloc[i,18] = test_x.iloc[0 + (3*i),6]\n",
        "        test_new_x.iloc[i,19] = test_x.iloc[1 + (3*i),6]\n",
        "        test_new_x.iloc[i,20] = test_x.iloc[2 + (3*i),6]\n",
        "        #ec\n",
        "        test_new_x.iloc[i,21] = test_x.iloc[0 + (3*i),7]\n",
        "        test_new_x.iloc[i,22] = test_x.iloc[1 + (3*i),7]\n",
        "        test_new_x.iloc[i,23] = test_x.iloc[2 + (3*i),7]\n",
        "        #분무\n",
        "        test_new_x.iloc[i,24] = test_x.iloc[0 + (3*i),8]\n",
        "        test_new_x.iloc[i,25] = test_x.iloc[1 + (3*i),8]\n",
        "        test_new_x.iloc[i,26] = test_x.iloc[2 + (3*i),8]\n",
        "        #백색\n",
        "        test_new_x.iloc[i,27] = test_x.iloc[0 + (3*i),9]\n",
        "        test_new_x.iloc[i,28] = test_x.iloc[1 + (3*i),9]\n",
        "        test_new_x.iloc[i,29] = test_x.iloc[2 + (3*i),9]\n",
        "        #적색\n",
        "        test_new_x.iloc[i,30] = test_x.iloc[0 + (3*i),10]\n",
        "        test_new_x.iloc[i,31] = test_x.iloc[1 + (3*i),10]\n",
        "        test_new_x.iloc[i,32] = test_x.iloc[2 + (3*i),10]\n",
        "        #청색\n",
        "        test_new_x.iloc[i,33] = test_x.iloc[0 + (3*i),11]\n",
        "        test_new_x.iloc[i,34] = test_x.iloc[1 + (3*i),11]\n",
        "        test_new_x.iloc[i,35] = test_x.iloc[2 + (3*i),11]\n",
        "        #총광\n",
        "        test_new_x.iloc[i,36] = test_x.iloc[0 + (3*i),12]\n",
        "        test_new_x.iloc[i,37] = test_x.iloc[1 + (3*i),12]\n",
        "        test_new_x.iloc[i,38] = test_x.iloc[2 + (3*i),12]\n",
        "\n",
        "\n",
        "\n",
        "    test_new_x.drop(['obs_time','시간대','내부온도관측치','내부습도관측치','co2관측치','ec관측치'], axis = 1, inplace = True)\n",
        "\n",
        "    test_x = test_new_x\n",
        "\n",
        "    test_x = test_x.drop(test_x.filter(regex='시간당').columns, axis=1)\n",
        "\n",
        "\n",
        "    test_x['하루평균온도'] = (test_x['05시내부온도관측치누적'] + test_x['19시내부온도관측치누적'] + test_x['23시내부온도관측치누적']) / 3\n",
        "    test_x['하루평균습도'] = (test_x['05시내부습도관측치누적'] + test_x['19시내부습도관측치누적'] + test_x['23시내부습도관측치누적']) / 3\n",
        "    test_x['하루평균co2'] = (test_x['05시co2관측치누적'] + test_x['19시co2관측치누적'] + test_x['23시co2관측치누적']) / 3\n",
        "    test_x['하루평균ec'] = (test_x['05시ec관측치누적'] + test_x['19시ec관측치누적'] + test_x['23시ec관측치누적']) / 3\n",
        "    test_x['하루평균분무량'] = (test_x['05시분무량누적'] + test_x['19시분무량누적'] + test_x['23시분무량누적']) / 3\n",
        "    test_x['하루평균백색광'] = (test_x['05시백색광누적'] + test_x['19시백색광누적'] + test_x['23시백색광누적']) / 3\n",
        "    test_x['하루평균적색광'] = (test_x['05시적색광누적'] + test_x['19시적색광누적'] + test_x['23시적색광누적']) / 3\n",
        "    test_x['하루평균청색광'] = (test_x['05시청색광누적'] + test_x['19시청색광누적'] + test_x['23시청색광누적']) / 3\n",
        "    test_x['하루평균총광량'] = (test_x['05시총광량누적'] + test_x['19시총광량누적'] + test_x['23시총광량누적']) / 3\n",
        "\n",
        "    test_x = test_x.drop(test_x.filter(regex = '총광').columns, axis =1)\n",
        "\n",
        "\n",
        "    test_x['hypothesis4'] = (test_x['05시ec관측치누적']+1) * (test_x['05시분무량누적']+1)\n",
        "    test_x['hypothesis5'] = (test_x['19시ec관측치누적']+1) * (test_x['19시분무량누적']+1)\n",
        "    test_x['hypothesis6'] = (test_x['23시ec관측치누적']+1) * (test_x['23시분무량누적']+1)\n",
        "    test_x['hypothesis7'] = (test_x['하루평균ec']+1) * (test_x['하루평균분무량']+1)\n",
        "\n",
        "    test_x['적색_+_청색05'] = (test_x['05시적색광누적']) + (test_x['05시청색광누적'])\n",
        "    test_x['적색_+_청색19'] = (test_x['19시적색광누적']) + (test_x['19시청색광누적'])\n",
        "    test_x['적색_+_청색23'] = (test_x['23시적색광누적']) + (test_x['23시청색광누적'])\n",
        "    test_x['적색_+_청색평균'] = (test_x['하루평균적색광']) + (test_x['하루평균청색광'])\n",
        "\n",
        "    test_x['hypothesis123'] =  test_x['hypothesis1'] + test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "    test_x['hypothesis12'] =  test_x['hypothesis2'] + test_x['hypothesis1']\n",
        "    test_x['hypothesis23'] =  test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "    test_x['hypothesis13'] =  test_x['hypothesis1'] + test_x['hypothesis3']\n",
        "    test_x['hypothesis123'] =  test_x['hypothesis1'] + test_x['hypothesis2'] + test_x['hypothesis3']\n",
        "  \n",
        "\n",
        "    test_x.drop(test_x.filter(regex = '백색'), axis = 1, inplace=True)\n",
        "\n",
        "    test_x.drop(test_x.filter(regex = '청색'), axis = 1, inplace=True)\n",
        "\n",
        "    test_x.drop(['hypothesis1', 'hypothesis2', 'hypothesis3'],axis=1,inplace=True)\n",
        "\n",
        "    basic_col = test_x.columns\n",
        "    kal_test = test_x\n",
        "\n",
        "    for i in range(2,34):\n",
        "        test_x['kf_X_'+str(i)]=0\n",
        "\n",
        "    for j in range(0,len(test_x.Case.unique())): \n",
        "        kal = test_x\n",
        "        for i in (range(len(basic_col))):\n",
        "            if((i == 0) | (i == 1)):\n",
        "                continue\n",
        "            current=0\n",
        "            sum_c=[]\n",
        "            z = kal.loc[:, kal.columns[i]]\n",
        "            a = []           #필터링 된 피쳐(after)\n",
        "            b = []           #필터링 전 피쳐(before)\n",
        "            my_filter = KalmanFilter(dim_x=2,dim_z=1) #create kalman filter\n",
        "            my_filter.x = np.array([[2.],[0.]])       # initial state (location and velocity)\n",
        "            my_filter.F = np.array([[1.,1.], [0.,1.]])    # state transition matrix\n",
        "            my_filter.H = np.array([[1.,0.]])    # Measurement function\n",
        "            my_filter.P *= 1000.                 # covariance matrix\n",
        "            my_filter.R = 5                      # state uncertainty\n",
        "            my_filter.Q = Q_discrete_white_noise(dim = 2,dt=.1,var=.5) # process uncertainty   \n",
        "            for k in z.values:\n",
        "                my_filter.predict()\n",
        "                my_filter.update(k)\n",
        "                x = my_filter.x\n",
        "                a.extend(x[0])\n",
        "                b.append(k)\n",
        "            sum_c=sum_c+a\n",
        "            test_x['kf_X_'+str(i)] = sum_c\n",
        "\n",
        "    copy_test_x = test_x.copy()\n",
        "\n",
        "    copy_test_x.drop(copy_test_x.filter(regex = 'kf').columns, axis = 1, inplace = True)\n",
        "\n",
        "    raw_cols_te = copy_test_x.columns\n",
        "    new_test_x = pd.DataFrame()\n",
        "    for i in range(0,len(copy_test_x.Case.unique())):\n",
        "        target = copy_test_x\n",
        "        mean_arr = []\n",
        "        median_arr = []\n",
        "\n",
        "        pbar = (target.columns[:])\n",
        "        for column in pbar:\n",
        "            column_list = target[column].to_list()\n",
        "            for i in range(7):\n",
        "                if((i) == (len(column_list))):\n",
        "                    break\n",
        "                mean_arr.append(column_list[i])\n",
        "                median_arr.append(column_list[i])\n",
        "\n",
        "            for i in range(7, len(column_list)):\n",
        "                mean_arr.append(float(np.mean(column_list[i-7:i])))\n",
        "                median_arr.append(float(np.median(column_list[i-7:i])))\n",
        "            target[f'{column}_mean_7'] = mean_arr\n",
        "            target[f'{column}_median_7'] = median_arr\n",
        "            mean_arr = []\n",
        "            median_arr = []\n",
        "        \n",
        "        new_test_x = pd.concat([new_test_x, target], axis=0)\n",
        "    test_x_moving_7 = new_test_x.drop(raw_cols_te, axis=1)\n",
        "\n",
        "    test_x = pd.concat([test_x, test_x_moving_7], axis=1)\n",
        "\n",
        "    raw_cols_te = copy_test_x.columns\n",
        "\n",
        "\n",
        "\n",
        "    new_test_x = pd.DataFrame()\n",
        "\n",
        "    for i in range(0,len(copy_test_x.Case.unique())):\n",
        "        target = copy_test_x[copy_test_x['Case'] == i]\n",
        "        mean_arr = []\n",
        "        median_arr = []\n",
        "\n",
        "\n",
        "        pbar = tqdm(target.columns[:])\n",
        "        for column in pbar:\n",
        "            column_list = target[column].to_list()\n",
        "            for i in range(14):\n",
        "                if((i) == (len(column_list))):\n",
        "                    break\n",
        "                mean_arr.append(column_list[i])\n",
        "                median_arr.append(column_list[i])\n",
        "                \n",
        "            for i in range(14, len(column_list)):\n",
        "                mean_arr.append(float(np.mean(column_list[i-14:i])))\n",
        "                median_arr.append(float(np.median(column_list[i-14:i])))\n",
        "            target[f'{column}_mean_14'] = mean_arr\n",
        "            target[f'{column}_median_14'] = median_arr\n",
        "            mean_arr = []\n",
        "            median_arr = []\n",
        "        \n",
        "        new_test_x = pd.concat([new_test_x, target], axis=0)\n",
        "    test_x_moving_14 = new_test_x.drop(raw_cols_te, axis=1)\n",
        "\n",
        "    test_x = pd.concat([test_x, test_x_moving_14], axis=1)\n",
        "\n",
        "    test_x_fil = test_x.iloc[:,1:34]\n",
        "\n",
        "\n",
        "    new_test_x = pd.DataFrame()\n",
        "    for i in range(0,len(copy_test_x.Case.unique())):\n",
        "        target = test_x_fil\n",
        "        test_merge = LPF(target,0.1,1)\n",
        "        test_merge = pd.DataFrame(test_merge)\n",
        "        \n",
        "        new_test_x = pd.concat([new_test_x, test_merge], axis=0)\n",
        "    new_test_x = new_test_x.add_suffix('_LPF')\n",
        "    new_test_x = new_test_x.reset_index(drop = True)\n",
        "    test_x = pd.concat([test_x,new_test_x], axis = 1)\n",
        "\n",
        "\n",
        "    test_x.drop(['0_LPF'],axis = 1, inplace=True)\n",
        "    test_x.drop(test_x.filter(regex = 'Case'),axis=1, inplace=True)\n",
        "    return test_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9ZTjq1fqsqzf"
      },
      "outputs": [],
      "source": [
        "def make_traindata_ctgan(input_path):\n",
        "    train = pd.DataFrame()\n",
        "    x = pd.read_csv(input_path)\n",
        "    x = x[['obs_time','내부온도관측치','내부습도관측치','co2관측치','ec관측치','시간당분무량','시간당백색광량','시간당적색광량','시간당청색광량']]\n",
        "    col_list = x.columns[1:]\n",
        "    for i in range(0,28) :\n",
        "        day = x.iloc[24*i:24*i+24]\n",
        "        time_list = day['obs_time'].unique()\n",
        "        for t in range(0,len(time_list)):\n",
        "            for col in col_list:\n",
        "                time = time_list[t]\n",
        "                value1 = day[day['obs_time']==time][col].iloc[0]\n",
        "                x[col+str(time)] = value1\n",
        "        nx = x.iloc[:1,9:]\n",
        "        train = pd.concat([train,nx]).reset_index(drop=True)\n",
        "    return train\n",
        "\n",
        "def make_raw (df, day) :\n",
        "    df_numpy = df.values\n",
        "    return_arr = []\n",
        "    \n",
        "    for i in range(len(df_numpy)) :\n",
        "            now = df_numpy[i]\n",
        "            for j in range(24):\n",
        "                value = np.insert(now[j*8:j*8+8],0, int(day)) # dat\n",
        "                value = np.insert(value , 1 ,int(j)) # obs_time\n",
        "                value = np.insert(value , 0 ,int(i)) # case\n",
        "                return_arr.append(value.tolist())\n",
        "\n",
        "    return_df = pd.DataFrame(np.array(return_arr),columns = ['Case','DAT', 'obs_time', '내부온도관측치', '내부습도관측치','co2관측치', \n",
        "                                        'ec관측치', '시간당분무량', '시간당백색광량',  '시간당적색광량',  '시간당청색광량' ])\n",
        "    \n",
        "    return_df['시간당총광량'] = return_df['시간당백색광량'] + return_df['시간당적색광량'] + return_df['시간당청색광량']\n",
        "    \n",
        "    # 중앙값 차이 값으로 값 변환\n",
        "    return_df['내부온도관측치'] =  return_df['내부온도관측치']  - 2\n",
        "    return_df['시간당분무량'] = return_df['시간당분무량'] + 1251.865000\n",
        "    return_df['ec관측치'] = return_df['ec관측치'] +1.7\n",
        "\n",
        "    cumsum_list = ['일간누적분무량', '일간누적백색광량', '일간누적적색광량', '일간누적청색광량', '일간누적총광량']\n",
        "    per_time_list = ['시간당분무량', '시간당백색광량', '시간당적색광량', '시간당청색광량', '시간당총광량']\n",
        "\n",
        "    for i in range(0, 5):\n",
        "        col1 = cumsum_list[i]\n",
        "        col2 = per_time_list[i]\n",
        "        return_df[col1] = 0\n",
        "        return_df[col1] = return_df.groupby((return_df.obs_time == 0).cumsum()).agg(col2).cumsum()\n",
        "\n",
        "    return_df = return_df[['Case', 'DAT', 'obs_time', '내부온도관측치', '내부습도관측치', 'co2관측치', 'ec관측치', '시간당분무량',\n",
        "             '일간누적분무량', '시간당백색광량', '일간누적백색광량', '시간당적색광량', '일간누적적색광량', '시간당청색광량',\n",
        "             '일간누적청색광량', '시간당총광량', '일간누적총광량']]\n",
        "\n",
        "    return return_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGpNgjqSs0rs"
      },
      "source": [
        "# CTGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OdNVeGbwGXig"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed: int=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)               # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True      # type: ignore\n",
        "\n",
        "''' sample '''\n",
        "# seed_everything(0)\n",
        "from ctgan import CTGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T_W-19uVGSoc"
      },
      "outputs": [],
      "source": [
        "# [path] 생성한 데이터샘플 저장\n",
        "generated_path = \"/content/drive/MyDrive/Project_L/ctgan_day0_27/\"\n",
        "\n",
        "# [path] ctgan에 넣을 데이터 \n",
        "input_path1 = '/content/drive/MyDrive/dacon/gan/상추/train_input/CASE_21.csv' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-KZbJuhLGSmZ"
      },
      "outputs": [],
      "source": [
        "def augmentation(input_path1, save_path):\n",
        "        \n",
        "    # [flatten] real data -> ctgan input data\n",
        "    raw_data1 = make_traindata_ctgan(input_path1)\n",
        "\n",
        "    input_data = raw_data1.iloc[:7]\n",
        "\n",
        "    model = CTGAN()\n",
        "    model.fit(input_data, epochs=50)\n",
        "    output_data = model.sample(50)\n",
        "    model.save(\"/content/drive/MyDrive/Project_L/gen_model7\")\n",
        "\n",
        "    for i in range(0,7):\n",
        "        dayi = make_raw(output_data,i)\n",
        "        dayi.to_csv(os.path.join(generated_path, f'generate_day_{i}_50_R.csv'), index=False)\n",
        "\n",
        "    input_data = raw_data1.iloc[7:14]\n",
        "    model = CTGAN()\n",
        "    model.fit(input_data, epochs=50)\n",
        "    output_data = model.sample(50)\n",
        "    model.save(\"/content/drive/MyDrive/Project_L/gen_model14\")\n",
        "\n",
        "    for i in range(7,14):\n",
        "        dayi = make_raw(output_data,i)\n",
        "        dayi.to_csv(os.path.join(generated_path, f'generate_day_{i}_50_R.csv'), index=False)\n",
        "\n",
        "    input_data = raw_data1.iloc[14:21]\n",
        "    model = CTGAN()\n",
        "    model.fit(input_data, epochs=50)\n",
        "    output_data = model.sample(50)\n",
        "    model.save(\"/content/drive/MyDrive/Project_L/gen_model21\")\n",
        "\n",
        "    for i in range(14,21):\n",
        "        output_data = model.sample(50)\n",
        "        dayi = make_raw(output_data,i)\n",
        "        dayi.to_csv(os.path.join(generated_path, f'generate_day_{i}_50_R.csv'), index=False)\n",
        "\n",
        "    input_data = raw_data1.iloc[21:]\n",
        "    model = CTGAN()\n",
        "    model.fit(input_data, epochs=50)\n",
        "    output_data = model.sample(50)\n",
        "    model.save(\"/content/drive/MyDrive/Project_L/gen_model28\")\n",
        "\n",
        "    for i in range(21,28):\n",
        "        output_data = model.sample(50)\n",
        "        dayi = make_raw(output_data,i)\n",
        "        dayi.to_csv(os.path.join(generated_path, f'generate_day_{i}_50_R.csv'), index=False)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TcmPGSBSGSj6"
      },
      "outputs": [],
      "source": [
        "augmentation(input_path1,generated_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k45Pkkg2GShi",
        "outputId": "464692dd-1918-479c-bfd2-4f2faca0151d"
      },
      "outputs": [],
      "source": [
        "# 예측모델 로드\n",
        "predict_model = TabularPredictor.load(\"/content/drive/MyDrive/Project_L/최종예측모델\", require_version_match=False)\n",
        "\n",
        "# 0일차 예측\n",
        "gen_data = pd.read_csv('/content/drive/MyDrive/Project_L/ctgan_day0_27/generate_day_0_50_R.csv')  \n",
        "max_list = []\n",
        "for i in range(50):\n",
        "    gen_data_new = gen_data[i*24:(i+1)*24]\n",
        "    gen_data_new['Case']=0\n",
        "    gan_data = makedatasets(gen_data_new)\n",
        "    y_pred = predict_model.predict(gan_data)\n",
        "    max_list.append(y_pred.max())\n",
        "max_list = pd.DataFrame(max_list)\n",
        "idx_max = max_list.idxmax()\n",
        "gen_dat = gen_data[int(idx_max.values)*24:(int(idx_max.values)+1)*24]\n",
        "gen_dat['DAT'] = 0\n",
        "print(max_list.max())\n",
        "# fix data 경로\n",
        "gen_dat.to_csv(\"/content/drive/MyDrive/Project_L/fix.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63i6NwGJGeqa",
        "outputId": "1562cdd4-c04e-4f41-8620-bd1367f6f78f"
      },
      "outputs": [],
      "source": [
        "predict_model = TabularPredictor.load(\"/content/drive/MyDrive/Project_L/최종예측모델\", require_version_match=False)\n",
        "\n",
        "for day in range(1, 28):\n",
        "    max_0 = pd.read_csv(\"/content/drive/MyDrive/Project_L/fix.csv\")\n",
        "    print(f'{day}일차 Start')\n",
        "    gen_data = pd.read_csv(f'/content/drive/MyDrive/dacon/상/generate_day_{day}_50_R.csv')  # 동적변경\n",
        "    max_list = []\n",
        "    for i in range(50):\n",
        "        gen_data_new = gen_data[i*24:(i+1)*24]\n",
        "        gen_data_new = gen_data_new.reset_index(drop=True)\n",
        "        max_0['Case'] = i\n",
        "        gen_data_new['Case'] = i\n",
        "        gen_data_new['DAT'] = day \n",
        "        gan_data = make_data(gen_data_new, max_0, day)\n",
        "        y_pred = predict_model.predict(gan_data)\n",
        "        max_list.append(y_pred.max())\n",
        "    max_list = pd.DataFrame(max_list)\n",
        "    print(max_list.max())\n",
        "    idx_max = max_list.idxmax()\n",
        "    gen_dat = gen_data[int(idx_max.values)*24:(int(idx_max.values)+1)*24]\n",
        "    gen_dat['DAT'] = day\n",
        "    con_dat = pd.concat([max_0, gen_dat], axis=0)\n",
        "    con_dat.to_csv(\"/content/drive/MyDrive/Project_L/fix.csv\", index=False)\n",
        "    print(f'{day}일차 End------------------------------')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
