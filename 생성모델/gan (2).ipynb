{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cygy69N84Gk"
      },
      "source": [
        "# grg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS1qnZGD8smn",
        "outputId": "f4ce100a-2836-4969-efa3-fe304cb552e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  8 04:10:58 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rv-Bjso8skF",
        "outputId": "01393fbe-2e3c-475d-f893-a593ac6bcbc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Fd1r4y8shy",
        "outputId": "edf8579b-6c78-4863-a0c7-288282faf16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoM8KXCv82Er"
      },
      "source": [
        "# gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wBRWQnVp-ifk"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "def preprocessing(input_path):\n",
        "    all_input_list = sorted(glob.glob(input_path))\n",
        "    train = pd.DataFrame()\n",
        "    for datapath in all_input_list:\n",
        "        data = pd.read_csv(datapath) \n",
        "  \n",
        "        data['obs_time'] = data.index % 24 \n",
        "        df = abs(data)\n",
        "        df.loc[(df['내부온도관측치'] > 40), '내부온도관측치'] = 40\n",
        "        df.loc[(df['내부습도관측치'] > 100), '내부습도관측치'] = 100\n",
        "        df.loc[(df['co2관측치'] > 1200), 'co2관측치'] = 1200\n",
        "        df.loc[(df['ec관측치'] > 8), 'ec관측치'] = 8\n",
        "        df.loc[(df['시간당분무량'] > 3000), '시간당분무량'] = 3000\n",
        "        df.loc[(df['시간당백색광량'] > 120000), '시간당백색광량'] = 120000\n",
        "        df.loc[(df['시간당적색광량'] > 120000), '시간당적색광량'] = 120000\n",
        "        df.loc[(df['시간당청색광량'] > 120000), '시간당청색광량'] = 120000\n",
        "        df.loc[(df['시간당총광량'] > 120000), '시간당총광량'] = 120000\n",
        "        df['시간당총광량'] = df['시간당청색광량']+df['시간당백색광량']+df['시간당적색광량']\n",
        "        \n",
        "        col_list = df.columns\n",
        "        for i in range(0,len(col_list)):\n",
        "            col = col_list[i]    \n",
        "            if '누적' in col : \n",
        "                df[col] = df.groupby((df.obs_time == 0).cumsum()).agg(col_list[i-1]).cumsum()   \n",
        "            df.to_csv(datapath,index=False)\n",
        "            train = pd.concat([train,df])\n",
        "    print('finish!!')\n",
        "    return train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0djyR4b8-z7e",
        "outputId": "a27f2f8d-a5f5-425a-fc62-8fbbc69392e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish!!\n"
          ]
        }
      ],
      "source": [
        "traininput = preprocessing('drive/MyDrive/dacon/gan/상추/train_input/*.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day0 = traininput[traininput['DAT']==0].reset_index(drop=True)\n",
        "day0 = day0[['obs_time','내부온도관측치','내부습도관측치','co2관측치','ec관측치','시간당분무량','시간당백색광량','시간당적색광량','시간당청색광량']]\n",
        "day0.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ZwYZ31hm3-CV",
        "outputId": "56301450-094d-4508-91c0-480190523087"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           obs_time       내부온도관측치       내부습도관측치        co2관측치         ec관측치  \\\n",
              "count  10752.000000  10752.000000  10752.000000  10752.000000  10752.000000   \n",
              "mean      11.500000     25.781004     54.912360    533.833783      1.273970   \n",
              "std        6.922508      4.361793     12.257845    144.127605      0.932456   \n",
              "min        0.000000      0.000000      0.000000     60.400000      0.000000   \n",
              "25%        5.750000     23.595463     49.183641    446.345833      0.401136   \n",
              "50%       11.500000     26.280460     56.510000    505.883333      1.212455   \n",
              "75%       17.250000     28.717917     61.310767    578.400000      2.011237   \n",
              "max       23.000000     39.158823     81.900001   1200.000000      3.034100   \n",
              "\n",
              "             시간당분무량        시간당백색광량       시간당적색광량       시간당청색광량  \n",
              "count  10752.000000   10752.000000  10752.000000  10752.000000  \n",
              "mean     430.609479    6765.408458   1309.564887    856.852189  \n",
              "std      491.308581    9450.283141   2653.722924   1938.172567  \n",
              "min        0.000000       0.000000      0.000000      0.000000  \n",
              "25%        0.000000       0.000000      0.000000      0.000000  \n",
              "50%      242.355000       0.000000      0.000000      0.000000  \n",
              "75%      769.000000   18255.190000    976.332000    135.110625  \n",
              "max     2735.210000  120000.000000   9928.800000  18570.857500  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa7455ff-9b49-4632-bba2-9b2087ff73d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs_time</th>\n",
              "      <th>내부온도관측치</th>\n",
              "      <th>내부습도관측치</th>\n",
              "      <th>co2관측치</th>\n",
              "      <th>ec관측치</th>\n",
              "      <th>시간당분무량</th>\n",
              "      <th>시간당백색광량</th>\n",
              "      <th>시간당적색광량</th>\n",
              "      <th>시간당청색광량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>11.500000</td>\n",
              "      <td>25.781004</td>\n",
              "      <td>54.912360</td>\n",
              "      <td>533.833783</td>\n",
              "      <td>1.273970</td>\n",
              "      <td>430.609479</td>\n",
              "      <td>6765.408458</td>\n",
              "      <td>1309.564887</td>\n",
              "      <td>856.852189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.922508</td>\n",
              "      <td>4.361793</td>\n",
              "      <td>12.257845</td>\n",
              "      <td>144.127605</td>\n",
              "      <td>0.932456</td>\n",
              "      <td>491.308581</td>\n",
              "      <td>9450.283141</td>\n",
              "      <td>2653.722924</td>\n",
              "      <td>1938.172567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.750000</td>\n",
              "      <td>23.595463</td>\n",
              "      <td>49.183641</td>\n",
              "      <td>446.345833</td>\n",
              "      <td>0.401136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.500000</td>\n",
              "      <td>26.280460</td>\n",
              "      <td>56.510000</td>\n",
              "      <td>505.883333</td>\n",
              "      <td>1.212455</td>\n",
              "      <td>242.355000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17.250000</td>\n",
              "      <td>28.717917</td>\n",
              "      <td>61.310767</td>\n",
              "      <td>578.400000</td>\n",
              "      <td>2.011237</td>\n",
              "      <td>769.000000</td>\n",
              "      <td>18255.190000</td>\n",
              "      <td>976.332000</td>\n",
              "      <td>135.110625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>39.158823</td>\n",
              "      <td>81.900001</td>\n",
              "      <td>1200.000000</td>\n",
              "      <td>3.034100</td>\n",
              "      <td>2735.210000</td>\n",
              "      <td>120000.000000</td>\n",
              "      <td>9928.800000</td>\n",
              "      <td>18570.857500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa7455ff-9b49-4632-bba2-9b2087ff73d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa7455ff-9b49-4632-bba2-9b2087ff73d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa7455ff-9b49-4632-bba2-9b2087ff73d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tbY1c5aUzOWh",
        "outputId": "0e01de5f-a6f1-4325-b1b6-88f2214f8ac0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       obs_time    내부온도관측치    내부습도관측치      co2관측치     ec관측치  시간당분무량  시간당백색광량  \\\n",
              "0             0  25.300000  81.835000  536.016667  1.407439     0.0   0.0000   \n",
              "1             1  25.680357  81.264286  528.696429  1.409003   126.0   0.0000   \n",
              "2             2  25.273333  81.471666  532.833333  1.406913     0.0   0.0000   \n",
              "3             3  25.355000  81.398334  545.566667  1.406689   126.0   0.0000   \n",
              "4             4  25.391667  81.483333  558.583333  1.411070     0.0   0.0000   \n",
              "...         ...        ...        ...         ...       ...     ...      ...   \n",
              "10747        19  29.980000  59.256667  505.466667  1.014238     0.0   9.2823   \n",
              "10748        20  29.730000  59.458333  504.433333  1.017222     0.0   0.0000   \n",
              "10749        21  29.491667  59.801667  501.216667  1.019655   769.0   0.0000   \n",
              "10750        22  29.531667  60.031667  501.400000  1.020756     0.0   0.0000   \n",
              "10751        23  29.349999  60.906667  503.300000  1.022382     0.0   0.0000   \n",
              "\n",
              "       시간당적색광량  시간당청색광량  \n",
              "0          0.0      0.0  \n",
              "1          0.0      0.0  \n",
              "2          0.0      0.0  \n",
              "3          0.0      0.0  \n",
              "4          0.0      0.0  \n",
              "...        ...      ...  \n",
              "10747      0.0      0.0  \n",
              "10748      0.0      0.0  \n",
              "10749      0.0      0.0  \n",
              "10750      0.0      0.0  \n",
              "10751      0.0      0.0  \n",
              "\n",
              "[10752 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b72deac-f47f-4875-a616-9228361f615e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs_time</th>\n",
              "      <th>내부온도관측치</th>\n",
              "      <th>내부습도관측치</th>\n",
              "      <th>co2관측치</th>\n",
              "      <th>ec관측치</th>\n",
              "      <th>시간당분무량</th>\n",
              "      <th>시간당백색광량</th>\n",
              "      <th>시간당적색광량</th>\n",
              "      <th>시간당청색광량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>81.835000</td>\n",
              "      <td>536.016667</td>\n",
              "      <td>1.407439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25.680357</td>\n",
              "      <td>81.264286</td>\n",
              "      <td>528.696429</td>\n",
              "      <td>1.409003</td>\n",
              "      <td>126.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>25.273333</td>\n",
              "      <td>81.471666</td>\n",
              "      <td>532.833333</td>\n",
              "      <td>1.406913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>25.355000</td>\n",
              "      <td>81.398334</td>\n",
              "      <td>545.566667</td>\n",
              "      <td>1.406689</td>\n",
              "      <td>126.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>25.391667</td>\n",
              "      <td>81.483333</td>\n",
              "      <td>558.583333</td>\n",
              "      <td>1.411070</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10747</th>\n",
              "      <td>19</td>\n",
              "      <td>29.980000</td>\n",
              "      <td>59.256667</td>\n",
              "      <td>505.466667</td>\n",
              "      <td>1.014238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.2823</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10748</th>\n",
              "      <td>20</td>\n",
              "      <td>29.730000</td>\n",
              "      <td>59.458333</td>\n",
              "      <td>504.433333</td>\n",
              "      <td>1.017222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10749</th>\n",
              "      <td>21</td>\n",
              "      <td>29.491667</td>\n",
              "      <td>59.801667</td>\n",
              "      <td>501.216667</td>\n",
              "      <td>1.019655</td>\n",
              "      <td>769.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10750</th>\n",
              "      <td>22</td>\n",
              "      <td>29.531667</td>\n",
              "      <td>60.031667</td>\n",
              "      <td>501.400000</td>\n",
              "      <td>1.020756</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10751</th>\n",
              "      <td>23</td>\n",
              "      <td>29.349999</td>\n",
              "      <td>60.906667</td>\n",
              "      <td>503.300000</td>\n",
              "      <td>1.022382</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10752 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b72deac-f47f-4875-a616-9228361f615e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b72deac-f47f-4875-a616-9228361f615e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b72deac-f47f-4875-a616-9228361f615e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "sc = MinMaxScaler()"
      ],
      "metadata": {
        "id": "ZccJOrAWiMCp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.fit(day0)\n",
        "newday0= sc.transform(day0)"
      ],
      "metadata": {
        "id": "_brVsVKuicbW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import hstack\n",
        "from numpy.random import rand\n",
        "from numpy.random import randn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "p2De1F5HFQRT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim \n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# 노이즈 -> 피쳐수만큼\n",
        "# generator input -> 노이즈가 들어감\n",
        "# generator ouput -> real data x 형태로 나와야 함.\n",
        "# discriminator input -> real data x 가 들어감\n",
        "# discriminator output -> 1\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input = 9 \n",
        "    self.output= 1\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input, 16), # input size, hidden size\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(16, 64),\n",
        "        nn.LeakyReLU(0.8),\n",
        "        nn.Linear(64, 128),\n",
        "        nn.LeakyReLU(0.5),\n",
        "        nn.Linear(128, self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.features = 9 # 피쳐수\n",
        "    self.output = 9  # 데이터수\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.features, 64), # input size, hidden size\n",
        "        nn.Sigmoid(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(64, 16),\n",
        "        #nn.LeakyReLU(0.2),\n",
        "        nn.Linear(16,self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print('generator',x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "# 모델 정의\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
        "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
        "\n",
        "criterion = nn.BCELoss().to(device)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=g_optim, mode='min', verbose=True, patience=10, factor=0.5)\n",
        "\n",
        "import time\n",
        "n_epochs = 1000\n",
        "noise = 9\n",
        "start_time = time.time()\n",
        "newdata = []\n",
        "testdata = []\n",
        "#print(real_data)\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  test = day0.iloc[:28].values\n",
        "  \n",
        "  nptonn = torch.from_numpy(newday0).float()\n",
        "\n",
        "  real = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(1.0) # \n",
        "  fake = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(0.0) # \n",
        "\n",
        "  real_data = nptonn.cuda()\n",
        "  g_optim.zero_grad()\n",
        "\n",
        "  z0 = torch.normal(mean=11.5, std=6.9, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z1 = torch.normal(mean=25.78, std=4.3, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z2 = torch.normal(mean=54.91, std=12.2, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z3 = torch.normal(mean=533.833, std=144.1, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z4 = torch.normal(mean=1.273, std=0.932, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z5 = torch.normal(mean=430.600, std=491.308, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z6 = torch.normal(mean=6765.408, std=9450.28, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z7 = torch.normal(mean=1309.564, std=2653.722, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z8 = torch.normal(mean=856.852, std=1938.17, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  zz = torch.normal(mean=0, std=1, size=(nptonn.shape[0], noise)).cuda()\n",
        "\n",
        "  z = torch.cat([z0,z1,z2,z3,z4,z5,z6,z7,z8], dim=1) #[M, N+N, K]\n",
        "  #print(z.size())\n",
        "\n",
        "  generated_dis = generator(z) # create distribution\n",
        "  #print(generated_dis.size())\n",
        "  #print(real_data.size())\n",
        "  generated_dis_value = generated_dis.detach().cpu()\n",
        "  g_loss =  criterion(discriminator(generated_dis), real) # calculate generator loss\n",
        "  \n",
        "  # update generator\n",
        "  g_loss.backward()\n",
        "  g_optim.step()\n",
        "\n",
        "  # update discriminator\n",
        "  real_loss = criterion(discriminator(real_data), real)\n",
        "  r_score = discriminator(real_data).mean()\n",
        "  fake_loss = criterion(discriminator(generated_dis.detach()), fake)\n",
        "  g_score = discriminator(generated_dis).mean()\n",
        "  d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "  newdata.append(generated_dis_value)\n",
        "\n",
        "  d_loss.backward()\n",
        "  d_optim.step()\n",
        "\n",
        "  print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [FAKE loss: {fake_loss.item():.6f}] \",\n",
        "        g_score, r_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QDx8n0j3zYF",
        "outputId": "c85dc3b1-a654-4fc5-fc5f-3f95103bfa0b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/1000] [D loss: 0.695153] [G loss: 0.660646] [FAKE loss: 0.726829]  tensor(0.5165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 1/1000] [D loss: 0.695528] [G loss: 0.653474] [FAKE loss: 0.734561]  tensor(0.5202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 2/1000] [D loss: 0.695631] [G loss: 0.646730] [FAKE loss: 0.742016]  tensor(0.5239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 3/1000] [D loss: 0.695816] [G loss: 0.639743] [FAKE loss: 0.749466]  tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 4/1000] [D loss: 0.696291] [G loss: 0.633179] [FAKE loss: 0.757242]  tensor(0.5311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 5/1000] [D loss: 0.696843] [G loss: 0.626081] [FAKE loss: 0.765147]  tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 6/1000] [D loss: 0.697194] [G loss: 0.619188] [FAKE loss: 0.773098]  tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 7/1000] [D loss: 0.697970] [G loss: 0.612480] [FAKE loss: 0.781469]  tensor(0.5422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 8/1000] [D loss: 0.698570] [G loss: 0.605179] [FAKE loss: 0.789640]  tensor(0.5458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 9/1000] [D loss: 0.699543] [G loss: 0.598266] [FAKE loss: 0.798608]  tensor(0.5498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 10/1000] [D loss: 0.700085] [G loss: 0.590925] [FAKE loss: 0.807094]  tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 11/1000] [D loss: 0.701065] [G loss: 0.584145] [FAKE loss: 0.816016]  tensor(0.5579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 12/1000] [D loss: 0.701901] [G loss: 0.576649] [FAKE loss: 0.824900]  tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 13/1000] [D loss: 0.703040] [G loss: 0.569246] [FAKE loss: 0.834467]  tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 14/1000] [D loss: 0.704354] [G loss: 0.562049] [FAKE loss: 0.844518]  tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 15/1000] [D loss: 0.705693] [G loss: 0.554732] [FAKE loss: 0.854494]  tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 16/1000] [D loss: 0.706994] [G loss: 0.547140] [FAKE loss: 0.864883]  tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 17/1000] [D loss: 0.708710] [G loss: 0.539508] [FAKE loss: 0.875629]  tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 18/1000] [D loss: 0.710205] [G loss: 0.531866] [FAKE loss: 0.885885]  tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 19/1000] [D loss: 0.712070] [G loss: 0.524422] [FAKE loss: 0.897524]  tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 20/1000] [D loss: 0.714116] [G loss: 0.516829] [FAKE loss: 0.909024]  tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 21/1000] [D loss: 0.715543] [G loss: 0.508997] [FAKE loss: 0.920053]  tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 22/1000] [D loss: 0.717704] [G loss: 0.500995] [FAKE loss: 0.931644]  tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 23/1000] [D loss: 0.720146] [G loss: 0.493184] [FAKE loss: 0.944323]  tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 24/1000] [D loss: 0.722422] [G loss: 0.485349] [FAKE loss: 0.956672]  tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 25/1000] [D loss: 0.725131] [G loss: 0.477545] [FAKE loss: 0.969721]  tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 26/1000] [D loss: 0.727583] [G loss: 0.469686] [FAKE loss: 0.982735]  tensor(0.6256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 27/1000] [D loss: 0.730454] [G loss: 0.461455] [FAKE loss: 0.996143]  tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 28/1000] [D loss: 0.733696] [G loss: 0.453187] [FAKE loss: 1.010502]  tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 29/1000] [D loss: 0.736817] [G loss: 0.445499] [FAKE loss: 1.024282]  tensor(0.6403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 30/1000] [D loss: 0.740764] [G loss: 0.437297] [FAKE loss: 1.040126]  tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 31/1000] [D loss: 0.744133] [G loss: 0.429526] [FAKE loss: 1.054688]  tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 32/1000] [D loss: 0.747349] [G loss: 0.420973] [FAKE loss: 1.069375]  tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 33/1000] [D loss: 0.751667] [G loss: 0.413450] [FAKE loss: 1.085577]  tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 34/1000] [D loss: 0.755451] [G loss: 0.406227] [FAKE loss: 1.100695]  tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 35/1000] [D loss: 0.760709] [G loss: 0.397144] [FAKE loss: 1.119159]  tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 36/1000] [D loss: 0.765121] [G loss: 0.389148] [FAKE loss: 1.135329]  tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 37/1000] [D loss: 0.769763] [G loss: 0.381113] [FAKE loss: 1.153191]  tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 38/1000] [D loss: 0.774422] [G loss: 0.373834] [FAKE loss: 1.169647]  tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 39/1000] [D loss: 0.780255] [G loss: 0.365207] [FAKE loss: 1.188819]  tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 40/1000] [D loss: 0.785456] [G loss: 0.357181] [FAKE loss: 1.207524]  tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 41/1000] [D loss: 0.791251] [G loss: 0.349394] [FAKE loss: 1.226875]  tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 42/1000] [D loss: 0.797344] [G loss: 0.341091] [FAKE loss: 1.245617]  tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 43/1000] [D loss: 0.804168] [G loss: 0.333698] [FAKE loss: 1.266161]  tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 44/1000] [D loss: 0.810185] [G loss: 0.325867] [FAKE loss: 1.285997]  tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 45/1000] [D loss: 0.816464] [G loss: 0.318197] [FAKE loss: 1.305986]  tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 46/1000] [D loss: 0.822430] [G loss: 0.310526] [FAKE loss: 1.325827]  tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 47/1000] [D loss: 0.830792] [G loss: 0.303559] [FAKE loss: 1.348910]  tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 48/1000] [D loss: 0.837381] [G loss: 0.295261] [FAKE loss: 1.369765]  tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 49/1000] [D loss: 0.845607] [G loss: 0.288382] [FAKE loss: 1.392783]  tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 50/1000] [D loss: 0.852205] [G loss: 0.281112] [FAKE loss: 1.413597]  tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 51/1000] [D loss: 0.860619] [G loss: 0.273895] [FAKE loss: 1.437408]  tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 52/1000] [D loss: 0.868635] [G loss: 0.266890] [FAKE loss: 1.459381]  tensor(0.7658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 53/1000] [D loss: 0.877748] [G loss: 0.260225] [FAKE loss: 1.484857]  tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 54/1000] [D loss: 0.885136] [G loss: 0.253617] [FAKE loss: 1.505511]  tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 55/1000] [D loss: 0.894501] [G loss: 0.247592] [FAKE loss: 1.531622]  tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 56/1000] [D loss: 0.903367] [G loss: 0.240088] [FAKE loss: 1.555457]  tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 57/1000] [D loss: 0.913718] [G loss: 0.233988] [FAKE loss: 1.581797]  tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 58/1000] [D loss: 0.921923] [G loss: 0.228145] [FAKE loss: 1.604641]  tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 59/1000] [D loss: 0.931747] [G loss: 0.221453] [FAKE loss: 1.630671]  tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 60/1000] [D loss: 0.940028] [G loss: 0.215741] [FAKE loss: 1.651734]  tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 61/1000] [D loss: 0.950003] [G loss: 0.210668] [FAKE loss: 1.677318]  tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 62/1000] [D loss: 0.959781] [G loss: 0.205620] [FAKE loss: 1.702190]  tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 63/1000] [D loss: 0.970813] [G loss: 0.199480] [FAKE loss: 1.728982]  tensor(0.8196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 64/1000] [D loss: 0.977889] [G loss: 0.194812] [FAKE loss: 1.748678]  tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 65/1000] [D loss: 0.987765] [G loss: 0.190342] [FAKE loss: 1.773480]  tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 66/1000] [D loss: 0.998202] [G loss: 0.184824] [FAKE loss: 1.799230]  tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 67/1000] [D loss: 1.007169] [G loss: 0.181131] [FAKE loss: 1.820869]  tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 68/1000] [D loss: 1.015661] [G loss: 0.177114] [FAKE loss: 1.842740]  tensor(0.8384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 69/1000] [D loss: 1.024206] [G loss: 0.173305] [FAKE loss: 1.863737]  tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 70/1000] [D loss: 1.031767] [G loss: 0.169447] [FAKE loss: 1.883034]  tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 71/1000] [D loss: 1.039273] [G loss: 0.166378] [FAKE loss: 1.901268]  tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 72/1000] [D loss: 1.048354] [G loss: 0.162613] [FAKE loss: 1.922387]  tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 73/1000] [D loss: 1.057418] [G loss: 0.159745] [FAKE loss: 1.943681]  tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 74/1000] [D loss: 1.062315] [G loss: 0.156870] [FAKE loss: 1.956956]  tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 75/1000] [D loss: 1.068635] [G loss: 0.154746] [FAKE loss: 1.972462]  tensor(0.8585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 76/1000] [D loss: 1.076984] [G loss: 0.152061] [FAKE loss: 1.991045]  tensor(0.8594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 77/1000] [D loss: 1.081769] [G loss: 0.150019] [FAKE loss: 2.003450]  tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 78/1000] [D loss: 1.087559] [G loss: 0.147896] [FAKE loss: 2.015893]  tensor(0.8632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 79/1000] [D loss: 1.089455] [G loss: 0.145322] [FAKE loss: 2.022254]  tensor(0.8647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 80/1000] [D loss: 1.095090] [G loss: 0.144991] [FAKE loss: 2.035239]  tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 81/1000] [D loss: 1.096341] [G loss: 0.143966] [FAKE loss: 2.039401]  tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 82/1000] [D loss: 1.099358] [G loss: 0.142990] [FAKE loss: 2.047230]  tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 83/1000] [D loss: 1.101432] [G loss: 0.142260] [FAKE loss: 2.050960]  tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 84/1000] [D loss: 1.104095] [G loss: 0.141735] [FAKE loss: 2.057484]  tensor(0.8684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 85/1000] [D loss: 1.106037] [G loss: 0.141380] [FAKE loss: 2.062027]  tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 86/1000] [D loss: 1.102906] [G loss: 0.142391] [FAKE loss: 2.055866]  tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 87/1000] [D loss: 1.102540] [G loss: 0.141218] [FAKE loss: 2.055137]  tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 88/1000] [D loss: 1.102295] [G loss: 0.142052] [FAKE loss: 2.054769]  tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 89/1000] [D loss: 1.099504] [G loss: 0.142816] [FAKE loss: 2.048126]  tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 90/1000] [D loss: 1.096173] [G loss: 0.143109] [FAKE loss: 2.041291]  tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 91/1000] [D loss: 1.094198] [G loss: 0.145088] [FAKE loss: 2.036724]  tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 92/1000] [D loss: 1.089848] [G loss: 0.145856] [FAKE loss: 2.026736]  tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 93/1000] [D loss: 1.083861] [G loss: 0.147057] [FAKE loss: 2.013337]  tensor(0.8637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 94/1000] [D loss: 1.081013] [G loss: 0.149849] [FAKE loss: 2.006777]  tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 95/1000] [D loss: 1.074351] [G loss: 0.150917] [FAKE loss: 1.992170]  tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 96/1000] [D loss: 1.068845] [G loss: 0.153053] [FAKE loss: 1.979403]  tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 97/1000] [D loss: 1.064071] [G loss: 0.155647] [FAKE loss: 1.967410]  tensor(0.8566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 98/1000] [D loss: 1.057733] [G loss: 0.157143] [FAKE loss: 1.953120]  tensor(0.8550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 99/1000] [D loss: 1.050426] [G loss: 0.160232] [FAKE loss: 1.935973]  tensor(0.8523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 100/1000] [D loss: 1.042074] [G loss: 0.163131] [FAKE loss: 1.917175]  tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 101/1000] [D loss: 1.036970] [G loss: 0.166137] [FAKE loss: 1.903890]  tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 102/1000] [D loss: 1.029505] [G loss: 0.168806] [FAKE loss: 1.885756]  tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 103/1000] [D loss: 1.019245] [G loss: 0.172941] [FAKE loss: 1.862638]  tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 104/1000] [D loss: 1.010866] [G loss: 0.175952] [FAKE loss: 1.843115]  tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 105/1000] [D loss: 1.004334] [G loss: 0.180461] [FAKE loss: 1.826661]  tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 106/1000] [D loss: 0.995224] [G loss: 0.184334] [FAKE loss: 1.805510]  tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 107/1000] [D loss: 0.986830] [G loss: 0.188349] [FAKE loss: 1.784141]  tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 108/1000] [D loss: 0.977642] [G loss: 0.192799] [FAKE loss: 1.762331]  tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 109/1000] [D loss: 0.970894] [G loss: 0.196935] [FAKE loss: 1.744153]  tensor(0.8213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 110/1000] [D loss: 0.961301] [G loss: 0.201091] [FAKE loss: 1.721488]  tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 111/1000] [D loss: 0.952103] [G loss: 0.205768] [FAKE loss: 1.699063]  tensor(0.8151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 112/1000] [D loss: 0.943454] [G loss: 0.211584] [FAKE loss: 1.676781]  tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 113/1000] [D loss: 0.936630] [G loss: 0.216763] [FAKE loss: 1.658605]  tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 114/1000] [D loss: 0.927233] [G loss: 0.221844] [FAKE loss: 1.635092]  tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 115/1000] [D loss: 0.919275] [G loss: 0.226573] [FAKE loss: 1.615037]  tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 116/1000] [D loss: 0.910063] [G loss: 0.231115] [FAKE loss: 1.591078]  tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 117/1000] [D loss: 0.901321] [G loss: 0.236599] [FAKE loss: 1.569507]  tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 118/1000] [D loss: 0.893892] [G loss: 0.241985] [FAKE loss: 1.548675]  tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 119/1000] [D loss: 0.886816] [G loss: 0.248559] [FAKE loss: 1.529908]  tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 120/1000] [D loss: 0.877432] [G loss: 0.254309] [FAKE loss: 1.506143]  tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 121/1000] [D loss: 0.870527] [G loss: 0.259764] [FAKE loss: 1.486779]  tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 122/1000] [D loss: 0.863724] [G loss: 0.265713] [FAKE loss: 1.466992]  tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 123/1000] [D loss: 0.856239] [G loss: 0.272025] [FAKE loss: 1.446334]  tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 124/1000] [D loss: 0.849834] [G loss: 0.277294] [FAKE loss: 1.428024]  tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 125/1000] [D loss: 0.843039] [G loss: 0.284041] [FAKE loss: 1.409027]  tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 126/1000] [D loss: 0.836892] [G loss: 0.289731] [FAKE loss: 1.390560]  tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 127/1000] [D loss: 0.829976] [G loss: 0.295710] [FAKE loss: 1.371006]  tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 128/1000] [D loss: 0.824150] [G loss: 0.302452] [FAKE loss: 1.353786]  tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 129/1000] [D loss: 0.818497] [G loss: 0.308860] [FAKE loss: 1.336820]  tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 130/1000] [D loss: 0.813539] [G loss: 0.314149] [FAKE loss: 1.320122]  tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 131/1000] [D loss: 0.806161] [G loss: 0.321020] [FAKE loss: 1.300930]  tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 132/1000] [D loss: 0.802615] [G loss: 0.326333] [FAKE loss: 1.286180]  tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 133/1000] [D loss: 0.796296] [G loss: 0.332486] [FAKE loss: 1.269105]  tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 134/1000] [D loss: 0.792286] [G loss: 0.338818] [FAKE loss: 1.254342]  tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 135/1000] [D loss: 0.787323] [G loss: 0.345230] [FAKE loss: 1.238765]  tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 136/1000] [D loss: 0.782583] [G loss: 0.350883] [FAKE loss: 1.223683]  tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 137/1000] [D loss: 0.779233] [G loss: 0.357011] [FAKE loss: 1.210725]  tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 138/1000] [D loss: 0.774992] [G loss: 0.362753] [FAKE loss: 1.196696]  tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 139/1000] [D loss: 0.770112] [G loss: 0.368565] [FAKE loss: 1.181301]  tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 140/1000] [D loss: 0.766860] [G loss: 0.373919] [FAKE loss: 1.168892]  tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 141/1000] [D loss: 0.764093] [G loss: 0.379835] [FAKE loss: 1.156918]  tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 142/1000] [D loss: 0.760252] [G loss: 0.385625] [FAKE loss: 1.144117]  tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 143/1000] [D loss: 0.756545] [G loss: 0.391023] [FAKE loss: 1.130871]  tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 144/1000] [D loss: 0.753981] [G loss: 0.396894] [FAKE loss: 1.121394]  tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 145/1000] [D loss: 0.751530] [G loss: 0.402669] [FAKE loss: 1.110612]  tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 146/1000] [D loss: 0.748735] [G loss: 0.406924] [FAKE loss: 1.099185]  tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 147/1000] [D loss: 0.745624] [G loss: 0.411935] [FAKE loss: 1.088528]  tensor(0.6629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 148/1000] [D loss: 0.744203] [G loss: 0.416943] [FAKE loss: 1.079798]  tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 149/1000] [D loss: 0.742400] [G loss: 0.422553] [FAKE loss: 1.070337]  tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 150/1000] [D loss: 0.739910] [G loss: 0.426760] [FAKE loss: 1.061558]  tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 151/1000] [D loss: 0.738322] [G loss: 0.430699] [FAKE loss: 1.053248]  tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 152/1000] [D loss: 0.735456] [G loss: 0.435463] [FAKE loss: 1.043184]  tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 153/1000] [D loss: 0.734425] [G loss: 0.439476] [FAKE loss: 1.036443]  tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 154/1000] [D loss: 0.733190] [G loss: 0.443602] [FAKE loss: 1.029462]  tensor(0.6423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 155/1000] [D loss: 0.731760] [G loss: 0.446954] [FAKE loss: 1.022079]  tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 156/1000] [D loss: 0.730697] [G loss: 0.450910] [FAKE loss: 1.015345]  tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 157/1000] [D loss: 0.729742] [G loss: 0.454691] [FAKE loss: 1.009718]  tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 158/1000] [D loss: 0.728460] [G loss: 0.457866] [FAKE loss: 1.003190]  tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 159/1000] [D loss: 0.727648] [G loss: 0.461988] [FAKE loss: 0.997592]  tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 160/1000] [D loss: 0.727224] [G loss: 0.464828] [FAKE loss: 0.993174]  tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 161/1000] [D loss: 0.725523] [G loss: 0.467228] [FAKE loss: 0.986295]  tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 162/1000] [D loss: 0.725115] [G loss: 0.470547] [FAKE loss: 0.982471]  tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 163/1000] [D loss: 0.724659] [G loss: 0.472893] [FAKE loss: 0.978189]  tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 164/1000] [D loss: 0.724347] [G loss: 0.475382] [FAKE loss: 0.974432]  tensor(0.6220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 165/1000] [D loss: 0.723701] [G loss: 0.477759] [FAKE loss: 0.969979]  tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 166/1000] [D loss: 0.723628] [G loss: 0.479600] [FAKE loss: 0.967464]  tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 167/1000] [D loss: 0.722754] [G loss: 0.481657] [FAKE loss: 0.963406]  tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 168/1000] [D loss: 0.722870] [G loss: 0.483307] [FAKE loss: 0.960239]  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 169/1000] [D loss: 0.722560] [G loss: 0.485203] [FAKE loss: 0.958030]  tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 170/1000] [D loss: 0.722869] [G loss: 0.486680] [FAKE loss: 0.956482]  tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 171/1000] [D loss: 0.722296] [G loss: 0.487603] [FAKE loss: 0.953526]  tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 172/1000] [D loss: 0.722487] [G loss: 0.488815] [FAKE loss: 0.952095]  tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 173/1000] [D loss: 0.722115] [G loss: 0.489479] [FAKE loss: 0.949901]  tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 174/1000] [D loss: 0.722885] [G loss: 0.491348] [FAKE loss: 0.949128]  tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 175/1000] [D loss: 0.722581] [G loss: 0.491435] [FAKE loss: 0.947563]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 176/1000] [D loss: 0.722783] [G loss: 0.491314] [FAKE loss: 0.946820]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 177/1000] [D loss: 0.722957] [G loss: 0.492256] [FAKE loss: 0.946138]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 178/1000] [D loss: 0.723237] [G loss: 0.492188] [FAKE loss: 0.946324]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 179/1000] [D loss: 0.723958] [G loss: 0.492153] [FAKE loss: 0.946664]  tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 180/1000] [D loss: 0.723697] [G loss: 0.492224] [FAKE loss: 0.945829]  tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 181/1000] [D loss: 0.724749] [G loss: 0.491770] [FAKE loss: 0.947290]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 182/1000] [D loss: 0.724729] [G loss: 0.491715] [FAKE loss: 0.947197]  tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 183/1000] [D loss: 0.725095] [G loss: 0.490797] [FAKE loss: 0.947905]  tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 184/1000] [D loss: 0.725394] [G loss: 0.490160] [FAKE loss: 0.949062]  tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 185/1000] [D loss: 0.726352] [G loss: 0.489310] [FAKE loss: 0.950618]  tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 186/1000] [D loss: 0.727337] [G loss: 0.488287] [FAKE loss: 0.952279]  tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 187/1000] [D loss: 0.727941] [G loss: 0.487148] [FAKE loss: 0.954692]  tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 188/1000] [D loss: 0.728917] [G loss: 0.485653] [FAKE loss: 0.956841]  tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 189/1000] [D loss: 0.729345] [G loss: 0.483999] [FAKE loss: 0.959251]  tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 190/1000] [D loss: 0.729726] [G loss: 0.482491] [FAKE loss: 0.960735]  tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 191/1000] [D loss: 0.730817] [G loss: 0.481310] [FAKE loss: 0.963884]  tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 192/1000] [D loss: 0.732000] [G loss: 0.479007] [FAKE loss: 0.967789]  tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 193/1000] [D loss: 0.732937] [G loss: 0.477266] [FAKE loss: 0.970197]  tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 194/1000] [D loss: 0.734239] [G loss: 0.475036] [FAKE loss: 0.974477]  tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 195/1000] [D loss: 0.734848] [G loss: 0.473001] [FAKE loss: 0.977101]  tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 196/1000] [D loss: 0.736716] [G loss: 0.470153] [FAKE loss: 0.981796]  tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 197/1000] [D loss: 0.737478] [G loss: 0.468015] [FAKE loss: 0.985858]  tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 198/1000] [D loss: 0.738373] [G loss: 0.465359] [FAKE loss: 0.989748]  tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 199/1000] [D loss: 0.739953] [G loss: 0.462617] [FAKE loss: 0.994230]  tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 200/1000] [D loss: 0.741383] [G loss: 0.459916] [FAKE loss: 0.999230]  tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 201/1000] [D loss: 0.742463] [G loss: 0.457804] [FAKE loss: 1.003659]  tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 202/1000] [D loss: 0.744065] [G loss: 0.454349] [FAKE loss: 1.009305]  tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 203/1000] [D loss: 0.745208] [G loss: 0.451404] [FAKE loss: 1.014263]  tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 204/1000] [D loss: 0.746905] [G loss: 0.448377] [FAKE loss: 1.019602]  tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 205/1000] [D loss: 0.748230] [G loss: 0.445108] [FAKE loss: 1.024823]  tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 206/1000] [D loss: 0.750441] [G loss: 0.441286] [FAKE loss: 1.031750]  tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 207/1000] [D loss: 0.752228] [G loss: 0.438682] [FAKE loss: 1.038075]  tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 208/1000] [D loss: 0.753833] [G loss: 0.435125] [FAKE loss: 1.044185]  tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 209/1000] [D loss: 0.755713] [G loss: 0.431881] [FAKE loss: 1.050543]  tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 210/1000] [D loss: 0.757959] [G loss: 0.427842] [FAKE loss: 1.057682]  tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 211/1000] [D loss: 0.759937] [G loss: 0.423868] [FAKE loss: 1.064690]  tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 212/1000] [D loss: 0.761506] [G loss: 0.420372] [FAKE loss: 1.071212]  tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 213/1000] [D loss: 0.763509] [G loss: 0.416461] [FAKE loss: 1.078048]  tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 214/1000] [D loss: 0.766016] [G loss: 0.412897] [FAKE loss: 1.086288]  tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 215/1000] [D loss: 0.767786] [G loss: 0.408744] [FAKE loss: 1.093127]  tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 216/1000] [D loss: 0.770617] [G loss: 0.405027] [FAKE loss: 1.101419]  tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 217/1000] [D loss: 0.772715] [G loss: 0.400722] [FAKE loss: 1.109324]  tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 218/1000] [D loss: 0.775159] [G loss: 0.396698] [FAKE loss: 1.117517]  tensor(0.6726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 219/1000] [D loss: 0.778015] [G loss: 0.392983] [FAKE loss: 1.126469]  tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 220/1000] [D loss: 0.780423] [G loss: 0.388742] [FAKE loss: 1.135648]  tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 221/1000] [D loss: 0.783749] [G loss: 0.384032] [FAKE loss: 1.145450]  tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 222/1000] [D loss: 0.786540] [G loss: 0.380011] [FAKE loss: 1.154268]  tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 223/1000] [D loss: 0.788973] [G loss: 0.375800] [FAKE loss: 1.163286]  tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 224/1000] [D loss: 0.792205] [G loss: 0.371357] [FAKE loss: 1.172842]  tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 225/1000] [D loss: 0.795605] [G loss: 0.366937] [FAKE loss: 1.183073]  tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 226/1000] [D loss: 0.798247] [G loss: 0.362273] [FAKE loss: 1.192544]  tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 227/1000] [D loss: 0.802220] [G loss: 0.358262] [FAKE loss: 1.204322]  tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 228/1000] [D loss: 0.805100] [G loss: 0.353687] [FAKE loss: 1.213806]  tensor(0.7022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 229/1000] [D loss: 0.808739] [G loss: 0.349404] [FAKE loss: 1.224452]  tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 230/1000] [D loss: 0.812473] [G loss: 0.344956] [FAKE loss: 1.235155]  tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 231/1000] [D loss: 0.816157] [G loss: 0.340372] [FAKE loss: 1.246584]  tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 232/1000] [D loss: 0.820496] [G loss: 0.335485] [FAKE loss: 1.259095]  tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 233/1000] [D loss: 0.823802] [G loss: 0.330754] [FAKE loss: 1.269690]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 234/1000] [D loss: 0.827496] [G loss: 0.326659] [FAKE loss: 1.280827]  tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 235/1000] [D loss: 0.831836] [G loss: 0.322438] [FAKE loss: 1.293058]  tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 236/1000] [D loss: 0.835769] [G loss: 0.317582] [FAKE loss: 1.304895]  tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 237/1000] [D loss: 0.840003] [G loss: 0.313161] [FAKE loss: 1.317042]  tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 238/1000] [D loss: 0.843761] [G loss: 0.308132] [FAKE loss: 1.328507]  tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 239/1000] [D loss: 0.849146] [G loss: 0.303858] [FAKE loss: 1.343428]  tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 240/1000] [D loss: 0.852970] [G loss: 0.299565] [FAKE loss: 1.354680]  tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 241/1000] [D loss: 0.857414] [G loss: 0.295232] [FAKE loss: 1.367428]  tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 242/1000] [D loss: 0.862773] [G loss: 0.290614] [FAKE loss: 1.381432]  tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 243/1000] [D loss: 0.868035] [G loss: 0.285825] [FAKE loss: 1.395803]  tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 244/1000] [D loss: 0.872566] [G loss: 0.281883] [FAKE loss: 1.408767]  tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 245/1000] [D loss: 0.878074] [G loss: 0.277077] [FAKE loss: 1.423648]  tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 246/1000] [D loss: 0.882926] [G loss: 0.272800] [FAKE loss: 1.437208]  tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 247/1000] [D loss: 0.888553] [G loss: 0.268549] [FAKE loss: 1.452016]  tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 248/1000] [D loss: 0.893335] [G loss: 0.264250] [FAKE loss: 1.465028]  tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 249/1000] [D loss: 0.898688] [G loss: 0.260311] [FAKE loss: 1.479630]  tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 250/1000] [D loss: 0.904207] [G loss: 0.256293] [FAKE loss: 1.494359]  tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 251/1000] [D loss: 0.908703] [G loss: 0.252341] [FAKE loss: 1.506462]  tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 252/1000] [D loss: 0.913321] [G loss: 0.248753] [FAKE loss: 1.519275]  tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 253/1000] [D loss: 0.918996] [G loss: 0.244977] [FAKE loss: 1.534163]  tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 254/1000] [D loss: 0.923498] [G loss: 0.241541] [FAKE loss: 1.546420]  tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 255/1000] [D loss: 0.928216] [G loss: 0.237627] [FAKE loss: 1.559692]  tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 256/1000] [D loss: 0.933405] [G loss: 0.234608] [FAKE loss: 1.573132]  tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 257/1000] [D loss: 0.937883] [G loss: 0.231271] [FAKE loss: 1.585420]  tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 258/1000] [D loss: 0.942059] [G loss: 0.228441] [FAKE loss: 1.596975]  tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 259/1000] [D loss: 0.947710] [G loss: 0.224774] [FAKE loss: 1.611459]  tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 260/1000] [D loss: 0.951690] [G loss: 0.222064] [FAKE loss: 1.621791]  tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 261/1000] [D loss: 0.956235] [G loss: 0.218811] [FAKE loss: 1.634540]  tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 262/1000] [D loss: 0.960146] [G loss: 0.216148] [FAKE loss: 1.645854]  tensor(0.8058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 263/1000] [D loss: 0.964228] [G loss: 0.213351] [FAKE loss: 1.655885]  tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 264/1000] [D loss: 0.968277] [G loss: 0.211451] [FAKE loss: 1.666426]  tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 265/1000] [D loss: 0.972500] [G loss: 0.208566] [FAKE loss: 1.678252]  tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 266/1000] [D loss: 0.978086] [G loss: 0.206682] [FAKE loss: 1.691496]  tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 267/1000] [D loss: 0.978175] [G loss: 0.204223] [FAKE loss: 1.694756]  tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 268/1000] [D loss: 0.983228] [G loss: 0.201477] [FAKE loss: 1.706844]  tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 269/1000] [D loss: 0.986511] [G loss: 0.199781] [FAKE loss: 1.716196]  tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 270/1000] [D loss: 0.990087] [G loss: 0.198250] [FAKE loss: 1.725365]  tensor(0.8206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 271/1000] [D loss: 0.992842] [G loss: 0.196456] [FAKE loss: 1.733906]  tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 272/1000] [D loss: 0.996190] [G loss: 0.195100] [FAKE loss: 1.742373]  tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 273/1000] [D loss: 0.998609] [G loss: 0.193382] [FAKE loss: 1.749084]  tensor(0.8244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 274/1000] [D loss: 1.000209] [G loss: 0.191451] [FAKE loss: 1.754184]  tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 275/1000] [D loss: 1.001932] [G loss: 0.190782] [FAKE loss: 1.759706]  tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 276/1000] [D loss: 1.005535] [G loss: 0.189430] [FAKE loss: 1.768540]  tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 277/1000] [D loss: 1.005614] [G loss: 0.187930] [FAKE loss: 1.770551]  tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 278/1000] [D loss: 1.008482] [G loss: 0.187144] [FAKE loss: 1.777373]  tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 279/1000] [D loss: 1.010114] [G loss: 0.186822] [FAKE loss: 1.781812]  tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 280/1000] [D loss: 1.010558] [G loss: 0.186191] [FAKE loss: 1.784804]  tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 281/1000] [D loss: 1.012631] [G loss: 0.184970] [FAKE loss: 1.790166]  tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 282/1000] [D loss: 1.012636] [G loss: 0.184448] [FAKE loss: 1.791084]  tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 283/1000] [D loss: 1.013124] [G loss: 0.183650] [FAKE loss: 1.793480]  tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 284/1000] [D loss: 1.013005] [G loss: 0.183601] [FAKE loss: 1.793736]  tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 285/1000] [D loss: 1.012615] [G loss: 0.184208] [FAKE loss: 1.793800]  tensor(0.8324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 286/1000] [D loss: 1.012786] [G loss: 0.183403] [FAKE loss: 1.794688]  tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 287/1000] [D loss: 1.011971] [G loss: 0.183621] [FAKE loss: 1.794085]  tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 288/1000] [D loss: 1.010384] [G loss: 0.184521] [FAKE loss: 1.791467]  tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 289/1000] [D loss: 1.009007] [G loss: 0.184439] [FAKE loss: 1.789593]  tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 290/1000] [D loss: 1.007606] [G loss: 0.185003] [FAKE loss: 1.786761]  tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 291/1000] [D loss: 1.006850] [G loss: 0.186116] [FAKE loss: 1.785136]  tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 292/1000] [D loss: 1.004406] [G loss: 0.186659] [FAKE loss: 1.780745]  tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 293/1000] [D loss: 1.002834] [G loss: 0.186944] [FAKE loss: 1.777686]  tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 294/1000] [D loss: 1.000191] [G loss: 0.187968] [FAKE loss: 1.772455]  tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 295/1000] [D loss: 0.997386] [G loss: 0.188966] [FAKE loss: 1.766157]  tensor(0.8281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 296/1000] [D loss: 0.995013] [G loss: 0.190000] [FAKE loss: 1.761709]  tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 297/1000] [D loss: 0.991639] [G loss: 0.191455] [FAKE loss: 1.754121]  tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 298/1000] [D loss: 0.988208] [G loss: 0.192882] [FAKE loss: 1.746974]  tensor(0.8246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 299/1000] [D loss: 0.986053] [G loss: 0.194070] [FAKE loss: 1.741854]  tensor(0.8234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 300/1000] [D loss: 0.981273] [G loss: 0.196107] [FAKE loss: 1.731804]  tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 301/1000] [D loss: 0.977655] [G loss: 0.198017] [FAKE loss: 1.724155]  tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 302/1000] [D loss: 0.974927] [G loss: 0.200422] [FAKE loss: 1.717419]  tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 303/1000] [D loss: 0.970546] [G loss: 0.201895] [FAKE loss: 1.707684]  tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 304/1000] [D loss: 0.965516] [G loss: 0.204187] [FAKE loss: 1.696947]  tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 305/1000] [D loss: 0.961226] [G loss: 0.206211] [FAKE loss: 1.686785]  tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 306/1000] [D loss: 0.956561] [G loss: 0.208163] [FAKE loss: 1.676612]  tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 307/1000] [D loss: 0.951875] [G loss: 0.211209] [FAKE loss: 1.665532]  tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 308/1000] [D loss: 0.947174] [G loss: 0.213371] [FAKE loss: 1.654855]  tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 309/1000] [D loss: 0.943291] [G loss: 0.216115] [FAKE loss: 1.645411]  tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 310/1000] [D loss: 0.937132] [G loss: 0.218970] [FAKE loss: 1.631459]  tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 311/1000] [D loss: 0.932408] [G loss: 0.221729] [FAKE loss: 1.620515]  tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 312/1000] [D loss: 0.927648] [G loss: 0.224175] [FAKE loss: 1.609006]  tensor(0.7990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 313/1000] [D loss: 0.921815] [G loss: 0.227896] [FAKE loss: 1.595527]  tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 314/1000] [D loss: 0.917233] [G loss: 0.230767] [FAKE loss: 1.584629]  tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 315/1000] [D loss: 0.911430] [G loss: 0.234020] [FAKE loss: 1.570764]  tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 316/1000] [D loss: 0.906861] [G loss: 0.237555] [FAKE loss: 1.559621]  tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 317/1000] [D loss: 0.900360] [G loss: 0.240975] [FAKE loss: 1.544429]  tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 318/1000] [D loss: 0.895775] [G loss: 0.244606] [FAKE loss: 1.533144]  tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 319/1000] [D loss: 0.890280] [G loss: 0.248323] [FAKE loss: 1.519664]  tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 320/1000] [D loss: 0.885404] [G loss: 0.251537] [FAKE loss: 1.507146]  tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 321/1000] [D loss: 0.879788] [G loss: 0.254726] [FAKE loss: 1.493502]  tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 322/1000] [D loss: 0.874130] [G loss: 0.258825] [FAKE loss: 1.479560]  tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 323/1000] [D loss: 0.869289] [G loss: 0.262636] [FAKE loss: 1.467408]  tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 324/1000] [D loss: 0.863950] [G loss: 0.266759] [FAKE loss: 1.454093]  tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 325/1000] [D loss: 0.858855] [G loss: 0.271019] [FAKE loss: 1.440953]  tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 326/1000] [D loss: 0.853755] [G loss: 0.275265] [FAKE loss: 1.427900]  tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 327/1000] [D loss: 0.848167] [G loss: 0.279562] [FAKE loss: 1.413784]  tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 328/1000] [D loss: 0.842578] [G loss: 0.283753] [FAKE loss: 1.399822]  tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 329/1000] [D loss: 0.837794] [G loss: 0.287887] [FAKE loss: 1.387013]  tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 330/1000] [D loss: 0.832664] [G loss: 0.292598] [FAKE loss: 1.373705]  tensor(0.7464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 331/1000] [D loss: 0.827399] [G loss: 0.297232] [FAKE loss: 1.360090]  tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 332/1000] [D loss: 0.822408] [G loss: 0.301123] [FAKE loss: 1.347080]  tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 333/1000] [D loss: 0.816969] [G loss: 0.305949] [FAKE loss: 1.333083]  tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 334/1000] [D loss: 0.812930] [G loss: 0.310641] [FAKE loss: 1.321478]  tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 335/1000] [D loss: 0.808032] [G loss: 0.315599] [FAKE loss: 1.308540]  tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 336/1000] [D loss: 0.803266] [G loss: 0.320054] [FAKE loss: 1.295591]  tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 337/1000] [D loss: 0.798442] [G loss: 0.324620] [FAKE loss: 1.282824]  tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 338/1000] [D loss: 0.794428] [G loss: 0.329523] [FAKE loss: 1.271226]  tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 339/1000] [D loss: 0.789928] [G loss: 0.334490] [FAKE loss: 1.258833]  tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 340/1000] [D loss: 0.785722] [G loss: 0.339245] [FAKE loss: 1.247019]  tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 341/1000] [D loss: 0.781461] [G loss: 0.343761] [FAKE loss: 1.234961]  tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 342/1000] [D loss: 0.776875] [G loss: 0.349060] [FAKE loss: 1.222392]  tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 343/1000] [D loss: 0.773189] [G loss: 0.353759] [FAKE loss: 1.211528]  tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 344/1000] [D loss: 0.769212] [G loss: 0.358620] [FAKE loss: 1.200143]  tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 345/1000] [D loss: 0.765203] [G loss: 0.363154] [FAKE loss: 1.188650]  tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 346/1000] [D loss: 0.761184] [G loss: 0.368217] [FAKE loss: 1.177182]  tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 347/1000] [D loss: 0.757867] [G loss: 0.373242] [FAKE loss: 1.166922]  tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 348/1000] [D loss: 0.754153] [G loss: 0.378035] [FAKE loss: 1.155972]  tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 349/1000] [D loss: 0.750273] [G loss: 0.382913] [FAKE loss: 1.144842]  tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 350/1000] [D loss: 0.747166] [G loss: 0.387945] [FAKE loss: 1.135298]  tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 351/1000] [D loss: 0.743863] [G loss: 0.392430] [FAKE loss: 1.125194]  tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 352/1000] [D loss: 0.740736] [G loss: 0.397434] [FAKE loss: 1.115480]  tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 353/1000] [D loss: 0.737485] [G loss: 0.401987] [FAKE loss: 1.105579]  tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 354/1000] [D loss: 0.734579] [G loss: 0.406594] [FAKE loss: 1.096331]  tensor(0.6659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 355/1000] [D loss: 0.731795] [G loss: 0.411217] [FAKE loss: 1.087373]  tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 356/1000] [D loss: 0.728956] [G loss: 0.415825] [FAKE loss: 1.078509]  tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 357/1000] [D loss: 0.726397] [G loss: 0.420294] [FAKE loss: 1.070024]  tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 358/1000] [D loss: 0.723674] [G loss: 0.424596] [FAKE loss: 1.061475]  tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 359/1000] [D loss: 0.721204] [G loss: 0.429063] [FAKE loss: 1.053298]  tensor(0.6512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 360/1000] [D loss: 0.718642] [G loss: 0.433367] [FAKE loss: 1.045253]  tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 361/1000] [D loss: 0.716431] [G loss: 0.437505] [FAKE loss: 1.037743]  tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 362/1000] [D loss: 0.714308] [G loss: 0.441578] [FAKE loss: 1.030448]  tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 363/1000] [D loss: 0.712218] [G loss: 0.445562] [FAKE loss: 1.023442]  tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 364/1000] [D loss: 0.710151] [G loss: 0.449038] [FAKE loss: 1.016528]  tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 365/1000] [D loss: 0.708286] [G loss: 0.452928] [FAKE loss: 1.010091]  tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 366/1000] [D loss: 0.706411] [G loss: 0.456775] [FAKE loss: 1.003760]  tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 367/1000] [D loss: 0.704702] [G loss: 0.460057] [FAKE loss: 0.997888]  tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 368/1000] [D loss: 0.703135] [G loss: 0.463460] [FAKE loss: 0.992148]  tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 369/1000] [D loss: 0.701398] [G loss: 0.466660] [FAKE loss: 0.986511]  tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 370/1000] [D loss: 0.700051] [G loss: 0.469631] [FAKE loss: 0.981558]  tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 371/1000] [D loss: 0.698652] [G loss: 0.472817] [FAKE loss: 0.976556]  tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 372/1000] [D loss: 0.697472] [G loss: 0.475305] [FAKE loss: 0.972220]  tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 373/1000] [D loss: 0.696177] [G loss: 0.478151] [FAKE loss: 0.967786]  tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 374/1000] [D loss: 0.695002] [G loss: 0.480527] [FAKE loss: 0.964014]  tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 375/1000] [D loss: 0.694069] [G loss: 0.482753] [FAKE loss: 0.960426]  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 376/1000] [D loss: 0.693351] [G loss: 0.484521] [FAKE loss: 0.957452]  tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 377/1000] [D loss: 0.692384] [G loss: 0.486664] [FAKE loss: 0.954307]  tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 378/1000] [D loss: 0.691520] [G loss: 0.488244] [FAKE loss: 0.951356]  tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 379/1000] [D loss: 0.690982] [G loss: 0.489791] [FAKE loss: 0.949417]  tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 380/1000] [D loss: 0.690300] [G loss: 0.490984] [FAKE loss: 0.947352]  tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 381/1000] [D loss: 0.689840] [G loss: 0.492175] [FAKE loss: 0.945552]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 382/1000] [D loss: 0.689213] [G loss: 0.492701] [FAKE loss: 0.943908]  tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 383/1000] [D loss: 0.689075] [G loss: 0.493650] [FAKE loss: 0.943385]  tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 384/1000] [D loss: 0.688667] [G loss: 0.493882] [FAKE loss: 0.942582]  tensor(0.6102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 385/1000] [D loss: 0.688877] [G loss: 0.494214] [FAKE loss: 0.942786]  tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 386/1000] [D loss: 0.688703] [G loss: 0.493718] [FAKE loss: 0.942677]  tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 387/1000] [D loss: 0.688783] [G loss: 0.493858] [FAKE loss: 0.943216]  tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 388/1000] [D loss: 0.688735] [G loss: 0.492877] [FAKE loss: 0.943715]  tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 389/1000] [D loss: 0.689342] [G loss: 0.492324] [FAKE loss: 0.945595]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 390/1000] [D loss: 0.689225] [G loss: 0.491321] [FAKE loss: 0.946585]  tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 391/1000] [D loss: 0.690051] [G loss: 0.490153] [FAKE loss: 0.949265]  tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 392/1000] [D loss: 0.690073] [G loss: 0.488916] [FAKE loss: 0.950964]  tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 393/1000] [D loss: 0.691016] [G loss: 0.486535] [FAKE loss: 0.954307]  tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 394/1000] [D loss: 0.691920] [G loss: 0.485056] [FAKE loss: 0.957504]  tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 395/1000] [D loss: 0.692430] [G loss: 0.482656] [FAKE loss: 0.960674]  tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 396/1000] [D loss: 0.693455] [G loss: 0.479675] [FAKE loss: 0.964690]  tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 397/1000] [D loss: 0.694829] [G loss: 0.477339] [FAKE loss: 0.969826]  tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 398/1000] [D loss: 0.696039] [G loss: 0.474510] [FAKE loss: 0.974828]  tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 399/1000] [D loss: 0.697154] [G loss: 0.470639] [FAKE loss: 0.979833]  tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 400/1000] [D loss: 0.698565] [G loss: 0.467782] [FAKE loss: 0.985322]  tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 401/1000] [D loss: 0.700377] [G loss: 0.463646] [FAKE loss: 0.991905]  tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 402/1000] [D loss: 0.701800] [G loss: 0.460370] [FAKE loss: 0.998121]  tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 403/1000] [D loss: 0.703861] [G loss: 0.456166] [FAKE loss: 1.005575]  tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 404/1000] [D loss: 0.705891] [G loss: 0.451463] [FAKE loss: 1.012988]  tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 405/1000] [D loss: 0.708343] [G loss: 0.446924] [FAKE loss: 1.021403]  tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 406/1000] [D loss: 0.710327] [G loss: 0.442281] [FAKE loss: 1.029345]  tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 407/1000] [D loss: 0.712576] [G loss: 0.437455] [FAKE loss: 1.038074]  tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 408/1000] [D loss: 0.715692] [G loss: 0.432233] [FAKE loss: 1.048072]  tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 409/1000] [D loss: 0.718051] [G loss: 0.427318] [FAKE loss: 1.056963]  tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 410/1000] [D loss: 0.721079] [G loss: 0.421679] [FAKE loss: 1.067674]  tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 411/1000] [D loss: 0.724415] [G loss: 0.415666] [FAKE loss: 1.078735]  tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 412/1000] [D loss: 0.727677] [G loss: 0.409876] [FAKE loss: 1.089871]  tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 413/1000] [D loss: 0.731352] [G loss: 0.404217] [FAKE loss: 1.101722]  tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 414/1000] [D loss: 0.735064] [G loss: 0.398068] [FAKE loss: 1.113913]  tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 415/1000] [D loss: 0.738780] [G loss: 0.392195] [FAKE loss: 1.126162]  tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 416/1000] [D loss: 0.743055] [G loss: 0.385769] [FAKE loss: 1.139513]  tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 417/1000] [D loss: 0.746690] [G loss: 0.380030] [FAKE loss: 1.152168]  tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 418/1000] [D loss: 0.751287] [G loss: 0.373519] [FAKE loss: 1.166247]  tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 419/1000] [D loss: 0.755607] [G loss: 0.367439] [FAKE loss: 1.180172]  tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 420/1000] [D loss: 0.760168] [G loss: 0.361086] [FAKE loss: 1.194119]  tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 421/1000] [D loss: 0.764909] [G loss: 0.355022] [FAKE loss: 1.209050]  tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 422/1000] [D loss: 0.769606] [G loss: 0.348540] [FAKE loss: 1.223611]  tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 423/1000] [D loss: 0.774450] [G loss: 0.342451] [FAKE loss: 1.238736]  tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 424/1000] [D loss: 0.779537] [G loss: 0.336161] [FAKE loss: 1.253925]  tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 425/1000] [D loss: 0.785242] [G loss: 0.329910] [FAKE loss: 1.270636]  tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 426/1000] [D loss: 0.790682] [G loss: 0.323534] [FAKE loss: 1.286991]  tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 427/1000] [D loss: 0.796186] [G loss: 0.317258] [FAKE loss: 1.303080]  tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 428/1000] [D loss: 0.801843] [G loss: 0.311015] [FAKE loss: 1.319904]  tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 429/1000] [D loss: 0.808220] [G loss: 0.304741] [FAKE loss: 1.337816]  tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 430/1000] [D loss: 0.814338] [G loss: 0.298688] [FAKE loss: 1.355260]  tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 431/1000] [D loss: 0.820625] [G loss: 0.292382] [FAKE loss: 1.373057]  tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 432/1000] [D loss: 0.827118] [G loss: 0.286450] [FAKE loss: 1.391076]  tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 433/1000] [D loss: 0.833868] [G loss: 0.280045] [FAKE loss: 1.409839]  tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 434/1000] [D loss: 0.840742] [G loss: 0.274295] [FAKE loss: 1.428349]  tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 435/1000] [D loss: 0.847738] [G loss: 0.268381] [FAKE loss: 1.447391]  tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 436/1000] [D loss: 0.854627] [G loss: 0.262917] [FAKE loss: 1.466111]  tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 437/1000] [D loss: 0.861967] [G loss: 0.256823] [FAKE loss: 1.485889]  tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 438/1000] [D loss: 0.869179] [G loss: 0.251323] [FAKE loss: 1.504798]  tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 439/1000] [D loss: 0.876261] [G loss: 0.245744] [FAKE loss: 1.523731]  tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 440/1000] [D loss: 0.884262] [G loss: 0.240188] [FAKE loss: 1.544306]  tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 441/1000] [D loss: 0.891744] [G loss: 0.235188] [FAKE loss: 1.563871]  tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 442/1000] [D loss: 0.899578] [G loss: 0.229961] [FAKE loss: 1.584048]  tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 443/1000] [D loss: 0.907111] [G loss: 0.224951] [FAKE loss: 1.603234]  tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 444/1000] [D loss: 0.914967] [G loss: 0.220087] [FAKE loss: 1.623317]  tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 445/1000] [D loss: 0.922476] [G loss: 0.215536] [FAKE loss: 1.642592]  tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 446/1000] [D loss: 0.929910] [G loss: 0.210776] [FAKE loss: 1.661417]  tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 447/1000] [D loss: 0.937846] [G loss: 0.206095] [FAKE loss: 1.681387]  tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 448/1000] [D loss: 0.945561] [G loss: 0.201888] [FAKE loss: 1.700555]  tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 449/1000] [D loss: 0.953436] [G loss: 0.197751] [FAKE loss: 1.719868]  tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 450/1000] [D loss: 0.960700] [G loss: 0.193674] [FAKE loss: 1.738029]  tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 451/1000] [D loss: 0.967979] [G loss: 0.189696] [FAKE loss: 1.756179]  tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 452/1000] [D loss: 0.975359] [G loss: 0.186028] [FAKE loss: 1.774488]  tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 453/1000] [D loss: 0.982778] [G loss: 0.182405] [FAKE loss: 1.792413]  tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 454/1000] [D loss: 0.989892] [G loss: 0.179324] [FAKE loss: 1.809714]  tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 455/1000] [D loss: 0.996384] [G loss: 0.175789] [FAKE loss: 1.825693]  tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 456/1000] [D loss: 1.003347] [G loss: 0.172945] [FAKE loss: 1.842674]  tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 457/1000] [D loss: 1.009919] [G loss: 0.169904] [FAKE loss: 1.858636]  tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 458/1000] [D loss: 1.015693] [G loss: 0.167142] [FAKE loss: 1.872772]  tensor(0.8461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 459/1000] [D loss: 1.021857] [G loss: 0.164593] [FAKE loss: 1.887626]  tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 460/1000] [D loss: 1.027537] [G loss: 0.161975] [FAKE loss: 1.901434]  tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 461/1000] [D loss: 1.033504] [G loss: 0.159600] [FAKE loss: 1.915792]  tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 462/1000] [D loss: 1.038955] [G loss: 0.157524] [FAKE loss: 1.928883]  tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 463/1000] [D loss: 1.043625] [G loss: 0.155412] [FAKE loss: 1.940364]  tensor(0.8561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 464/1000] [D loss: 1.049131] [G loss: 0.153418] [FAKE loss: 1.953293]  tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 465/1000] [D loss: 1.053423] [G loss: 0.151525] [FAKE loss: 1.963643]  tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 466/1000] [D loss: 1.057216] [G loss: 0.149883] [FAKE loss: 1.973108]  tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 467/1000] [D loss: 1.061541] [G loss: 0.148447] [FAKE loss: 1.983258]  tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 468/1000] [D loss: 1.065812] [G loss: 0.146845] [FAKE loss: 1.993384]  tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 469/1000] [D loss: 1.068925] [G loss: 0.145392] [FAKE loss: 2.000954]  tensor(0.8647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 470/1000] [D loss: 1.072251] [G loss: 0.144129] [FAKE loss: 2.009099]  tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 471/1000] [D loss: 1.075108] [G loss: 0.143147] [FAKE loss: 2.015944]  tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 472/1000] [D loss: 1.078050] [G loss: 0.142122] [FAKE loss: 2.023107]  tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 473/1000] [D loss: 1.081107] [G loss: 0.141031] [FAKE loss: 2.030020]  tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 474/1000] [D loss: 1.083778] [G loss: 0.140364] [FAKE loss: 2.036211]  tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 475/1000] [D loss: 1.085567] [G loss: 0.139589] [FAKE loss: 2.040611]  tensor(0.8697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 476/1000] [D loss: 1.087691] [G loss: 0.139055] [FAKE loss: 2.045412]  tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 477/1000] [D loss: 1.088507] [G loss: 0.138350] [FAKE loss: 2.047627]  tensor(0.8708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 478/1000] [D loss: 1.090226] [G loss: 0.137987] [FAKE loss: 2.051388]  tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 479/1000] [D loss: 1.091501] [G loss: 0.137636] [FAKE loss: 2.054384]  tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 480/1000] [D loss: 1.091814] [G loss: 0.137422] [FAKE loss: 2.055292]  tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 481/1000] [D loss: 1.092211] [G loss: 0.137296] [FAKE loss: 2.056231]  tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 482/1000] [D loss: 1.092818] [G loss: 0.137192] [FAKE loss: 2.057451]  tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 483/1000] [D loss: 1.092392] [G loss: 0.137219] [FAKE loss: 2.056413]  tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 484/1000] [D loss: 1.091664] [G loss: 0.137450] [FAKE loss: 2.054796]  tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 485/1000] [D loss: 1.091948] [G loss: 0.137486] [FAKE loss: 2.054917]  tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 486/1000] [D loss: 1.090014] [G loss: 0.137861] [FAKE loss: 2.050774]  tensor(0.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 487/1000] [D loss: 1.089658] [G loss: 0.138119] [FAKE loss: 2.049586]  tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 488/1000] [D loss: 1.089062] [G loss: 0.138654] [FAKE loss: 2.047881]  tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 489/1000] [D loss: 1.086673] [G loss: 0.139239] [FAKE loss: 2.042281]  tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 490/1000] [D loss: 1.085350] [G loss: 0.139830] [FAKE loss: 2.038626]  tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 491/1000] [D loss: 1.083849] [G loss: 0.140721] [FAKE loss: 2.034564]  tensor(0.8689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 492/1000] [D loss: 1.081290] [G loss: 0.141621] [FAKE loss: 2.028689]  tensor(0.8680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 493/1000] [D loss: 1.078872] [G loss: 0.142472] [FAKE loss: 2.022462]  tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 494/1000] [D loss: 1.076084] [G loss: 0.143731] [FAKE loss: 2.015664]  tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 495/1000] [D loss: 1.071997] [G loss: 0.144791] [FAKE loss: 2.006054]  tensor(0.8653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 496/1000] [D loss: 1.070060] [G loss: 0.146135] [FAKE loss: 2.000425]  tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 497/1000] [D loss: 1.066013] [G loss: 0.147325] [FAKE loss: 1.990844]  tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 498/1000] [D loss: 1.062261] [G loss: 0.149045] [FAKE loss: 1.981655]  tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 499/1000] [D loss: 1.058395] [G loss: 0.150564] [FAKE loss: 1.971811]  tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 500/1000] [D loss: 1.054029] [G loss: 0.152198] [FAKE loss: 1.961076]  tensor(0.8586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 501/1000] [D loss: 1.049633] [G loss: 0.154269] [FAKE loss: 1.950117]  tensor(0.8574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 502/1000] [D loss: 1.044663] [G loss: 0.156230] [FAKE loss: 1.937868]  tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 503/1000] [D loss: 1.038913] [G loss: 0.158630] [FAKE loss: 1.923771]  tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 504/1000] [D loss: 1.033558] [G loss: 0.160549] [FAKE loss: 1.910846]  tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 505/1000] [D loss: 1.028774] [G loss: 0.162996] [FAKE loss: 1.898484]  tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 506/1000] [D loss: 1.023389] [G loss: 0.165542] [FAKE loss: 1.884875]  tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 507/1000] [D loss: 1.017411] [G loss: 0.167871] [FAKE loss: 1.870402]  tensor(0.8454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 508/1000] [D loss: 1.011558] [G loss: 0.171064] [FAKE loss: 1.855455]  tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 509/1000] [D loss: 1.005802] [G loss: 0.173722] [FAKE loss: 1.840568]  tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 510/1000] [D loss: 0.999625] [G loss: 0.176700] [FAKE loss: 1.824733]  tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 511/1000] [D loss: 0.992216] [G loss: 0.180012] [FAKE loss: 1.806629]  tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 512/1000] [D loss: 0.986284] [G loss: 0.183304] [FAKE loss: 1.790951]  tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 513/1000] [D loss: 0.979738] [G loss: 0.186725] [FAKE loss: 1.774633]  tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 514/1000] [D loss: 0.972896] [G loss: 0.190250] [FAKE loss: 1.757094]  tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 515/1000] [D loss: 0.966380] [G loss: 0.193789] [FAKE loss: 1.740009]  tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 516/1000] [D loss: 0.959442] [G loss: 0.197656] [FAKE loss: 1.721881]  tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 517/1000] [D loss: 0.952937] [G loss: 0.201883] [FAKE loss: 1.704569]  tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 518/1000] [D loss: 0.946196] [G loss: 0.206130] [FAKE loss: 1.686748]  tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 519/1000] [D loss: 0.939390] [G loss: 0.209956] [FAKE loss: 1.668904]  tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 520/1000] [D loss: 0.931887] [G loss: 0.214550] [FAKE loss: 1.648939]  tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 521/1000] [D loss: 0.926077] [G loss: 0.218577] [FAKE loss: 1.632394]  tensor(0.8035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 522/1000] [D loss: 0.918594] [G loss: 0.223269] [FAKE loss: 1.613321]  tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 523/1000] [D loss: 0.912128] [G loss: 0.227996] [FAKE loss: 1.594874]  tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 524/1000] [D loss: 0.905167] [G loss: 0.232716] [FAKE loss: 1.575794]  tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 525/1000] [D loss: 0.899491] [G loss: 0.237454] [FAKE loss: 1.559222]  tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 526/1000] [D loss: 0.893138] [G loss: 0.242218] [FAKE loss: 1.541232]  tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 527/1000] [D loss: 0.887472] [G loss: 0.247148] [FAKE loss: 1.524422]  tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 528/1000] [D loss: 0.880876] [G loss: 0.252440] [FAKE loss: 1.505546]  tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 529/1000] [D loss: 0.874621] [G loss: 0.257133] [FAKE loss: 1.487291]  tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 530/1000] [D loss: 0.869439] [G loss: 0.262023] [FAKE loss: 1.471650]  tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 531/1000] [D loss: 0.863171] [G loss: 0.267317] [FAKE loss: 1.452682]  tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 532/1000] [D loss: 0.858432] [G loss: 0.272714] [FAKE loss: 1.437370]  tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 533/1000] [D loss: 0.852101] [G loss: 0.278362] [FAKE loss: 1.418542]  tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 534/1000] [D loss: 0.846961] [G loss: 0.283857] [FAKE loss: 1.401628]  tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 535/1000] [D loss: 0.841517] [G loss: 0.289472] [FAKE loss: 1.384859]  tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 536/1000] [D loss: 0.836850] [G loss: 0.294681] [FAKE loss: 1.369071]  tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 537/1000] [D loss: 0.830920] [G loss: 0.300595] [FAKE loss: 1.351452]  tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 538/1000] [D loss: 0.825935] [G loss: 0.306894] [FAKE loss: 1.334405]  tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 539/1000] [D loss: 0.821658] [G loss: 0.312463] [FAKE loss: 1.319550]  tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 540/1000] [D loss: 0.817474] [G loss: 0.318408] [FAKE loss: 1.304070]  tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 541/1000] [D loss: 0.811485] [G loss: 0.324769] [FAKE loss: 1.285879]  tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 542/1000] [D loss: 0.807705] [G loss: 0.331069] [FAKE loss: 1.271030]  tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 543/1000] [D loss: 0.802161] [G loss: 0.337210] [FAKE loss: 1.253671]  tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 544/1000] [D loss: 0.798319] [G loss: 0.344005] [FAKE loss: 1.239321]  tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 545/1000] [D loss: 0.793209] [G loss: 0.350364] [FAKE loss: 1.222718]  tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 546/1000] [D loss: 0.789053] [G loss: 0.356884] [FAKE loss: 1.207226]  tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 547/1000] [D loss: 0.784105] [G loss: 0.363631] [FAKE loss: 1.190571]  tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 548/1000] [D loss: 0.780174] [G loss: 0.369809] [FAKE loss: 1.175852]  tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 549/1000] [D loss: 0.776179] [G loss: 0.378550] [FAKE loss: 1.160589]  tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 550/1000] [D loss: 0.771680] [G loss: 0.384378] [FAKE loss: 1.144565]  tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 551/1000] [D loss: 0.768252] [G loss: 0.391547] [FAKE loss: 1.130924]  tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 552/1000] [D loss: 0.764116] [G loss: 0.398406] [FAKE loss: 1.116884]  tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 553/1000] [D loss: 0.760439] [G loss: 0.405516] [FAKE loss: 1.102258]  tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 554/1000] [D loss: 0.756480] [G loss: 0.412998] [FAKE loss: 1.087792]  tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 555/1000] [D loss: 0.752929] [G loss: 0.420288] [FAKE loss: 1.073962]  tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 556/1000] [D loss: 0.749564] [G loss: 0.427850] [FAKE loss: 1.060704]  tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 557/1000] [D loss: 0.746488] [G loss: 0.434127] [FAKE loss: 1.048139]  tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 558/1000] [D loss: 0.742773] [G loss: 0.441182] [FAKE loss: 1.033680]  tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 559/1000] [D loss: 0.739319] [G loss: 0.448511] [FAKE loss: 1.020976]  tensor(0.6386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 560/1000] [D loss: 0.736150] [G loss: 0.455217] [FAKE loss: 1.007990]  tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 561/1000] [D loss: 0.733245] [G loss: 0.462757] [FAKE loss: 0.996186]  tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 562/1000] [D loss: 0.730322] [G loss: 0.469559] [FAKE loss: 0.984299]  tensor(0.6257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 563/1000] [D loss: 0.727459] [G loss: 0.476832] [FAKE loss: 0.972867]  tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 564/1000] [D loss: 0.724798] [G loss: 0.483281] [FAKE loss: 0.962147]  tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 565/1000] [D loss: 0.722472] [G loss: 0.489645] [FAKE loss: 0.951180]  tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 566/1000] [D loss: 0.719382] [G loss: 0.496067] [FAKE loss: 0.940378]  tensor(0.6090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 567/1000] [D loss: 0.717727] [G loss: 0.503030] [FAKE loss: 0.931134]  tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 568/1000] [D loss: 0.715606] [G loss: 0.509111] [FAKE loss: 0.921785]  tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 569/1000] [D loss: 0.712857] [G loss: 0.515799] [FAKE loss: 0.911314]  tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 570/1000] [D loss: 0.712078] [G loss: 0.521670] [FAKE loss: 0.904460]  tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 571/1000] [D loss: 0.709706] [G loss: 0.527228] [FAKE loss: 0.895783]  tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 572/1000] [D loss: 0.707419] [G loss: 0.531833] [FAKE loss: 0.886329]  tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 573/1000] [D loss: 0.706401] [G loss: 0.537441] [FAKE loss: 0.879754]  tensor(0.5845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 574/1000] [D loss: 0.705243] [G loss: 0.543102] [FAKE loss: 0.873310]  tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 575/1000] [D loss: 0.703651] [G loss: 0.547923] [FAKE loss: 0.866756]  tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 576/1000] [D loss: 0.701868] [G loss: 0.553275] [FAKE loss: 0.859694]  tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 577/1000] [D loss: 0.700729] [G loss: 0.556615] [FAKE loss: 0.853954]  tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 578/1000] [D loss: 0.700080] [G loss: 0.560775] [FAKE loss: 0.849315]  tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 579/1000] [D loss: 0.698477] [G loss: 0.564369] [FAKE loss: 0.843515]  tensor(0.5695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 580/1000] [D loss: 0.697775] [G loss: 0.568250] [FAKE loss: 0.838729]  tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 581/1000] [D loss: 0.696430] [G loss: 0.571325] [FAKE loss: 0.835010]  tensor(0.5656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 582/1000] [D loss: 0.696116] [G loss: 0.573952] [FAKE loss: 0.831465]  tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 583/1000] [D loss: 0.695363] [G loss: 0.575722] [FAKE loss: 0.828171]  tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 584/1000] [D loss: 0.695408] [G loss: 0.578701] [FAKE loss: 0.826141]  tensor(0.5613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 585/1000] [D loss: 0.694688] [G loss: 0.580886] [FAKE loss: 0.823540]  tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 586/1000] [D loss: 0.694568] [G loss: 0.581489] [FAKE loss: 0.821612]  tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 587/1000] [D loss: 0.693771] [G loss: 0.582739] [FAKE loss: 0.819976]  tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 588/1000] [D loss: 0.693847] [G loss: 0.582731] [FAKE loss: 0.819107]  tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 589/1000] [D loss: 0.694139] [G loss: 0.583888] [FAKE loss: 0.819055]  tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 590/1000] [D loss: 0.693658] [G loss: 0.583134] [FAKE loss: 0.818470]  tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 591/1000] [D loss: 0.694332] [G loss: 0.583835] [FAKE loss: 0.819728]  tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 592/1000] [D loss: 0.694322] [G loss: 0.582134] [FAKE loss: 0.819739]  tensor(0.5588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 593/1000] [D loss: 0.694910] [G loss: 0.581135] [FAKE loss: 0.821549]  tensor(0.5593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 594/1000] [D loss: 0.695554] [G loss: 0.579943] [FAKE loss: 0.824020]  tensor(0.5600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 595/1000] [D loss: 0.695692] [G loss: 0.578894] [FAKE loss: 0.824855]  tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 596/1000] [D loss: 0.695740] [G loss: 0.576765] [FAKE loss: 0.826828]  tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 597/1000] [D loss: 0.696896] [G loss: 0.574745] [FAKE loss: 0.830522]  tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 598/1000] [D loss: 0.697105] [G loss: 0.571596] [FAKE loss: 0.833011]  tensor(0.5648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 599/1000] [D loss: 0.698515] [G loss: 0.569288] [FAKE loss: 0.837734]  tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 600/1000] [D loss: 0.698406] [G loss: 0.566498] [FAKE loss: 0.840231]  tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 601/1000] [D loss: 0.700469] [G loss: 0.563212] [FAKE loss: 0.846155]  tensor(0.5702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 602/1000] [D loss: 0.701512] [G loss: 0.559554] [FAKE loss: 0.850311]  tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 603/1000] [D loss: 0.702425] [G loss: 0.554922] [FAKE loss: 0.855775]  tensor(0.5744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 604/1000] [D loss: 0.703010] [G loss: 0.551160] [FAKE loss: 0.860947]  tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 605/1000] [D loss: 0.704845] [G loss: 0.546503] [FAKE loss: 0.868111]  tensor(0.5794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 606/1000] [D loss: 0.706087] [G loss: 0.542099] [FAKE loss: 0.873894]  tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 607/1000] [D loss: 0.708036] [G loss: 0.535970] [FAKE loss: 0.881619]  tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 608/1000] [D loss: 0.710230] [G loss: 0.530537] [FAKE loss: 0.889692]  tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 609/1000] [D loss: 0.712405] [G loss: 0.525341] [FAKE loss: 0.898064]  tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 610/1000] [D loss: 0.715494] [G loss: 0.518302] [FAKE loss: 0.908095]  tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 611/1000] [D loss: 0.717115] [G loss: 0.512520] [FAKE loss: 0.916522]  tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 612/1000] [D loss: 0.720823] [G loss: 0.505726] [FAKE loss: 0.927518]  tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 613/1000] [D loss: 0.723360] [G loss: 0.498539] [FAKE loss: 0.937858]  tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 614/1000] [D loss: 0.727758] [G loss: 0.490318] [FAKE loss: 0.951026]  tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 615/1000] [D loss: 0.731970] [G loss: 0.482658] [FAKE loss: 0.964540]  tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 616/1000] [D loss: 0.735670] [G loss: 0.473751] [FAKE loss: 0.977152]  tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 617/1000] [D loss: 0.741091] [G loss: 0.465633] [FAKE loss: 0.992958]  tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 618/1000] [D loss: 0.746044] [G loss: 0.457057] [FAKE loss: 1.007997]  tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 619/1000] [D loss: 0.751446] [G loss: 0.447881] [FAKE loss: 1.024490]  tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 620/1000] [D loss: 0.756816] [G loss: 0.438509] [FAKE loss: 1.040155]  tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 621/1000] [D loss: 0.763216] [G loss: 0.428352] [FAKE loss: 1.059140]  tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 622/1000] [D loss: 0.769745] [G loss: 0.418758] [FAKE loss: 1.077500]  tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 623/1000] [D loss: 0.776435] [G loss: 0.409013] [FAKE loss: 1.095999]  tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 624/1000] [D loss: 0.783901] [G loss: 0.399434] [FAKE loss: 1.116701]  tensor(0.6713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 625/1000] [D loss: 0.790898] [G loss: 0.388813] [FAKE loss: 1.136803]  tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 626/1000] [D loss: 0.799158] [G loss: 0.380362] [FAKE loss: 1.158826]  tensor(0.6850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 627/1000] [D loss: 0.808052] [G loss: 0.370252] [FAKE loss: 1.182424]  tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 628/1000] [D loss: 0.815889] [G loss: 0.359939] [FAKE loss: 1.204104]  tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 629/1000] [D loss: 0.824494] [G loss: 0.350448] [FAKE loss: 1.227378]  tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 630/1000] [D loss: 0.832203] [G loss: 0.341066] [FAKE loss: 1.248351]  tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 631/1000] [D loss: 0.841556] [G loss: 0.332161] [FAKE loss: 1.273382]  tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 632/1000] [D loss: 0.850862] [G loss: 0.322029] [FAKE loss: 1.298153]  tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 633/1000] [D loss: 0.861777] [G loss: 0.312037] [FAKE loss: 1.325443]  tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 634/1000] [D loss: 0.871586] [G loss: 0.303630] [FAKE loss: 1.351014]  tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 635/1000] [D loss: 0.881283] [G loss: 0.295730] [FAKE loss: 1.376490]  tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 636/1000] [D loss: 0.891407] [G loss: 0.286289] [FAKE loss: 1.401522]  tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 637/1000] [D loss: 0.901244] [G loss: 0.278564] [FAKE loss: 1.428101]  tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 638/1000] [D loss: 0.910753] [G loss: 0.270778] [FAKE loss: 1.452979]  tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 639/1000] [D loss: 0.921424] [G loss: 0.262323] [FAKE loss: 1.479959]  tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 640/1000] [D loss: 0.932641] [G loss: 0.255350] [FAKE loss: 1.507722]  tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 641/1000] [D loss: 0.943820] [G loss: 0.247153] [FAKE loss: 1.535846]  tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 642/1000] [D loss: 0.954752] [G loss: 0.240739] [FAKE loss: 1.563516]  tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 643/1000] [D loss: 0.964763] [G loss: 0.233101] [FAKE loss: 1.588787]  tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 644/1000] [D loss: 0.974330] [G loss: 0.227101] [FAKE loss: 1.612901]  tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 645/1000] [D loss: 0.986620] [G loss: 0.220653] [FAKE loss: 1.643688]  tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 646/1000] [D loss: 0.995430] [G loss: 0.213633] [FAKE loss: 1.666051]  tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 647/1000] [D loss: 1.007103] [G loss: 0.209368] [FAKE loss: 1.694645]  tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 648/1000] [D loss: 1.015101] [G loss: 0.202614] [FAKE loss: 1.715670]  tensor(0.8170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 649/1000] [D loss: 1.026286] [G loss: 0.198104] [FAKE loss: 1.743485]  tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 650/1000] [D loss: 1.037538] [G loss: 0.192082] [FAKE loss: 1.769815]  tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 651/1000] [D loss: 1.045740] [G loss: 0.186641] [FAKE loss: 1.791007]  tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 652/1000] [D loss: 1.055451] [G loss: 0.182945] [FAKE loss: 1.815130]  tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 653/1000] [D loss: 1.064388] [G loss: 0.178402] [FAKE loss: 1.837510]  tensor(0.8376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 654/1000] [D loss: 1.073025] [G loss: 0.174426] [FAKE loss: 1.859159]  tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 655/1000] [D loss: 1.082540] [G loss: 0.170460] [FAKE loss: 1.883202]  tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 656/1000] [D loss: 1.088147] [G loss: 0.167317] [FAKE loss: 1.898081]  tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 657/1000] [D loss: 1.096623] [G loss: 0.163476] [FAKE loss: 1.918989]  tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 658/1000] [D loss: 1.103362] [G loss: 0.160794] [FAKE loss: 1.936949]  tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 659/1000] [D loss: 1.112296] [G loss: 0.157867] [FAKE loss: 1.957204]  tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 660/1000] [D loss: 1.117203] [G loss: 0.154886] [FAKE loss: 1.971401]  tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 661/1000] [D loss: 1.123097] [G loss: 0.152964] [FAKE loss: 1.986296]  tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 662/1000] [D loss: 1.126482] [G loss: 0.151247] [FAKE loss: 1.996031]  tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 663/1000] [D loss: 1.131539] [G loss: 0.148882] [FAKE loss: 2.009279]  tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 664/1000] [D loss: 1.136913] [G loss: 0.146476] [FAKE loss: 2.023196]  tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 665/1000] [D loss: 1.137915] [G loss: 0.146021] [FAKE loss: 2.027974]  tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 666/1000] [D loss: 1.140416] [G loss: 0.145528] [FAKE loss: 2.036020]  tensor(0.8663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 667/1000] [D loss: 1.142560] [G loss: 0.142942] [FAKE loss: 2.042763]  tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 668/1000] [D loss: 1.141686] [G loss: 0.143003] [FAKE loss: 2.043220]  tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 669/1000] [D loss: 1.141639] [G loss: 0.142922] [FAKE loss: 2.045507]  tensor(0.8677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 670/1000] [D loss: 1.143552] [G loss: 0.142018] [FAKE loss: 2.051786]  tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 671/1000] [D loss: 1.142256] [G loss: 0.141882] [FAKE loss: 2.050254]  tensor(0.8681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 672/1000] [D loss: 1.141717] [G loss: 0.141623] [FAKE loss: 2.050442]  tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 673/1000] [D loss: 1.139356] [G loss: 0.142334] [FAKE loss: 2.048643]  tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 674/1000] [D loss: 1.136634] [G loss: 0.142663] [FAKE loss: 2.044353]  tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 675/1000] [D loss: 1.135218] [G loss: 0.144127] [FAKE loss: 2.042938]  tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 676/1000] [D loss: 1.128762] [G loss: 0.144615] [FAKE loss: 2.031101]  tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 677/1000] [D loss: 1.123970] [G loss: 0.145122] [FAKE loss: 2.022966]  tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 678/1000] [D loss: 1.119542] [G loss: 0.146845] [FAKE loss: 2.014851]  tensor(0.8639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 679/1000] [D loss: 1.113778] [G loss: 0.148253] [FAKE loss: 2.003887]  tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 680/1000] [D loss: 1.107962] [G loss: 0.149938] [FAKE loss: 1.993065]  tensor(0.8612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 681/1000] [D loss: 1.099975] [G loss: 0.151096] [FAKE loss: 1.977937]  tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 682/1000] [D loss: 1.093798] [G loss: 0.153944] [FAKE loss: 1.965802]  tensor(0.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 683/1000] [D loss: 1.088088] [G loss: 0.155460] [FAKE loss: 1.954856]  tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 684/1000] [D loss: 1.080104] [G loss: 0.158067] [FAKE loss: 1.939002]  tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 685/1000] [D loss: 1.071256] [G loss: 0.160545] [FAKE loss: 1.921609]  tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 686/1000] [D loss: 1.064593] [G loss: 0.163531] [FAKE loss: 1.907530]  tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 687/1000] [D loss: 1.054787] [G loss: 0.166746] [FAKE loss: 1.888164]  tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 688/1000] [D loss: 1.046156] [G loss: 0.170367] [FAKE loss: 1.870009]  tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 689/1000] [D loss: 1.036608] [G loss: 0.173795] [FAKE loss: 1.850909]  tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 690/1000] [D loss: 1.027124] [G loss: 0.176575] [FAKE loss: 1.831856]  tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 691/1000] [D loss: 1.017721] [G loss: 0.180656] [FAKE loss: 1.811577]  tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 692/1000] [D loss: 1.007688] [G loss: 0.183967] [FAKE loss: 1.791600]  tensor(0.8321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 693/1000] [D loss: 0.998531] [G loss: 0.188462] [FAKE loss: 1.772141]  tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 694/1000] [D loss: 0.988362] [G loss: 0.192716] [FAKE loss: 1.751020]  tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 695/1000] [D loss: 0.978515] [G loss: 0.196706] [FAKE loss: 1.730639]  tensor(0.8218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 696/1000] [D loss: 0.968687] [G loss: 0.201103] [FAKE loss: 1.709764]  tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 697/1000] [D loss: 0.959300] [G loss: 0.206059] [FAKE loss: 1.689797]  tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 698/1000] [D loss: 0.947742] [G loss: 0.210974] [FAKE loss: 1.665417]  tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 699/1000] [D loss: 0.938375] [G loss: 0.215817] [FAKE loss: 1.645146]  tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 700/1000] [D loss: 0.926462] [G loss: 0.220991] [FAKE loss: 1.620821]  tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 701/1000] [D loss: 0.918593] [G loss: 0.226414] [FAKE loss: 1.603039]  tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 702/1000] [D loss: 0.908067] [G loss: 0.232282] [FAKE loss: 1.580463]  tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 703/1000] [D loss: 0.897188] [G loss: 0.238199] [FAKE loss: 1.557837]  tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 704/1000] [D loss: 0.888187] [G loss: 0.243159] [FAKE loss: 1.536952]  tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 705/1000] [D loss: 0.879056] [G loss: 0.249363] [FAKE loss: 1.517396]  tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 706/1000] [D loss: 0.869419] [G loss: 0.255212] [FAKE loss: 1.496500]  tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 707/1000] [D loss: 0.859131] [G loss: 0.261127] [FAKE loss: 1.474295]  tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 708/1000] [D loss: 0.850035] [G loss: 0.266899] [FAKE loss: 1.454425]  tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 709/1000] [D loss: 0.841415] [G loss: 0.273241] [FAKE loss: 1.435099]  tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 710/1000] [D loss: 0.832506] [G loss: 0.279854] [FAKE loss: 1.414768]  tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 711/1000] [D loss: 0.823984] [G loss: 0.286258] [FAKE loss: 1.396007]  tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 712/1000] [D loss: 0.815258] [G loss: 0.292364] [FAKE loss: 1.376187]  tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 713/1000] [D loss: 0.806707] [G loss: 0.299291] [FAKE loss: 1.356818]  tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 714/1000] [D loss: 0.798790] [G loss: 0.305386] [FAKE loss: 1.339705]  tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 715/1000] [D loss: 0.791319] [G loss: 0.312517] [FAKE loss: 1.321532]  tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 716/1000] [D loss: 0.783640] [G loss: 0.318458] [FAKE loss: 1.304434]  tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 717/1000] [D loss: 0.776089] [G loss: 0.324779] [FAKE loss: 1.287835]  tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 718/1000] [D loss: 0.769397] [G loss: 0.332186] [FAKE loss: 1.271174]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 719/1000] [D loss: 0.761443] [G loss: 0.338672] [FAKE loss: 1.254292]  tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 720/1000] [D loss: 0.755234] [G loss: 0.344385] [FAKE loss: 1.239292]  tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 721/1000] [D loss: 0.749452] [G loss: 0.351830] [FAKE loss: 1.224794]  tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 722/1000] [D loss: 0.742379] [G loss: 0.357534] [FAKE loss: 1.208501]  tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 723/1000] [D loss: 0.736511] [G loss: 0.363691] [FAKE loss: 1.194391]  tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 724/1000] [D loss: 0.730756] [G loss: 0.369624] [FAKE loss: 1.180561]  tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 725/1000] [D loss: 0.724390] [G loss: 0.377016] [FAKE loss: 1.165274]  tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 726/1000] [D loss: 0.719731] [G loss: 0.382958] [FAKE loss: 1.154369]  tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 727/1000] [D loss: 0.714080] [G loss: 0.387943] [FAKE loss: 1.140658]  tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 728/1000] [D loss: 0.710427] [G loss: 0.395496] [FAKE loss: 1.130341]  tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 729/1000] [D loss: 0.703929] [G loss: 0.401183] [FAKE loss: 1.116225]  tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 730/1000] [D loss: 0.700114] [G loss: 0.407906] [FAKE loss: 1.106578]  tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 731/1000] [D loss: 0.695464] [G loss: 0.414229] [FAKE loss: 1.094907]  tensor(0.6621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 732/1000] [D loss: 0.691233] [G loss: 0.420019] [FAKE loss: 1.083354]  tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 733/1000] [D loss: 0.687539] [G loss: 0.423978] [FAKE loss: 1.074253]  tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 734/1000] [D loss: 0.682619] [G loss: 0.428974] [FAKE loss: 1.062101]  tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 735/1000] [D loss: 0.679376] [G loss: 0.434851] [FAKE loss: 1.054015]  tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 736/1000] [D loss: 0.678511] [G loss: 0.439324] [FAKE loss: 1.049708]  tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 737/1000] [D loss: 0.672819] [G loss: 0.445593] [FAKE loss: 1.036930]  tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 738/1000] [D loss: 0.671609] [G loss: 0.450651] [FAKE loss: 1.031802]  tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 739/1000] [D loss: 0.669019] [G loss: 0.456537] [FAKE loss: 1.025300]  tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 740/1000] [D loss: 0.667255] [G loss: 0.459449] [FAKE loss: 1.019955]  tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 741/1000] [D loss: 0.661607] [G loss: 0.464382] [FAKE loss: 1.007503]  tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 742/1000] [D loss: 0.659765] [G loss: 0.467599] [FAKE loss: 1.002280]  tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 743/1000] [D loss: 0.657617] [G loss: 0.472827] [FAKE loss: 0.996654]  tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 744/1000] [D loss: 0.654794] [G loss: 0.476670] [FAKE loss: 0.989119]  tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 745/1000] [D loss: 0.652977] [G loss: 0.482638] [FAKE loss: 0.984514]  tensor(0.6221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 746/1000] [D loss: 0.653427] [G loss: 0.483002] [FAKE loss: 0.982356]  tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 747/1000] [D loss: 0.650090] [G loss: 0.485685] [FAKE loss: 0.975764]  tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 748/1000] [D loss: 0.648764] [G loss: 0.490037] [FAKE loss: 0.972573]  tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 749/1000] [D loss: 0.648668] [G loss: 0.491442] [FAKE loss: 0.970879]  tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 750/1000] [D loss: 0.647156] [G loss: 0.494758] [FAKE loss: 0.967076]  tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 751/1000] [D loss: 0.647640] [G loss: 0.496089] [FAKE loss: 0.967290]  tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 752/1000] [D loss: 0.647229] [G loss: 0.498534] [FAKE loss: 0.966067]  tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 753/1000] [D loss: 0.645951] [G loss: 0.501095] [FAKE loss: 0.962185]  tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 754/1000] [D loss: 0.648177] [G loss: 0.499149] [FAKE loss: 0.965050]  tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 755/1000] [D loss: 0.647616] [G loss: 0.501852] [FAKE loss: 0.964841]  tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 756/1000] [D loss: 0.644532] [G loss: 0.500195] [FAKE loss: 0.959501]  tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 757/1000] [D loss: 0.647110] [G loss: 0.501774] [FAKE loss: 0.963311]  tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 758/1000] [D loss: 0.648371] [G loss: 0.501750] [FAKE loss: 0.966139]  tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 759/1000] [D loss: 0.651273] [G loss: 0.500063] [FAKE loss: 0.969945]  tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 760/1000] [D loss: 0.650786] [G loss: 0.498249] [FAKE loss: 0.970543]  tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 761/1000] [D loss: 0.652095] [G loss: 0.496584] [FAKE loss: 0.974821]  tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 762/1000] [D loss: 0.653574] [G loss: 0.493651] [FAKE loss: 0.977822]  tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 763/1000] [D loss: 0.657993] [G loss: 0.492074] [FAKE loss: 0.987112]  tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 764/1000] [D loss: 0.660847] [G loss: 0.489604] [FAKE loss: 0.992326]  tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 765/1000] [D loss: 0.661798] [G loss: 0.485266] [FAKE loss: 0.997512]  tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 766/1000] [D loss: 0.665595] [G loss: 0.482536] [FAKE loss: 1.004435]  tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 767/1000] [D loss: 0.668211] [G loss: 0.480294] [FAKE loss: 1.012585]  tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 768/1000] [D loss: 0.673416] [G loss: 0.474984] [FAKE loss: 1.024701]  tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 769/1000] [D loss: 0.675479] [G loss: 0.472027] [FAKE loss: 1.029273]  tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 770/1000] [D loss: 0.679440] [G loss: 0.465577] [FAKE loss: 1.038482]  tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 771/1000] [D loss: 0.685202] [G loss: 0.461325] [FAKE loss: 1.051264]  tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 772/1000] [D loss: 0.688848] [G loss: 0.456873] [FAKE loss: 1.060765]  tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 773/1000] [D loss: 0.693599] [G loss: 0.450316] [FAKE loss: 1.072788]  tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 774/1000] [D loss: 0.699448] [G loss: 0.441552] [FAKE loss: 1.087996]  tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 775/1000] [D loss: 0.705784] [G loss: 0.436189] [FAKE loss: 1.101591]  tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 776/1000] [D loss: 0.710704] [G loss: 0.431614] [FAKE loss: 1.114015]  tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 777/1000] [D loss: 0.717714] [G loss: 0.423740] [FAKE loss: 1.130161]  tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 778/1000] [D loss: 0.724154] [G loss: 0.418626] [FAKE loss: 1.145533]  tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 779/1000] [D loss: 0.730071] [G loss: 0.409780] [FAKE loss: 1.161180]  tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 780/1000] [D loss: 0.736833] [G loss: 0.403865] [FAKE loss: 1.176886]  tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 781/1000] [D loss: 0.745431] [G loss: 0.394873] [FAKE loss: 1.196258]  tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 782/1000] [D loss: 0.754458] [G loss: 0.387391] [FAKE loss: 1.216381]  tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 783/1000] [D loss: 0.758086] [G loss: 0.381322] [FAKE loss: 1.228822]  tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 784/1000] [D loss: 0.770385] [G loss: 0.370697] [FAKE loss: 1.256551]  tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 785/1000] [D loss: 0.775936] [G loss: 0.361914] [FAKE loss: 1.268400]  tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 786/1000] [D loss: 0.784575] [G loss: 0.357575] [FAKE loss: 1.290228]  tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 787/1000] [D loss: 0.792353] [G loss: 0.352725] [FAKE loss: 1.309789]  tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 788/1000] [D loss: 0.804411] [G loss: 0.340860] [FAKE loss: 1.335823]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 789/1000] [D loss: 0.814395] [G loss: 0.336648] [FAKE loss: 1.358470]  tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 790/1000] [D loss: 0.821912] [G loss: 0.327778] [FAKE loss: 1.378500]  tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 791/1000] [D loss: 0.826230] [G loss: 0.322517] [FAKE loss: 1.390370]  tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 792/1000] [D loss: 0.839671] [G loss: 0.312667] [FAKE loss: 1.420765]  tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 793/1000] [D loss: 0.852335] [G loss: 0.307336] [FAKE loss: 1.448367]  tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 794/1000] [D loss: 0.857009] [G loss: 0.300648] [FAKE loss: 1.460989]  tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 795/1000] [D loss: 0.869449] [G loss: 0.296185] [FAKE loss: 1.489520]  tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 796/1000] [D loss: 0.880678] [G loss: 0.288370] [FAKE loss: 1.514555]  tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 797/1000] [D loss: 0.886659] [G loss: 0.282908] [FAKE loss: 1.531072]  tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 798/1000] [D loss: 0.893618] [G loss: 0.275454] [FAKE loss: 1.548810]  tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 799/1000] [D loss: 0.904433] [G loss: 0.270093] [FAKE loss: 1.573707]  tensor(0.7716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 800/1000] [D loss: 0.913612] [G loss: 0.266530] [FAKE loss: 1.593212]  tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 801/1000] [D loss: 0.922256] [G loss: 0.261264] [FAKE loss: 1.614590]  tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 802/1000] [D loss: 0.931787] [G loss: 0.253891] [FAKE loss: 1.636243]  tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 803/1000] [D loss: 0.933794] [G loss: 0.251660] [FAKE loss: 1.643903]  tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 804/1000] [D loss: 0.944925] [G loss: 0.242343] [FAKE loss: 1.669151]  tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 805/1000] [D loss: 0.952906] [G loss: 0.238714] [FAKE loss: 1.687773]  tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 806/1000] [D loss: 0.961263] [G loss: 0.238377] [FAKE loss: 1.707437]  tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 807/1000] [D loss: 0.969370] [G loss: 0.230777] [FAKE loss: 1.726290]  tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 808/1000] [D loss: 0.972147] [G loss: 0.226251] [FAKE loss: 1.734176]  tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 809/1000] [D loss: 0.979208] [G loss: 0.227447] [FAKE loss: 1.749910]  tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 810/1000] [D loss: 0.985465] [G loss: 0.223556] [FAKE loss: 1.765735]  tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 811/1000] [D loss: 0.985160] [G loss: 0.221909] [FAKE loss: 1.767201]  tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 812/1000] [D loss: 0.987752] [G loss: 0.219132] [FAKE loss: 1.775291]  tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 813/1000] [D loss: 0.992225] [G loss: 0.216053] [FAKE loss: 1.785141]  tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 814/1000] [D loss: 0.993971] [G loss: 0.213604] [FAKE loss: 1.793040]  tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 815/1000] [D loss: 0.998387] [G loss: 0.212354] [FAKE loss: 1.801067]  tensor(0.8142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 816/1000] [D loss: 0.993986] [G loss: 0.209063] [FAKE loss: 1.795247]  tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 817/1000] [D loss: 0.998711] [G loss: 0.212332] [FAKE loss: 1.805151]  tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 818/1000] [D loss: 0.997371] [G loss: 0.210440] [FAKE loss: 1.804689]  tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 819/1000] [D loss: 0.995643] [G loss: 0.211179] [FAKE loss: 1.801423]  tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 820/1000] [D loss: 0.996786] [G loss: 0.209569] [FAKE loss: 1.806559]  tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 821/1000] [D loss: 0.991062] [G loss: 0.209539] [FAKE loss: 1.794975]  tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 822/1000] [D loss: 0.989023] [G loss: 0.210511] [FAKE loss: 1.792374]  tensor(0.8170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 823/1000] [D loss: 0.988375] [G loss: 0.207982] [FAKE loss: 1.790816]  tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 824/1000] [D loss: 0.986002] [G loss: 0.210271] [FAKE loss: 1.788661]  tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 825/1000] [D loss: 0.982274] [G loss: 0.213501] [FAKE loss: 1.781866]  tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 826/1000] [D loss: 0.975971] [G loss: 0.212602] [FAKE loss: 1.769107]  tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 827/1000] [D loss: 0.975659] [G loss: 0.213320] [FAKE loss: 1.769083]  tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 828/1000] [D loss: 0.967376] [G loss: 0.214827] [FAKE loss: 1.752704]  tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 829/1000] [D loss: 0.962558] [G loss: 0.215174] [FAKE loss: 1.741871]  tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 830/1000] [D loss: 0.956094] [G loss: 0.219574] [FAKE loss: 1.730754]  tensor(0.8083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 831/1000] [D loss: 0.948000] [G loss: 0.219310] [FAKE loss: 1.714143]  tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 832/1000] [D loss: 0.943283] [G loss: 0.223567] [FAKE loss: 1.705287]  tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 833/1000] [D loss: 0.941585] [G loss: 0.223673] [FAKE loss: 1.702374]  tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 834/1000] [D loss: 0.930526] [G loss: 0.228085] [FAKE loss: 1.678382]  tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 835/1000] [D loss: 0.924348] [G loss: 0.228275] [FAKE loss: 1.666171]  tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 836/1000] [D loss: 0.915415] [G loss: 0.233602] [FAKE loss: 1.647793]  tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 837/1000] [D loss: 0.908688] [G loss: 0.237145] [FAKE loss: 1.634542]  tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 838/1000] [D loss: 0.895875] [G loss: 0.240173] [FAKE loss: 1.607284]  tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 839/1000] [D loss: 0.890072] [G loss: 0.243243] [FAKE loss: 1.595436]  tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 840/1000] [D loss: 0.883740] [G loss: 0.247631] [FAKE loss: 1.582594]  tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 841/1000] [D loss: 0.874548] [G loss: 0.250381] [FAKE loss: 1.562766]  tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 842/1000] [D loss: 0.864464] [G loss: 0.256209] [FAKE loss: 1.539914]  tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 843/1000] [D loss: 0.857863] [G loss: 0.259423] [FAKE loss: 1.526025]  tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 844/1000] [D loss: 0.848372] [G loss: 0.264796] [FAKE loss: 1.505587]  tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 845/1000] [D loss: 0.838410] [G loss: 0.270013] [FAKE loss: 1.485000]  tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 846/1000] [D loss: 0.830366] [G loss: 0.273836] [FAKE loss: 1.465968]  tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 847/1000] [D loss: 0.823244] [G loss: 0.279688] [FAKE loss: 1.450160]  tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 848/1000] [D loss: 0.812517] [G loss: 0.285253] [FAKE loss: 1.426699]  tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 849/1000] [D loss: 0.803678] [G loss: 0.291729] [FAKE loss: 1.406859]  tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 850/1000] [D loss: 0.794672] [G loss: 0.296307] [FAKE loss: 1.386831]  tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 851/1000] [D loss: 0.786824] [G loss: 0.303153] [FAKE loss: 1.368430]  tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 852/1000] [D loss: 0.778563] [G loss: 0.308739] [FAKE loss: 1.350327]  tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 853/1000] [D loss: 0.769919] [G loss: 0.313119] [FAKE loss: 1.330585]  tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 854/1000] [D loss: 0.760875] [G loss: 0.322482] [FAKE loss: 1.309514]  tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 855/1000] [D loss: 0.751526] [G loss: 0.328552] [FAKE loss: 1.290338]  tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 856/1000] [D loss: 0.745095] [G loss: 0.335537] [FAKE loss: 1.273988]  tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 857/1000] [D loss: 0.736552] [G loss: 0.341993] [FAKE loss: 1.254809]  tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 858/1000] [D loss: 0.729085] [G loss: 0.349066] [FAKE loss: 1.236793]  tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 859/1000] [D loss: 0.722060] [G loss: 0.355597] [FAKE loss: 1.219193]  tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 860/1000] [D loss: 0.713763] [G loss: 0.365129] [FAKE loss: 1.202395]  tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 861/1000] [D loss: 0.707250] [G loss: 0.371327] [FAKE loss: 1.184938]  tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 862/1000] [D loss: 0.698450] [G loss: 0.379097] [FAKE loss: 1.163951]  tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 863/1000] [D loss: 0.692557] [G loss: 0.387497] [FAKE loss: 1.149608]  tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 864/1000] [D loss: 0.686405] [G loss: 0.393999] [FAKE loss: 1.133624]  tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 865/1000] [D loss: 0.678357] [G loss: 0.402276] [FAKE loss: 1.116183]  tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 866/1000] [D loss: 0.673723] [G loss: 0.410145] [FAKE loss: 1.102129]  tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 867/1000] [D loss: 0.667790] [G loss: 0.417554] [FAKE loss: 1.087964]  tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 868/1000] [D loss: 0.659737] [G loss: 0.427530] [FAKE loss: 1.068239]  tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 869/1000] [D loss: 0.655123] [G loss: 0.434197] [FAKE loss: 1.056705]  tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 870/1000] [D loss: 0.649505] [G loss: 0.443265] [FAKE loss: 1.041882]  tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 871/1000] [D loss: 0.643315] [G loss: 0.450563] [FAKE loss: 1.025893]  tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 872/1000] [D loss: 0.638715] [G loss: 0.459487] [FAKE loss: 1.012559]  tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 873/1000] [D loss: 0.634118] [G loss: 0.468524] [FAKE loss: 1.001042]  tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 874/1000] [D loss: 0.628760] [G loss: 0.474695] [FAKE loss: 0.986977]  tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 875/1000] [D loss: 0.623507] [G loss: 0.483552] [FAKE loss: 0.972731]  tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 876/1000] [D loss: 0.620941] [G loss: 0.492135] [FAKE loss: 0.963548]  tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 877/1000] [D loss: 0.615281] [G loss: 0.499752] [FAKE loss: 0.950303]  tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 878/1000] [D loss: 0.610202] [G loss: 0.507854] [FAKE loss: 0.937741]  tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 879/1000] [D loss: 0.607707] [G loss: 0.515042] [FAKE loss: 0.929632]  tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 880/1000] [D loss: 0.602047] [G loss: 0.527161] [FAKE loss: 0.916173]  tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 881/1000] [D loss: 0.599226] [G loss: 0.533540] [FAKE loss: 0.906725]  tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 882/1000] [D loss: 0.596349] [G loss: 0.542201] [FAKE loss: 0.899062]  tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 883/1000] [D loss: 0.591998] [G loss: 0.549571] [FAKE loss: 0.886962]  tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 884/1000] [D loss: 0.591036] [G loss: 0.557367] [FAKE loss: 0.883859]  tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 885/1000] [D loss: 0.587576] [G loss: 0.564163] [FAKE loss: 0.874401]  tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 886/1000] [D loss: 0.583176] [G loss: 0.572689] [FAKE loss: 0.862632]  tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 887/1000] [D loss: 0.580251] [G loss: 0.581214] [FAKE loss: 0.855090]  tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 888/1000] [D loss: 0.577707] [G loss: 0.588646] [FAKE loss: 0.849304]  tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 889/1000] [D loss: 0.572715] [G loss: 0.594051] [FAKE loss: 0.838124]  tensor(0.5585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 890/1000] [D loss: 0.570698] [G loss: 0.599959] [FAKE loss: 0.833828]  tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 891/1000] [D loss: 0.570754] [G loss: 0.605003] [FAKE loss: 0.830778]  tensor(0.5522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 892/1000] [D loss: 0.568910] [G loss: 0.609198] [FAKE loss: 0.826840]  tensor(0.5499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 893/1000] [D loss: 0.567919] [G loss: 0.616283] [FAKE loss: 0.824505]  tensor(0.5485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 894/1000] [D loss: 0.565691] [G loss: 0.619931] [FAKE loss: 0.820449]  tensor(0.5465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 895/1000] [D loss: 0.565640] [G loss: 0.621362] [FAKE loss: 0.820840]  tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 896/1000] [D loss: 0.565963] [G loss: 0.622817] [FAKE loss: 0.820421]  tensor(0.5455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 897/1000] [D loss: 0.565224] [G loss: 0.623674] [FAKE loss: 0.821717]  tensor(0.5442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 898/1000] [D loss: 0.564837] [G loss: 0.626691] [FAKE loss: 0.821719]  tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 899/1000] [D loss: 0.562441] [G loss: 0.623809] [FAKE loss: 0.818649]  tensor(0.5418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 900/1000] [D loss: 0.563336] [G loss: 0.620407] [FAKE loss: 0.822002]  tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 901/1000] [D loss: 0.564423] [G loss: 0.620321] [FAKE loss: 0.825951]  tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 902/1000] [D loss: 0.566096] [G loss: 0.618023] [FAKE loss: 0.832371]  tensor(0.5479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 903/1000] [D loss: 0.567129] [G loss: 0.610774] [FAKE loss: 0.837378]  tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 904/1000] [D loss: 0.571087] [G loss: 0.609011] [FAKE loss: 0.847267]  tensor(0.5545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 905/1000] [D loss: 0.571303] [G loss: 0.603844] [FAKE loss: 0.850906]  tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 906/1000] [D loss: 0.572198] [G loss: 0.593932] [FAKE loss: 0.857648]  tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 907/1000] [D loss: 0.576095] [G loss: 0.589167] [FAKE loss: 0.870063]  tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 908/1000] [D loss: 0.581325] [G loss: 0.575386] [FAKE loss: 0.885327]  tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 909/1000] [D loss: 0.588040] [G loss: 0.566422] [FAKE loss: 0.902193]  tensor(0.5753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 910/1000] [D loss: 0.590953] [G loss: 0.553016] [FAKE loss: 0.913089]  tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 911/1000] [D loss: 0.599010] [G loss: 0.543186] [FAKE loss: 0.934854]  tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 912/1000] [D loss: 0.603923] [G loss: 0.530249] [FAKE loss: 0.950016]  tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 913/1000] [D loss: 0.611774] [G loss: 0.518720] [FAKE loss: 0.970489]  tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 914/1000] [D loss: 0.619304] [G loss: 0.503440] [FAKE loss: 0.992940]  tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 915/1000] [D loss: 0.626688] [G loss: 0.486852] [FAKE loss: 1.013312]  tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 916/1000] [D loss: 0.642138] [G loss: 0.473204] [FAKE loss: 1.048313]  tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 917/1000] [D loss: 0.645078] [G loss: 0.460539] [FAKE loss: 1.061445]  tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 918/1000] [D loss: 0.655707] [G loss: 0.441621] [FAKE loss: 1.088328]  tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 919/1000] [D loss: 0.668916] [G loss: 0.424885] [FAKE loss: 1.120880]  tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 920/1000] [D loss: 0.681020] [G loss: 0.411226] [FAKE loss: 1.151174]  tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 921/1000] [D loss: 0.691474] [G loss: 0.396048] [FAKE loss: 1.178225]  tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 922/1000] [D loss: 0.703282] [G loss: 0.382182] [FAKE loss: 1.207729]  tensor(0.6865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 923/1000] [D loss: 0.719664] [G loss: 0.367491] [FAKE loss: 1.247139]  tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 924/1000] [D loss: 0.732007] [G loss: 0.352859] [FAKE loss: 1.277590]  tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 925/1000] [D loss: 0.748492] [G loss: 0.337457] [FAKE loss: 1.317995]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 926/1000] [D loss: 0.766399] [G loss: 0.322337] [FAKE loss: 1.358472]  tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 927/1000] [D loss: 0.777236] [G loss: 0.311125] [FAKE loss: 1.387652]  tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 928/1000] [D loss: 0.797243] [G loss: 0.294247] [FAKE loss: 1.431559]  tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 929/1000] [D loss: 0.814312] [G loss: 0.283595] [FAKE loss: 1.472096]  tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 930/1000] [D loss: 0.833065] [G loss: 0.269704] [FAKE loss: 1.515769]  tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 931/1000] [D loss: 0.844525] [G loss: 0.258190] [FAKE loss: 1.544080]  tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 932/1000] [D loss: 0.865041] [G loss: 0.246574] [FAKE loss: 1.590436]  tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 933/1000] [D loss: 0.883524] [G loss: 0.235317] [FAKE loss: 1.630520]  tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 934/1000] [D loss: 0.903176] [G loss: 0.225152] [FAKE loss: 1.675820]  tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 935/1000] [D loss: 0.919679] [G loss: 0.215160] [FAKE loss: 1.713097]  tensor(0.8081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 936/1000] [D loss: 0.942048] [G loss: 0.205386] [FAKE loss: 1.763816]  tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 937/1000] [D loss: 0.960040] [G loss: 0.197373] [FAKE loss: 1.803658]  tensor(0.8243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 938/1000] [D loss: 0.979638] [G loss: 0.187129] [FAKE loss: 1.845835]  tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 939/1000] [D loss: 0.998103] [G loss: 0.179011] [FAKE loss: 1.887953]  tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 940/1000] [D loss: 1.023539] [G loss: 0.171515] [FAKE loss: 1.942368]  tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 941/1000] [D loss: 1.035820] [G loss: 0.163332] [FAKE loss: 1.969737]  tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 942/1000] [D loss: 1.054497] [G loss: 0.156193] [FAKE loss: 2.011184]  tensor(0.8564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 943/1000] [D loss: 1.077179] [G loss: 0.150048] [FAKE loss: 2.059220]  tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 944/1000] [D loss: 1.096675] [G loss: 0.143918] [FAKE loss: 2.101514]  tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 945/1000] [D loss: 1.115924] [G loss: 0.138333] [FAKE loss: 2.142750]  tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 946/1000] [D loss: 1.130344] [G loss: 0.131990] [FAKE loss: 2.175349]  tensor(0.8771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 947/1000] [D loss: 1.150436] [G loss: 0.127748] [FAKE loss: 2.217905]  tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 948/1000] [D loss: 1.162980] [G loss: 0.123271] [FAKE loss: 2.245453]  tensor(0.8848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 949/1000] [D loss: 1.181376] [G loss: 0.117347] [FAKE loss: 2.284653]  tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 950/1000] [D loss: 1.199340] [G loss: 0.115077] [FAKE loss: 2.323044]  tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 951/1000] [D loss: 1.213493] [G loss: 0.110265] [FAKE loss: 2.352812]  tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 952/1000] [D loss: 1.229577] [G loss: 0.106953] [FAKE loss: 2.386823]  tensor(0.8992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 953/1000] [D loss: 1.241097] [G loss: 0.103669] [FAKE loss: 2.411662]  tensor(0.9016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 954/1000] [D loss: 1.258222] [G loss: 0.100864] [FAKE loss: 2.447697]  tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 955/1000] [D loss: 1.270269] [G loss: 0.098070] [FAKE loss: 2.471833]  tensor(0.9073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 956/1000] [D loss: 1.284789] [G loss: 0.095852] [FAKE loss: 2.502817]  tensor(0.9094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 957/1000] [D loss: 1.292503] [G loss: 0.094216] [FAKE loss: 2.519305]  tensor(0.9113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 958/1000] [D loss: 1.305838] [G loss: 0.091184] [FAKE loss: 2.548678]  tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 959/1000] [D loss: 1.312984] [G loss: 0.090925] [FAKE loss: 2.562851]  tensor(0.9146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 960/1000] [D loss: 1.326222] [G loss: 0.088241] [FAKE loss: 2.589726]  tensor(0.9166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 961/1000] [D loss: 1.327894] [G loss: 0.087042] [FAKE loss: 2.594419]  tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 962/1000] [D loss: 1.335557] [G loss: 0.085635] [FAKE loss: 2.610150]  tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 963/1000] [D loss: 1.341024] [G loss: 0.084629] [FAKE loss: 2.621918]  tensor(0.9191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 964/1000] [D loss: 1.344367] [G loss: 0.084505] [FAKE loss: 2.628358]  tensor(0.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 965/1000] [D loss: 1.344642] [G loss: 0.084159] [FAKE loss: 2.629481]  tensor(0.9213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 966/1000] [D loss: 1.351908] [G loss: 0.084114] [FAKE loss: 2.644196]  tensor(0.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 967/1000] [D loss: 1.350116] [G loss: 0.083226] [FAKE loss: 2.640219]  tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 968/1000] [D loss: 1.355353] [G loss: 0.082656] [FAKE loss: 2.651066]  tensor(0.9210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 969/1000] [D loss: 1.355539] [G loss: 0.083024] [FAKE loss: 2.649827]  tensor(0.9214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 970/1000] [D loss: 1.350307] [G loss: 0.083093] [FAKE loss: 2.639651]  tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 971/1000] [D loss: 1.349008] [G loss: 0.084384] [FAKE loss: 2.636326]  tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 972/1000] [D loss: 1.340036] [G loss: 0.084179] [FAKE loss: 2.617682]  tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 973/1000] [D loss: 1.333389] [G loss: 0.085075] [FAKE loss: 2.603696]  tensor(0.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 974/1000] [D loss: 1.331539] [G loss: 0.087434] [FAKE loss: 2.599223]  tensor(0.9179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 975/1000] [D loss: 1.323263] [G loss: 0.088168] [FAKE loss: 2.582185]  tensor(0.9163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 976/1000] [D loss: 1.313386] [G loss: 0.089470] [FAKE loss: 2.560096]  tensor(0.9148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 977/1000] [D loss: 1.306388] [G loss: 0.091448] [FAKE loss: 2.544962]  tensor(0.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 978/1000] [D loss: 1.292908] [G loss: 0.093065] [FAKE loss: 2.516174]  tensor(0.9116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 979/1000] [D loss: 1.280887] [G loss: 0.095541] [FAKE loss: 2.489964]  tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 980/1000] [D loss: 1.270779] [G loss: 0.097651] [FAKE loss: 2.468374]  tensor(0.9077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 981/1000] [D loss: 1.262621] [G loss: 0.100134] [FAKE loss: 2.449489]  tensor(0.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 982/1000] [D loss: 1.250505] [G loss: 0.103179] [FAKE loss: 2.423711]  tensor(0.9032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 983/1000] [D loss: 1.229309] [G loss: 0.106611] [FAKE loss: 2.378704]  tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 984/1000] [D loss: 1.217193] [G loss: 0.109789] [FAKE loss: 2.351285]  tensor(0.8962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 985/1000] [D loss: 1.203915] [G loss: 0.113661] [FAKE loss: 2.322356]  tensor(0.8937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 986/1000] [D loss: 1.188561] [G loss: 0.118549] [FAKE loss: 2.288255]  tensor(0.8906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 987/1000] [D loss: 1.168707] [G loss: 0.122070] [FAKE loss: 2.244565]  tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 988/1000] [D loss: 1.152013] [G loss: 0.126630] [FAKE loss: 2.208237]  tensor(0.8813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 989/1000] [D loss: 1.137206] [G loss: 0.131508] [FAKE loss: 2.175003]  tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 990/1000] [D loss: 1.120426] [G loss: 0.136283] [FAKE loss: 2.137195]  tensor(0.8726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 991/1000] [D loss: 1.103661] [G loss: 0.142085] [FAKE loss: 2.099536]  tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 992/1000] [D loss: 1.088976] [G loss: 0.147606] [FAKE loss: 2.064959]  tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 993/1000] [D loss: 1.071167] [G loss: 0.154133] [FAKE loss: 2.023861]  tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 994/1000] [D loss: 1.055457] [G loss: 0.161493] [FAKE loss: 1.987651]  tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 995/1000] [D loss: 1.037858] [G loss: 0.166089] [FAKE loss: 1.946883]  tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 996/1000] [D loss: 1.018296] [G loss: 0.173356] [FAKE loss: 1.901853]  tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 997/1000] [D loss: 1.003706] [G loss: 0.182161] [FAKE loss: 1.864605]  tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 998/1000] [D loss: 0.985201] [G loss: 0.190077] [FAKE loss: 1.821527]  tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 999/1000] [D loss: 0.967578] [G loss: 0.197818] [FAKE loss: 1.779824]  tensor(0.8217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata[1][15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VNqEGGHTf2g",
        "outputId": "953dcccb-cd81-4c3a-8909-80c209a8e246"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4545, 0.4319, 0.5340, 0.5422, 0.4173, 0.5004, 0.4007, 0.5746, 0.4306])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newday0[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydcAhZJ6jNl2",
        "outputId": "8eebd577-89bd-4a49-ce8c-66df5242dd3f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.65217391, 0.72686896, 0.92376881, 0.39502165, 0.45635057,\n",
              "       0.09213187, 0.15212658, 0.09833333, 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim \n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input = 9 \n",
        "    self.output= 1\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input, 32), # input size, hidden size\n",
        "        nn.LeakyReLU(0.5),\n",
        "        #nn.Dropout(0.2),\n",
        "        nn.Linear(32, 64),\n",
        "        nn.LeakyReLU(0.8),\n",
        "        nn.Linear(64, 128),\n",
        "        nn.LeakyReLU(0.5),\n",
        "        nn.Linear(128, self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.features = 9 # 피쳐수\n",
        "    self.output = 9  # 데이터수\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.features, 64), # input size, hidden size\n",
        "        nn.Sigmoid(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(64, 32),\n",
        "        #nn.LeakyReLU(0.2),\n",
        "        nn.Linear(32, self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print('generator',x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "# 모델 정의\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
        "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
        "\n",
        "criterion = nn.BCELoss().to(device)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=g_optim, mode='min', verbose=True, patience=10, factor=0.5)\n",
        "\n",
        "import time\n",
        "n_epochs = 1000\n",
        "noise = 9\n",
        "start_time = time.time()\n",
        "newdata = []\n",
        "testdata = []\n",
        "#print(real_data)\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  test = day0.iloc[:28].values\n",
        "  \n",
        "  nptonn = torch.from_numpy(newday0).float()\n",
        "\n",
        "  real = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(1.0) # \n",
        "  fake = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(0.0) # \n",
        "\n",
        "  real_data = nptonn.cuda()\n",
        "  g_optim.zero_grad()\n",
        "\n",
        "  z0 = torch.normal(mean=11.5, std=6.9, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z1 = torch.normal(mean=25.78, std=4.3, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z2 = torch.normal(mean=54.91, std=12.2, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z3 = torch.normal(mean=533.833, std=144.1, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z4 = torch.normal(mean=1.273, std=0.932, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z5 = torch.normal(mean=430.600, std=491.308, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z6 = torch.normal(mean=6765.408, std=9450.28, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z7 = torch.normal(mean=1309.564, std=2653.722, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z8 = torch.normal(mean=856.852, std=1938.17, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  zz = torch.normal(mean=0, std=1, size=(nptonn.shape[0], noise)).cuda()\n",
        "\n",
        "  z = torch.cat([z0,z1,z2,z3,z4,z5,z6,z7,z8], dim=1) #[M, N+N, K]\n",
        "  #print(z.size())\n",
        "\n",
        "  generated_dis = generator(z) # create distribution\n",
        "  #print(generated_dis.size())\n",
        "  #print(real_data.size())\n",
        "  generated_dis_value = generated_dis.detach().cpu()\n",
        "  g_loss =  criterion(discriminator(generated_dis), real) # calculate generator loss\n",
        "  \n",
        "  # update generator\n",
        "  g_loss.backward()\n",
        "  g_optim.step()\n",
        "\n",
        "  # update discriminator\n",
        "  real_loss = criterion(discriminator(real_data), real)\n",
        "  r_score = discriminator(real_data).mean()\n",
        "  fake_loss = criterion(discriminator(generated_dis.detach()), fake)\n",
        "  g_score = discriminator(generated_dis).mean()\n",
        "  d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "  if g_score > 0.8 :\n",
        "    newdata.append(generated_dis_value)\n",
        "\n",
        "  d_loss.backward()\n",
        "  d_optim.step()\n",
        "\n",
        "  print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [FAKE loss: {fake_loss.item():.6f}] \",\n",
        "        g_score, r_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udw2NdEwoM_z",
        "outputId": "b19b4d7a-9750-464d-b97c-426658b2683f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/1000] [D loss: 0.698281] [G loss: 0.717518] [FAKE loss: 0.669360]  tensor(0.4880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 1/1000] [D loss: 0.698361] [G loss: 0.711011] [FAKE loss: 0.675600]  tensor(0.4911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 2/1000] [D loss: 0.698465] [G loss: 0.704787] [FAKE loss: 0.681645]  tensor(0.4942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 3/1000] [D loss: 0.698607] [G loss: 0.698636] [FAKE loss: 0.687691]  tensor(0.4973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 4/1000] [D loss: 0.698783] [G loss: 0.692512] [FAKE loss: 0.693785]  tensor(0.5003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 5/1000] [D loss: 0.698999] [G loss: 0.686378] [FAKE loss: 0.699965]  tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 6/1000] [D loss: 0.699235] [G loss: 0.680259] [FAKE loss: 0.706207]  tensor(0.5065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 7/1000] [D loss: 0.699540] [G loss: 0.674055] [FAKE loss: 0.712613]  tensor(0.5096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 8/1000] [D loss: 0.699876] [G loss: 0.667838] [FAKE loss: 0.719116]  tensor(0.5128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 9/1000] [D loss: 0.700279] [G loss: 0.661536] [FAKE loss: 0.725792]  tensor(0.5161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 10/1000] [D loss: 0.700729] [G loss: 0.655191] [FAKE loss: 0.732603]  tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 11/1000] [D loss: 0.701232] [G loss: 0.648794] [FAKE loss: 0.739561]  tensor(0.5227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 12/1000] [D loss: 0.701769] [G loss: 0.642387] [FAKE loss: 0.746625]  tensor(0.5260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 13/1000] [D loss: 0.702356] [G loss: 0.635941] [FAKE loss: 0.753827]  tensor(0.5294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 14/1000] [D loss: 0.703021] [G loss: 0.629414] [FAKE loss: 0.761223]  tensor(0.5329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 15/1000] [D loss: 0.703728] [G loss: 0.622867] [FAKE loss: 0.768745]  tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 16/1000] [D loss: 0.704520] [G loss: 0.616235] [FAKE loss: 0.776473]  tensor(0.5400, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 17/1000] [D loss: 0.705356] [G loss: 0.609595] [FAKE loss: 0.784324]  tensor(0.5436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 18/1000] [D loss: 0.706243] [G loss: 0.602937] [FAKE loss: 0.792312]  tensor(0.5472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 19/1000] [D loss: 0.707186] [G loss: 0.596253] [FAKE loss: 0.800449]  tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 20/1000] [D loss: 0.708204] [G loss: 0.589517] [FAKE loss: 0.808775]  tensor(0.5546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 21/1000] [D loss: 0.709276] [G loss: 0.582762] [FAKE loss: 0.817250]  tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 22/1000] [D loss: 0.710390] [G loss: 0.576013] [FAKE loss: 0.825848]  tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 23/1000] [D loss: 0.711592] [G loss: 0.569199] [FAKE loss: 0.834665]  tensor(0.5660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 24/1000] [D loss: 0.712885] [G loss: 0.562321] [FAKE loss: 0.843707]  tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 25/1000] [D loss: 0.714251] [G loss: 0.555412] [FAKE loss: 0.852935]  tensor(0.5738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 26/1000] [D loss: 0.715718] [G loss: 0.548435] [FAKE loss: 0.862407]  tensor(0.5779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 27/1000] [D loss: 0.717314] [G loss: 0.541356] [FAKE loss: 0.872180]  tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 28/1000] [D loss: 0.719006] [G loss: 0.534230] [FAKE loss: 0.882186]  tensor(0.5861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 29/1000] [D loss: 0.720813] [G loss: 0.527036] [FAKE loss: 0.892463]  tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 30/1000] [D loss: 0.722711] [G loss: 0.519816] [FAKE loss: 0.902961]  tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 31/1000] [D loss: 0.724753] [G loss: 0.512504] [FAKE loss: 0.913785]  tensor(0.5990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 32/1000] [D loss: 0.726901] [G loss: 0.505157] [FAKE loss: 0.924862]  tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 33/1000] [D loss: 0.729133] [G loss: 0.497809] [FAKE loss: 0.936148]  tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 34/1000] [D loss: 0.731563] [G loss: 0.490320] [FAKE loss: 0.947869]  tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 35/1000] [D loss: 0.734067] [G loss: 0.482857] [FAKE loss: 0.959777]  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 36/1000] [D loss: 0.736756] [G loss: 0.475285] [FAKE loss: 0.972099]  tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 37/1000] [D loss: 0.739622] [G loss: 0.467627] [FAKE loss: 0.984815]  tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 38/1000] [D loss: 0.742659] [G loss: 0.459900] [FAKE loss: 0.997912]  tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 39/1000] [D loss: 0.745851] [G loss: 0.452128] [FAKE loss: 1.011364]  tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 40/1000] [D loss: 0.749264] [G loss: 0.444247] [FAKE loss: 1.025303]  tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 41/1000] [D loss: 0.752881] [G loss: 0.436288] [FAKE loss: 1.039695]  tensor(0.6464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 42/1000] [D loss: 0.756687] [G loss: 0.428278] [FAKE loss: 1.054508]  tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 43/1000] [D loss: 0.760675] [G loss: 0.420238] [FAKE loss: 1.069726]  tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 44/1000] [D loss: 0.764833] [G loss: 0.412188] [FAKE loss: 1.085322]  tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 45/1000] [D loss: 0.769237] [G loss: 0.404064] [FAKE loss: 1.101444]  tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 46/1000] [D loss: 0.773826] [G loss: 0.395938] [FAKE loss: 1.117969]  tensor(0.6731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 47/1000] [D loss: 0.778649] [G loss: 0.387773] [FAKE loss: 1.134992]  tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 48/1000] [D loss: 0.783673] [G loss: 0.379613] [FAKE loss: 1.152444]  tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 49/1000] [D loss: 0.788956] [G loss: 0.371413] [FAKE loss: 1.170440]  tensor(0.6898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 50/1000] [D loss: 0.794526] [G loss: 0.363165] [FAKE loss: 1.189028]  tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 51/1000] [D loss: 0.800338] [G loss: 0.354922] [FAKE loss: 1.208114]  tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 52/1000] [D loss: 0.806417] [G loss: 0.346675] [FAKE loss: 1.227746]  tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 53/1000] [D loss: 0.812810] [G loss: 0.338398] [FAKE loss: 1.248010]  tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 54/1000] [D loss: 0.819432] [G loss: 0.330174] [FAKE loss: 1.268734]  tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 55/1000] [D loss: 0.826289] [G loss: 0.322010] [FAKE loss: 1.289918]  tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 56/1000] [D loss: 0.833411] [G loss: 0.313887] [FAKE loss: 1.311623]  tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 57/1000] [D loss: 0.840719] [G loss: 0.305876] [FAKE loss: 1.333684]  tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 58/1000] [D loss: 0.848515] [G loss: 0.297770] [FAKE loss: 1.356697]  tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 59/1000] [D loss: 0.856421] [G loss: 0.289848] [FAKE loss: 1.379902]  tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 60/1000] [D loss: 0.864589] [G loss: 0.282010] [FAKE loss: 1.403591]  tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 61/1000] [D loss: 0.873230] [G loss: 0.274131] [FAKE loss: 1.428180]  tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 62/1000] [D loss: 0.881966] [G loss: 0.266461] [FAKE loss: 1.452902]  tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 63/1000] [D loss: 0.891304] [G loss: 0.258698] [FAKE loss: 1.478763]  tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 64/1000] [D loss: 0.900454] [G loss: 0.251321] [FAKE loss: 1.504171]  tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 65/1000] [D loss: 0.910233] [G loss: 0.243858] [FAKE loss: 1.530750]  tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 66/1000] [D loss: 0.920090] [G loss: 0.236627] [FAKE loss: 1.557388]  tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 67/1000] [D loss: 0.930351] [G loss: 0.229454] [FAKE loss: 1.584728]  tensor(0.7950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 68/1000] [D loss: 0.940681] [G loss: 0.222519] [FAKE loss: 1.612094]  tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 69/1000] [D loss: 0.951164] [G loss: 0.215775] [FAKE loss: 1.639637]  tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 70/1000] [D loss: 0.961905] [G loss: 0.209168] [FAKE loss: 1.667559]  tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 71/1000] [D loss: 0.972505] [G loss: 0.202881] [FAKE loss: 1.695048]  tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 72/1000] [D loss: 0.983341] [G loss: 0.196737] [FAKE loss: 1.722848]  tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 73/1000] [D loss: 0.994126] [G loss: 0.190854] [FAKE loss: 1.750373]  tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 74/1000] [D loss: 1.004947] [G loss: 0.185187] [FAKE loss: 1.777785]  tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 75/1000] [D loss: 1.015622] [G loss: 0.179801] [FAKE loss: 1.804706]  tensor(0.8354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 76/1000] [D loss: 1.025973] [G loss: 0.174750] [FAKE loss: 1.830768]  tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 77/1000] [D loss: 1.036241] [G loss: 0.169922] [FAKE loss: 1.856446]  tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 78/1000] [D loss: 1.046299] [G loss: 0.165355] [FAKE loss: 1.881473]  tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 79/1000] [D loss: 1.056032] [G loss: 0.161082] [FAKE loss: 1.905609]  tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 80/1000] [D loss: 1.065260] [G loss: 0.157138] [FAKE loss: 1.928487]  tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 81/1000] [D loss: 1.074156] [G loss: 0.153451] [FAKE loss: 1.950445]  tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 82/1000] [D loss: 1.082379] [G loss: 0.150118] [FAKE loss: 1.970793]  tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 83/1000] [D loss: 1.090282] [G loss: 0.147006] [FAKE loss: 1.990234]  tensor(0.8633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 84/1000] [D loss: 1.097196] [G loss: 0.144313] [FAKE loss: 2.007425]  tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 85/1000] [D loss: 1.103761] [G loss: 0.141820] [FAKE loss: 2.023641]  tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 86/1000] [D loss: 1.109329] [G loss: 0.139714] [FAKE loss: 2.037585]  tensor(0.8696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 87/1000] [D loss: 1.114165] [G loss: 0.137898] [FAKE loss: 2.049788]  tensor(0.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 88/1000] [D loss: 1.118149] [G loss: 0.136397] [FAKE loss: 2.060004]  tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 89/1000] [D loss: 1.121127] [G loss: 0.135246] [FAKE loss: 2.067928]  tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 90/1000] [D loss: 1.123767] [G loss: 0.134241] [FAKE loss: 2.074897]  tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 91/1000] [D loss: 1.124856] [G loss: 0.133727] [FAKE loss: 2.078483]  tensor(0.8748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 92/1000] [D loss: 1.125111] [G loss: 0.133492] [FAKE loss: 2.080124]  tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 93/1000] [D loss: 1.124753] [G loss: 0.133473] [FAKE loss: 2.080259]  tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 94/1000] [D loss: 1.123222] [G loss: 0.133829] [FAKE loss: 2.077771]  tensor(0.8747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 95/1000] [D loss: 1.121233] [G loss: 0.134356] [FAKE loss: 2.074094]  tensor(0.8743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 96/1000] [D loss: 1.117571] [G loss: 0.135408] [FAKE loss: 2.066801]  tensor(0.8734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 97/1000] [D loss: 1.113631] [G loss: 0.136590] [FAKE loss: 2.058681]  tensor(0.8723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 98/1000] [D loss: 1.108614] [G loss: 0.138142] [FAKE loss: 2.048142]  tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 99/1000] [D loss: 1.102626] [G loss: 0.140043] [FAKE loss: 2.035396]  tensor(0.8693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 100/1000] [D loss: 1.096117] [G loss: 0.142170] [FAKE loss: 2.021351]  tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 101/1000] [D loss: 1.088967] [G loss: 0.144569] [FAKE loss: 2.005768]  tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 102/1000] [D loss: 1.080940] [G loss: 0.147333] [FAKE loss: 1.988180]  tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 103/1000] [D loss: 1.072382] [G loss: 0.150363] [FAKE loss: 1.969284]  tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 104/1000] [D loss: 1.063002] [G loss: 0.153774] [FAKE loss: 1.948501]  tensor(0.8575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 105/1000] [D loss: 1.053423] [G loss: 0.157378] [FAKE loss: 1.927082]  tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 106/1000] [D loss: 1.043036] [G loss: 0.161396] [FAKE loss: 1.903815]  tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 107/1000] [D loss: 1.032386] [G loss: 0.165659] [FAKE loss: 1.879794]  tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 108/1000] [D loss: 1.021276] [G loss: 0.170259] [FAKE loss: 1.854631]  tensor(0.8435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 109/1000] [D loss: 1.010355] [G loss: 0.174967] [FAKE loss: 1.829630]  tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 110/1000] [D loss: 0.998634] [G loss: 0.180174] [FAKE loss: 1.802819]  tensor(0.8351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 111/1000] [D loss: 0.986843] [G loss: 0.185620] [FAKE loss: 1.775665]  tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 112/1000] [D loss: 0.974965] [G loss: 0.191326] [FAKE loss: 1.748139]  tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 113/1000] [D loss: 0.963015] [G loss: 0.197297] [FAKE loss: 1.720278]  tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 114/1000] [D loss: 0.950950] [G loss: 0.203568] [FAKE loss: 1.692002]  tensor(0.8158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 115/1000] [D loss: 0.938914] [G loss: 0.210089] [FAKE loss: 1.663609]  tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 116/1000] [D loss: 0.926724] [G loss: 0.216957] [FAKE loss: 1.634740]  tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 117/1000] [D loss: 0.914642] [G loss: 0.224063] [FAKE loss: 1.605925]  tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 118/1000] [D loss: 0.902849] [G loss: 0.231317] [FAKE loss: 1.577536]  tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 119/1000] [D loss: 0.891053] [G loss: 0.238877] [FAKE loss: 1.548999]  tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 120/1000] [D loss: 0.879656] [G loss: 0.246531] [FAKE loss: 1.521124]  tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 121/1000] [D loss: 0.868144] [G loss: 0.254564] [FAKE loss: 1.492894]  tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 122/1000] [D loss: 0.857007] [G loss: 0.262706] [FAKE loss: 1.465299]  tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 123/1000] [D loss: 0.845904] [G loss: 0.271158] [FAKE loss: 1.437667]  tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 124/1000] [D loss: 0.835069] [G loss: 0.279778] [FAKE loss: 1.410476]  tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 125/1000] [D loss: 0.824626] [G loss: 0.288480] [FAKE loss: 1.383984]  tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 126/1000] [D loss: 0.814528] [G loss: 0.297284] [FAKE loss: 1.358106]  tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 127/1000] [D loss: 0.804797] [G loss: 0.306159] [FAKE loss: 1.332897]  tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 128/1000] [D loss: 0.795208] [G loss: 0.315258] [FAKE loss: 1.307921]  tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 129/1000] [D loss: 0.786019] [G loss: 0.324383] [FAKE loss: 1.283702]  tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 130/1000] [D loss: 0.777215] [G loss: 0.333527] [FAKE loss: 1.260224]  tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 131/1000] [D loss: 0.768834] [G loss: 0.342639] [FAKE loss: 1.237566]  tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 132/1000] [D loss: 0.760699] [G loss: 0.351844] [FAKE loss: 1.215392]  tensor(0.7034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 133/1000] [D loss: 0.752970] [G loss: 0.360990] [FAKE loss: 1.194028]  tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 134/1000] [D loss: 0.745614] [G loss: 0.370082] [FAKE loss: 1.173421]  tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 135/1000] [D loss: 0.738524] [G loss: 0.379195] [FAKE loss: 1.153367]  tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 136/1000] [D loss: 0.731827] [G loss: 0.388191] [FAKE loss: 1.134130]  tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 137/1000] [D loss: 0.725431] [G loss: 0.397129] [FAKE loss: 1.115541]  tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 138/1000] [D loss: 0.719491] [G loss: 0.405833] [FAKE loss: 1.097921]  tensor(0.6664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 139/1000] [D loss: 0.713811] [G loss: 0.414469] [FAKE loss: 1.080888]  tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 140/1000] [D loss: 0.708500] [G loss: 0.422901] [FAKE loss: 1.064670]  tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 141/1000] [D loss: 0.703500] [G loss: 0.431162] [FAKE loss: 1.049163]  tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 142/1000] [D loss: 0.698704] [G loss: 0.439340] [FAKE loss: 1.034166]  tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 143/1000] [D loss: 0.694323] [G loss: 0.447181] [FAKE loss: 1.020109]  tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 144/1000] [D loss: 0.690210] [G loss: 0.454817] [FAKE loss: 1.006708]  tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 145/1000] [D loss: 0.686389] [G loss: 0.462195] [FAKE loss: 0.994025]  tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 146/1000] [D loss: 0.682783] [G loss: 0.469379] [FAKE loss: 0.981917]  tensor(0.6254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 147/1000] [D loss: 0.679504] [G loss: 0.476213] [FAKE loss: 0.970612]  tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 148/1000] [D loss: 0.676355] [G loss: 0.482909] [FAKE loss: 0.959730]  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 149/1000] [D loss: 0.673532] [G loss: 0.489203] [FAKE loss: 0.949674]  tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 150/1000] [D loss: 0.671004] [G loss: 0.495111] [FAKE loss: 0.940385]  tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 151/1000] [D loss: 0.668726] [G loss: 0.500660] [FAKE loss: 0.931783]  tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 152/1000] [D loss: 0.666561] [G loss: 0.506012] [FAKE loss: 0.923604]  tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 153/1000] [D loss: 0.664793] [G loss: 0.510773] [FAKE loss: 0.916421]  tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 154/1000] [D loss: 0.663036] [G loss: 0.515433] [FAKE loss: 0.909470]  tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 155/1000] [D loss: 0.661574] [G loss: 0.519601] [FAKE loss: 0.903322]  tensor(0.5948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 156/1000] [D loss: 0.660384] [G loss: 0.523287] [FAKE loss: 0.897937]  tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 157/1000] [D loss: 0.659246] [G loss: 0.526780] [FAKE loss: 0.892880]  tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 158/1000] [D loss: 0.658417] [G loss: 0.529713] [FAKE loss: 0.888666]  tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 159/1000] [D loss: 0.657802] [G loss: 0.532204] [FAKE loss: 0.885111]  tensor(0.5873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 160/1000] [D loss: 0.657247] [G loss: 0.534464] [FAKE loss: 0.881907]  tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 161/1000] [D loss: 0.656957] [G loss: 0.536192] [FAKE loss: 0.879467]  tensor(0.5850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 162/1000] [D loss: 0.656702] [G loss: 0.537713] [FAKE loss: 0.877327]  tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 163/1000] [D loss: 0.656696] [G loss: 0.538717] [FAKE loss: 0.875921]  tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 164/1000] [D loss: 0.656842] [G loss: 0.539340] [FAKE loss: 0.875050]  tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 165/1000] [D loss: 0.657130] [G loss: 0.539592] [FAKE loss: 0.874697]  tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 166/1000] [D loss: 0.657593] [G loss: 0.539435] [FAKE loss: 0.874922]  tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 167/1000] [D loss: 0.658253] [G loss: 0.538828] [FAKE loss: 0.875771]  tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 168/1000] [D loss: 0.658795] [G loss: 0.538232] [FAKE loss: 0.876610]  tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 169/1000] [D loss: 0.659765] [G loss: 0.536868] [FAKE loss: 0.878527]  tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 170/1000] [D loss: 0.660741] [G loss: 0.535347] [FAKE loss: 0.880676]  tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 171/1000] [D loss: 0.661832] [G loss: 0.533512] [FAKE loss: 0.883273]  tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 172/1000] [D loss: 0.663095] [G loss: 0.531298] [FAKE loss: 0.886425]  tensor(0.5879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 173/1000] [D loss: 0.664444] [G loss: 0.528830] [FAKE loss: 0.889958]  tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 174/1000] [D loss: 0.665971] [G loss: 0.525990] [FAKE loss: 0.894050]  tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 175/1000] [D loss: 0.667661] [G loss: 0.522808] [FAKE loss: 0.898670]  tensor(0.5929, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 176/1000] [D loss: 0.669341] [G loss: 0.519534] [FAKE loss: 0.903460]  tensor(0.5948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 177/1000] [D loss: 0.671180] [G loss: 0.515944] [FAKE loss: 0.908759]  tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 178/1000] [D loss: 0.673156] [G loss: 0.512079] [FAKE loss: 0.914515]  tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 179/1000] [D loss: 0.675289] [G loss: 0.507926] [FAKE loss: 0.920763]  tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 180/1000] [D loss: 0.677412] [G loss: 0.503717] [FAKE loss: 0.927163]  tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 181/1000] [D loss: 0.679847] [G loss: 0.499039] [FAKE loss: 0.934356]  tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 182/1000] [D loss: 0.682339] [G loss: 0.494242] [FAKE loss: 0.941821]  tensor(0.6101, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 183/1000] [D loss: 0.684888] [G loss: 0.489335] [FAKE loss: 0.949558]  tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 184/1000] [D loss: 0.687832] [G loss: 0.483899] [FAKE loss: 0.958235]  tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 185/1000] [D loss: 0.690679] [G loss: 0.478577] [FAKE loss: 0.966861]  tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 186/1000] [D loss: 0.693953] [G loss: 0.472719] [FAKE loss: 0.976479]  tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 187/1000] [D loss: 0.696995] [G loss: 0.467156] [FAKE loss: 0.985765]  tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 188/1000] [D loss: 0.700323] [G loss: 0.461264] [FAKE loss: 0.995749]  tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 189/1000] [D loss: 0.703847] [G loss: 0.455167] [FAKE loss: 1.006246]  tensor(0.6344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 190/1000] [D loss: 0.707543] [G loss: 0.448911] [FAKE loss: 1.017201]  tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 191/1000] [D loss: 0.711474] [G loss: 0.442442] [FAKE loss: 1.028736]  tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 192/1000] [D loss: 0.715250] [G loss: 0.436201] [FAKE loss: 1.040063]  tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 193/1000] [D loss: 0.719462] [G loss: 0.429550] [FAKE loss: 1.052359]  tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 194/1000] [D loss: 0.723887] [G loss: 0.422747] [FAKE loss: 1.065173]  tensor(0.6553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 195/1000] [D loss: 0.728512] [G loss: 0.415828] [FAKE loss: 1.078474]  tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 196/1000] [D loss: 0.733038] [G loss: 0.409108] [FAKE loss: 1.091657]  tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 197/1000] [D loss: 0.738048] [G loss: 0.401996] [FAKE loss: 1.105883]  tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 198/1000] [D loss: 0.743084] [G loss: 0.394980] [FAKE loss: 1.120230]  tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 199/1000] [D loss: 0.748277] [G loss: 0.387938] [FAKE loss: 1.134953]  tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 200/1000] [D loss: 0.753731] [G loss: 0.380772] [FAKE loss: 1.150257]  tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 201/1000] [D loss: 0.759159] [G loss: 0.373769] [FAKE loss: 1.165560]  tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 202/1000] [D loss: 0.765306] [G loss: 0.366257] [FAKE loss: 1.182346]  tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 203/1000] [D loss: 0.770998] [G loss: 0.359308] [FAKE loss: 1.198264]  tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 204/1000] [D loss: 0.777190] [G loss: 0.352074] [FAKE loss: 1.215218]  tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 205/1000] [D loss: 0.783630] [G loss: 0.344796] [FAKE loss: 1.232697]  tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 206/1000] [D loss: 0.790169] [G loss: 0.337607] [FAKE loss: 1.250400]  tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 207/1000] [D loss: 0.796677] [G loss: 0.330617] [FAKE loss: 1.268058]  tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 208/1000] [D loss: 0.803692] [G loss: 0.323395] [FAKE loss: 1.286745]  tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 209/1000] [D loss: 0.810716] [G loss: 0.316349] [FAKE loss: 1.305456]  tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 210/1000] [D loss: 0.817923] [G loss: 0.309354] [FAKE loss: 1.324536]  tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 211/1000] [D loss: 0.825373] [G loss: 0.302351] [FAKE loss: 1.344098]  tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 212/1000] [D loss: 0.833026] [G loss: 0.295411] [FAKE loss: 1.364057]  tensor(0.7443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 213/1000] [D loss: 0.840388] [G loss: 0.288858] [FAKE loss: 1.383420]  tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 214/1000] [D loss: 0.848398] [G loss: 0.282050] [FAKE loss: 1.404058]  tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 215/1000] [D loss: 0.856118] [G loss: 0.275617] [FAKE loss: 1.424088]  tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 216/1000] [D loss: 0.864364] [G loss: 0.269031] [FAKE loss: 1.445140]  tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 217/1000] [D loss: 0.872582] [G loss: 0.262655] [FAKE loss: 1.466097]  tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 218/1000] [D loss: 0.880864] [G loss: 0.256429] [FAKE loss: 1.487139]  tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 219/1000] [D loss: 0.889876] [G loss: 0.249975] [FAKE loss: 1.509590]  tensor(0.7789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 220/1000] [D loss: 0.898102] [G loss: 0.244147] [FAKE loss: 1.530414]  tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 221/1000] [D loss: 0.907088] [G loss: 0.238084] [FAKE loss: 1.552696]  tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 222/1000] [D loss: 0.915793] [G loss: 0.232343] [FAKE loss: 1.574350]  tensor(0.7927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 223/1000] [D loss: 0.925219] [G loss: 0.226418] [FAKE loss: 1.597374]  tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 224/1000] [D loss: 0.933997] [G loss: 0.221003] [FAKE loss: 1.619026]  tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 225/1000] [D loss: 0.943271] [G loss: 0.215507] [FAKE loss: 1.641585]  tensor(0.8062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 226/1000] [D loss: 0.952487] [G loss: 0.210208] [FAKE loss: 1.663938]  tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 227/1000] [D loss: 0.961664] [G loss: 0.205097] [FAKE loss: 1.686120]  tensor(0.8146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 228/1000] [D loss: 0.970853] [G loss: 0.200143] [FAKE loss: 1.708226]  tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 229/1000] [D loss: 0.980089] [G loss: 0.195334] [FAKE loss: 1.730317]  tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 230/1000] [D loss: 0.989374] [G loss: 0.190630] [FAKE loss: 1.752396]  tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 231/1000] [D loss: 0.998558] [G loss: 0.186145] [FAKE loss: 1.774153]  tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 232/1000] [D loss: 1.007716] [G loss: 0.181788] [FAKE loss: 1.795733]  tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 233/1000] [D loss: 1.017110] [G loss: 0.177490] [FAKE loss: 1.817656]  tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 234/1000] [D loss: 1.025249] [G loss: 0.173801] [FAKE loss: 1.836937]  tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 235/1000] [D loss: 1.034717] [G loss: 0.169723] [FAKE loss: 1.858733]  tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 236/1000] [D loss: 1.043597] [G loss: 0.165991] [FAKE loss: 1.879209]  tensor(0.8471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 237/1000] [D loss: 1.051953] [G loss: 0.162564] [FAKE loss: 1.898487]  tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 238/1000] [D loss: 1.059968] [G loss: 0.159349] [FAKE loss: 1.916927]  tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 239/1000] [D loss: 1.067614] [G loss: 0.156359] [FAKE loss: 1.934466]  tensor(0.8553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 240/1000] [D loss: 1.075427] [G loss: 0.153387] [FAKE loss: 1.952174]  tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 241/1000] [D loss: 1.081880] [G loss: 0.150963] [FAKE loss: 1.966990]  tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 242/1000] [D loss: 1.089310] [G loss: 0.148281] [FAKE loss: 1.983584]  tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 243/1000] [D loss: 1.095765] [G loss: 0.146007] [FAKE loss: 1.998047]  tensor(0.8642, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 244/1000] [D loss: 1.101120] [G loss: 0.144118] [FAKE loss: 2.010125]  tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 245/1000] [D loss: 1.105730] [G loss: 0.142519] [FAKE loss: 2.020521]  tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 246/1000] [D loss: 1.110464] [G loss: 0.140923] [FAKE loss: 2.030972]  tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 247/1000] [D loss: 1.114199] [G loss: 0.139694] [FAKE loss: 2.039229]  tensor(0.8697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 248/1000] [D loss: 1.117890] [G loss: 0.138490] [FAKE loss: 2.047192]  tensor(0.8707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 249/1000] [D loss: 1.119773] [G loss: 0.137898] [FAKE loss: 2.051335]  tensor(0.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 250/1000] [D loss: 1.122896] [G loss: 0.136936] [FAKE loss: 2.057750]  tensor(0.8721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 251/1000] [D loss: 1.124051] [G loss: 0.136596] [FAKE loss: 2.060015]  tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 252/1000] [D loss: 1.124019] [G loss: 0.136662] [FAKE loss: 2.059691]  tensor(0.8723, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 253/1000] [D loss: 1.124026] [G loss: 0.136724] [FAKE loss: 2.059230]  tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 254/1000] [D loss: 1.123050] [G loss: 0.137105] [FAKE loss: 2.056580]  tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 255/1000] [D loss: 1.121228] [G loss: 0.137789] [FAKE loss: 2.052020]  tensor(0.8713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 256/1000] [D loss: 1.119571] [G loss: 0.138434] [FAKE loss: 2.047566]  tensor(0.8708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 257/1000] [D loss: 1.116564] [G loss: 0.139531] [FAKE loss: 2.040185]  tensor(0.8698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 258/1000] [D loss: 1.113006] [G loss: 0.140833] [FAKE loss: 2.031482]  tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 259/1000] [D loss: 1.108555] [G loss: 0.142456] [FAKE loss: 2.020765]  tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 260/1000] [D loss: 1.103627] [G loss: 0.144284] [FAKE loss: 2.008867]  tensor(0.8657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 261/1000] [D loss: 1.097865] [G loss: 0.146441] [FAKE loss: 1.995077]  tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 262/1000] [D loss: 1.091731] [G loss: 0.148789] [FAKE loss: 1.980317]  tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 263/1000] [D loss: 1.085473] [G loss: 0.151232] [FAKE loss: 1.965085]  tensor(0.8597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 264/1000] [D loss: 1.077633] [G loss: 0.154304] [FAKE loss: 1.946465]  tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 265/1000] [D loss: 1.069994] [G loss: 0.157405] [FAKE loss: 1.928025]  tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 266/1000] [D loss: 1.061997] [G loss: 0.160729] [FAKE loss: 1.908649]  tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 267/1000] [D loss: 1.053397] [G loss: 0.164391] [FAKE loss: 1.887849]  tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 268/1000] [D loss: 1.044245] [G loss: 0.168387] [FAKE loss: 1.865729]  tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 269/1000] [D loss: 1.034602] [G loss: 0.172714] [FAKE loss: 1.842415]  tensor(0.8414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 270/1000] [D loss: 1.024692] [G loss: 0.177306] [FAKE loss: 1.818354]  tensor(0.8376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 271/1000] [D loss: 1.014108] [G loss: 0.182346] [FAKE loss: 1.792741]  tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 272/1000] [D loss: 1.004047] [G loss: 0.187356] [FAKE loss: 1.767971]  tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 273/1000] [D loss: 0.993487] [G loss: 0.192773] [FAKE loss: 1.742006]  tensor(0.8247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 274/1000] [D loss: 0.982421] [G loss: 0.198637] [FAKE loss: 1.714836]  tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 275/1000] [D loss: 0.971476] [G loss: 0.204683] [FAKE loss: 1.687720]  tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 276/1000] [D loss: 0.960532] [G loss: 0.210977] [FAKE loss: 1.660423]  tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 277/1000] [D loss: 0.949481] [G loss: 0.217580] [FAKE loss: 1.632736]  tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 278/1000] [D loss: 0.938134] [G loss: 0.224611] [FAKE loss: 1.604286]  tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 279/1000] [D loss: 0.927101] [G loss: 0.231756] [FAKE loss: 1.576301]  tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 280/1000] [D loss: 0.915719] [G loss: 0.239408] [FAKE loss: 1.547461]  tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 281/1000] [D loss: 0.904603] [G loss: 0.247229] [FAKE loss: 1.519005]  tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 282/1000] [D loss: 0.893256] [G loss: 0.255520] [FAKE loss: 1.489945]  tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 283/1000] [D loss: 0.882271] [G loss: 0.263953] [FAKE loss: 1.461478]  tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 284/1000] [D loss: 0.871566] [G loss: 0.272555] [FAKE loss: 1.433449]  tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 285/1000] [D loss: 0.860587] [G loss: 0.281712] [FAKE loss: 1.404756]  tensor(0.7545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 286/1000] [D loss: 0.849961] [G loss: 0.291010] [FAKE loss: 1.376663]  tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 287/1000] [D loss: 0.839464] [G loss: 0.300614] [FAKE loss: 1.348734]  tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 288/1000] [D loss: 0.829246] [G loss: 0.310409] [FAKE loss: 1.321274]  tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 289/1000] [D loss: 0.819074] [G loss: 0.320577] [FAKE loss: 1.293834]  tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 290/1000] [D loss: 0.809261] [G loss: 0.330878] [FAKE loss: 1.267044]  tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 291/1000] [D loss: 0.799640] [G loss: 0.341438] [FAKE loss: 1.240582]  tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 292/1000] [D loss: 0.790181] [G loss: 0.352282] [FAKE loss: 1.214402]  tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 293/1000] [D loss: 0.781075] [G loss: 0.363244] [FAKE loss: 1.188892]  tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 294/1000] [D loss: 0.772099] [G loss: 0.374509] [FAKE loss: 1.163622]  tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 295/1000] [D loss: 0.763455] [G loss: 0.385887] [FAKE loss: 1.139007]  tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 296/1000] [D loss: 0.755080] [G loss: 0.397424] [FAKE loss: 1.114929]  tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 297/1000] [D loss: 0.747055] [G loss: 0.409022] [FAKE loss: 1.091562]  tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 298/1000] [D loss: 0.739222] [G loss: 0.420822] [FAKE loss: 1.068606]  tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 299/1000] [D loss: 0.731671] [G loss: 0.432719] [FAKE loss: 1.046247]  tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 300/1000] [D loss: 0.724459] [G loss: 0.444626] [FAKE loss: 1.024617]  tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 301/1000] [D loss: 0.717532] [G loss: 0.456580] [FAKE loss: 1.003614]  tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 302/1000] [D loss: 0.710905] [G loss: 0.468535] [FAKE loss: 0.983285]  tensor(0.6259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 303/1000] [D loss: 0.704586] [G loss: 0.480452] [FAKE loss: 0.963658]  tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 304/1000] [D loss: 0.698603] [G loss: 0.492265] [FAKE loss: 0.944800]  tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 305/1000] [D loss: 0.692860] [G loss: 0.504062] [FAKE loss: 0.926533]  tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 306/1000] [D loss: 0.687450] [G loss: 0.515690] [FAKE loss: 0.909055]  tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 307/1000] [D loss: 0.682354] [G loss: 0.527133] [FAKE loss: 0.892341]  tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 308/1000] [D loss: 0.677575] [G loss: 0.538346] [FAKE loss: 0.876410]  tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 309/1000] [D loss: 0.673086] [G loss: 0.549329] [FAKE loss: 0.861219]  tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 310/1000] [D loss: 0.668965] [G loss: 0.559918] [FAKE loss: 0.846943]  tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 311/1000] [D loss: 0.665013] [G loss: 0.570373] [FAKE loss: 0.833190]  tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 312/1000] [D loss: 0.661436] [G loss: 0.580336] [FAKE loss: 0.820389]  tensor(0.5597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 313/1000] [D loss: 0.658186] [G loss: 0.589833] [FAKE loss: 0.808455]  tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 314/1000] [D loss: 0.655272] [G loss: 0.598800] [FAKE loss: 0.797420]  tensor(0.5495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 315/1000] [D loss: 0.652562] [G loss: 0.607409] [FAKE loss: 0.787031]  tensor(0.5448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 316/1000] [D loss: 0.650175] [G loss: 0.615421] [FAKE loss: 0.777538]  tensor(0.5404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 317/1000] [D loss: 0.648047] [G loss: 0.622898] [FAKE loss: 0.768828]  tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 318/1000] [D loss: 0.646219] [G loss: 0.629732] [FAKE loss: 0.760989]  tensor(0.5328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 319/1000] [D loss: 0.644638] [G loss: 0.635976] [FAKE loss: 0.753929]  tensor(0.5294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 320/1000] [D loss: 0.643250] [G loss: 0.641679] [FAKE loss: 0.747550]  tensor(0.5264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 321/1000] [D loss: 0.642154] [G loss: 0.646661] [FAKE loss: 0.742056]  tensor(0.5238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 322/1000] [D loss: 0.641285] [G loss: 0.650982] [FAKE loss: 0.737331]  tensor(0.5216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 323/1000] [D loss: 0.640692] [G loss: 0.654536] [FAKE loss: 0.733475]  tensor(0.5197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 324/1000] [D loss: 0.640442] [G loss: 0.657185] [FAKE loss: 0.730629]  tensor(0.5183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 325/1000] [D loss: 0.640221] [G loss: 0.659471] [FAKE loss: 0.728173]  tensor(0.5172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 326/1000] [D loss: 0.640152] [G loss: 0.661174] [FAKE loss: 0.726356]  tensor(0.5163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 327/1000] [D loss: 0.640520] [G loss: 0.661746] [FAKE loss: 0.725750]  tensor(0.5160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 328/1000] [D loss: 0.640856] [G loss: 0.662060] [FAKE loss: 0.725418]  tensor(0.5158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 329/1000] [D loss: 0.641519] [G loss: 0.661437] [FAKE loss: 0.726081]  tensor(0.5162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 330/1000] [D loss: 0.642097] [G loss: 0.660659] [FAKE loss: 0.726910]  tensor(0.5166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 331/1000] [D loss: 0.642902] [G loss: 0.659133] [FAKE loss: 0.728529]  tensor(0.5173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 332/1000] [D loss: 0.644143] [G loss: 0.656517] [FAKE loss: 0.731354]  tensor(0.5187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 333/1000] [D loss: 0.645103] [G loss: 0.654107] [FAKE loss: 0.733947]  tensor(0.5199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 334/1000] [D loss: 0.646268] [G loss: 0.651046] [FAKE loss: 0.737275]  tensor(0.5215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 335/1000] [D loss: 0.647589] [G loss: 0.647432] [FAKE loss: 0.741227]  tensor(0.5234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 336/1000] [D loss: 0.649099] [G loss: 0.643224] [FAKE loss: 0.745870]  tensor(0.5256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 337/1000] [D loss: 0.650628] [G loss: 0.638743] [FAKE loss: 0.750848]  tensor(0.5280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 338/1000] [D loss: 0.652106] [G loss: 0.634135] [FAKE loss: 0.756022]  tensor(0.5304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 339/1000] [D loss: 0.653908] [G loss: 0.628767] [FAKE loss: 0.762124]  tensor(0.5333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 340/1000] [D loss: 0.655583] [G loss: 0.623438] [FAKE loss: 0.768247]  tensor(0.5361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 341/1000] [D loss: 0.657329] [G loss: 0.617817] [FAKE loss: 0.774777]  tensor(0.5392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 342/1000] [D loss: 0.659324] [G loss: 0.611631] [FAKE loss: 0.782058]  tensor(0.5425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 343/1000] [D loss: 0.661317] [G loss: 0.605332] [FAKE loss: 0.789580]  tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 344/1000] [D loss: 0.663389] [G loss: 0.598797] [FAKE loss: 0.797490]  tensor(0.5495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 345/1000] [D loss: 0.665444] [G loss: 0.592200] [FAKE loss: 0.805585]  tensor(0.5531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 346/1000] [D loss: 0.667858] [G loss: 0.584980] [FAKE loss: 0.814602]  tensor(0.5571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 347/1000] [D loss: 0.670084] [G loss: 0.578006] [FAKE loss: 0.823436]  tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 348/1000] [D loss: 0.672654] [G loss: 0.570483] [FAKE loss: 0.833139]  tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 349/1000] [D loss: 0.674868] [G loss: 0.563484] [FAKE loss: 0.842300]  tensor(0.5692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 350/1000] [D loss: 0.677414] [G loss: 0.555987] [FAKE loss: 0.852287]  tensor(0.5735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 351/1000] [D loss: 0.680020] [G loss: 0.548426] [FAKE loss: 0.862539]  tensor(0.5779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 352/1000] [D loss: 0.682730] [G loss: 0.540761] [FAKE loss: 0.873131]  tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 353/1000] [D loss: 0.685259] [G loss: 0.533396] [FAKE loss: 0.883486]  tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 354/1000] [D loss: 0.688157] [G loss: 0.525577] [FAKE loss: 0.894688]  tensor(0.5912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 355/1000] [D loss: 0.691151] [G loss: 0.517710] [FAKE loss: 0.906184]  tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 356/1000] [D loss: 0.693970] [G loss: 0.510159] [FAKE loss: 0.917419]  tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 357/1000] [D loss: 0.697144] [G loss: 0.502235] [FAKE loss: 0.929446]  tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 358/1000] [D loss: 0.700408] [G loss: 0.494304] [FAKE loss: 0.941722]  tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 359/1000] [D loss: 0.703964] [G loss: 0.486128] [FAKE loss: 0.954642]  tensor(0.6150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 360/1000] [D loss: 0.707603] [G loss: 0.477992] [FAKE loss: 0.967780]  tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 361/1000] [D loss: 0.711171] [G loss: 0.470075] [FAKE loss: 0.980824]  tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 362/1000] [D loss: 0.714839] [G loss: 0.462183] [FAKE loss: 0.994106]  tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 363/1000] [D loss: 0.718725] [G loss: 0.454188] [FAKE loss: 1.007857]  tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 364/1000] [D loss: 0.722462] [G loss: 0.446516] [FAKE loss: 1.021335]  tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 365/1000] [D loss: 0.726315] [G loss: 0.438867] [FAKE loss: 1.035063]  tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 366/1000] [D loss: 0.730159] [G loss: 0.431380] [FAKE loss: 1.048786]  tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 367/1000] [D loss: 0.733984] [G loss: 0.424068] [FAKE loss: 1.062485]  tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 368/1000] [D loss: 0.737730] [G loss: 0.416985] [FAKE loss: 1.076031]  tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 369/1000] [D loss: 0.741589] [G loss: 0.409933] [FAKE loss: 1.089805]  tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 370/1000] [D loss: 0.745603] [G loss: 0.402874] [FAKE loss: 1.103884]  tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 371/1000] [D loss: 0.749815] [G loss: 0.395774] [FAKE loss: 1.118351]  tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 372/1000] [D loss: 0.754224] [G loss: 0.388644] [FAKE loss: 1.133198]  tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 373/1000] [D loss: 0.758689] [G loss: 0.381622] [FAKE loss: 1.148144]  tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 374/1000] [D loss: 0.763470] [G loss: 0.374478] [FAKE loss: 1.163700]  tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 375/1000] [D loss: 0.768392] [G loss: 0.367377] [FAKE loss: 1.179518]  tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 376/1000] [D loss: 0.773525] [G loss: 0.360264] [FAKE loss: 1.195732]  tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 377/1000] [D loss: 0.778880] [G loss: 0.353139] [FAKE loss: 1.212360]  tensor(0.7025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 378/1000] [D loss: 0.784491] [G loss: 0.345980] [FAKE loss: 1.229470]  tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 379/1000] [D loss: 0.790253] [G loss: 0.338886] [FAKE loss: 1.246844]  tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 380/1000] [D loss: 0.796429] [G loss: 0.331653] [FAKE loss: 1.265003]  tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 381/1000] [D loss: 0.802553] [G loss: 0.324658] [FAKE loss: 1.283015]  tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 382/1000] [D loss: 0.808981] [G loss: 0.317626] [FAKE loss: 1.301584]  tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 383/1000] [D loss: 0.815473] [G loss: 0.310744] [FAKE loss: 1.320228]  tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 384/1000] [D loss: 0.822107] [G loss: 0.303955] [FAKE loss: 1.339100]  tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 385/1000] [D loss: 0.829023] [G loss: 0.297161] [FAKE loss: 1.358474]  tensor(0.7429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 386/1000] [D loss: 0.836066] [G loss: 0.290479] [FAKE loss: 1.378042]  tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 387/1000] [D loss: 0.843218] [G loss: 0.283920] [FAKE loss: 1.397759]  tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 388/1000] [D loss: 0.850517] [G loss: 0.277457] [FAKE loss: 1.417703]  tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 389/1000] [D loss: 0.858125] [G loss: 0.270993] [FAKE loss: 1.438191]  tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 390/1000] [D loss: 0.865669] [G loss: 0.264762] [FAKE loss: 1.458479]  tensor(0.7674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 391/1000] [D loss: 0.873582] [G loss: 0.258500] [FAKE loss: 1.479425]  tensor(0.7722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 392/1000] [D loss: 0.881485] [G loss: 0.252431] [FAKE loss: 1.500275]  tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 393/1000] [D loss: 0.889624] [G loss: 0.246416] [FAKE loss: 1.521511]  tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 394/1000] [D loss: 0.897856] [G loss: 0.240534] [FAKE loss: 1.542847]  tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 395/1000] [D loss: 0.906104] [G loss: 0.234826] [FAKE loss: 1.564127]  tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 396/1000] [D loss: 0.914493] [G loss: 0.229221] [FAKE loss: 1.585594]  tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 397/1000] [D loss: 0.922889] [G loss: 0.223784] [FAKE loss: 1.606980]  tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 398/1000] [D loss: 0.931549] [G loss: 0.218388] [FAKE loss: 1.628797]  tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 399/1000] [D loss: 0.940041] [G loss: 0.213240] [FAKE loss: 1.650176]  tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 400/1000] [D loss: 0.948680] [G loss: 0.208183] [FAKE loss: 1.671742]  tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 401/1000] [D loss: 0.957120] [G loss: 0.203370] [FAKE loss: 1.692806]  tensor(0.8160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 402/1000] [D loss: 0.965501] [G loss: 0.198732] [FAKE loss: 1.713641]  tensor(0.8198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 403/1000] [D loss: 0.973836] [G loss: 0.194253] [FAKE loss: 1.734272]  tensor(0.8235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 404/1000] [D loss: 0.982137] [G loss: 0.189924] [FAKE loss: 1.754719]  tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 405/1000] [D loss: 0.990116] [G loss: 0.185857] [FAKE loss: 1.774403]  tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 406/1000] [D loss: 0.998040] [G loss: 0.181930] [FAKE loss: 1.793859]  tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 407/1000] [D loss: 1.005881] [G loss: 0.178152] [FAKE loss: 1.813021]  tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 408/1000] [D loss: 1.013474] [G loss: 0.174578] [FAKE loss: 1.831563]  tensor(0.8398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 409/1000] [D loss: 1.020895] [G loss: 0.171169] [FAKE loss: 1.849631]  tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 410/1000] [D loss: 1.028224] [G loss: 0.167891] [FAKE loss: 1.867382]  tensor(0.8455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 411/1000] [D loss: 1.035143] [G loss: 0.164853] [FAKE loss: 1.884180]  tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 412/1000] [D loss: 1.041789] [G loss: 0.161994] [FAKE loss: 1.900296]  tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 413/1000] [D loss: 1.048196] [G loss: 0.159294] [FAKE loss: 1.915796]  tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 414/1000] [D loss: 1.054321] [G loss: 0.156764] [FAKE loss: 1.930589]  tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 415/1000] [D loss: 1.060084] [G loss: 0.154420] [FAKE loss: 1.944518]  tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 416/1000] [D loss: 1.065473] [G loss: 0.152261] [FAKE loss: 1.957554]  tensor(0.8588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 417/1000] [D loss: 1.070444] [G loss: 0.150295] [FAKE loss: 1.969606]  tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 418/1000] [D loss: 1.074902] [G loss: 0.148542] [FAKE loss: 1.980485]  tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 419/1000] [D loss: 1.079002] [G loss: 0.146949] [FAKE loss: 1.990501]  tensor(0.8633, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 420/1000] [D loss: 1.082575] [G loss: 0.145564] [FAKE loss: 1.999310]  tensor(0.8645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 421/1000] [D loss: 1.085838] [G loss: 0.144312] [FAKE loss: 2.007349]  tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 422/1000] [D loss: 1.088195] [G loss: 0.143373] [FAKE loss: 2.013420]  tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 423/1000] [D loss: 1.090514] [G loss: 0.142478] [FAKE loss: 2.019261]  tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 424/1000] [D loss: 1.092262] [G loss: 0.141785] [FAKE loss: 2.023805]  tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 425/1000] [D loss: 1.093133] [G loss: 0.141386] [FAKE loss: 2.026438]  tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 426/1000] [D loss: 1.093282] [G loss: 0.141232] [FAKE loss: 2.027467]  tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 427/1000] [D loss: 1.093433] [G loss: 0.141099] [FAKE loss: 2.028341]  tensor(0.8684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 428/1000] [D loss: 1.092880] [G loss: 0.141205] [FAKE loss: 2.027645]  tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 429/1000] [D loss: 1.091528] [G loss: 0.141580] [FAKE loss: 2.025189]  tensor(0.8680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 430/1000] [D loss: 1.089934] [G loss: 0.142054] [FAKE loss: 2.022084]  tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 431/1000] [D loss: 1.087504] [G loss: 0.142812] [FAKE loss: 2.017143]  tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 432/1000] [D loss: 1.084398] [G loss: 0.143808] [FAKE loss: 2.010684]  tensor(0.8661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 433/1000] [D loss: 1.080692] [G loss: 0.145026] [FAKE loss: 2.002856]  tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 434/1000] [D loss: 1.076645] [G loss: 0.146387] [FAKE loss: 1.994177]  tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 435/1000] [D loss: 1.071871] [G loss: 0.148022] [FAKE loss: 1.983870]  tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 436/1000] [D loss: 1.066727] [G loss: 0.149827] [FAKE loss: 1.972648]  tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 437/1000] [D loss: 1.061106] [G loss: 0.151838] [FAKE loss: 1.960296]  tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 438/1000] [D loss: 1.054888] [G loss: 0.154108] [FAKE loss: 1.946569]  tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 439/1000] [D loss: 1.048448] [G loss: 0.156518] [FAKE loss: 1.932219]  tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 440/1000] [D loss: 1.041148] [G loss: 0.159300] [FAKE loss: 1.915964]  tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 441/1000] [D loss: 1.033582] [G loss: 0.162262] [FAKE loss: 1.898990]  tensor(0.8502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 442/1000] [D loss: 1.025459] [G loss: 0.165520] [FAKE loss: 1.880710]  tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 443/1000] [D loss: 1.017321] [G loss: 0.168885] [FAKE loss: 1.862207]  tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 444/1000] [D loss: 1.008310] [G loss: 0.172694] [FAKE loss: 1.841761]  tensor(0.8414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 445/1000] [D loss: 0.999233] [G loss: 0.176661] [FAKE loss: 1.820982]  tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 446/1000] [D loss: 0.989943] [G loss: 0.180851] [FAKE loss: 1.799572]  tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 447/1000] [D loss: 0.980235] [G loss: 0.185364] [FAKE loss: 1.777117]  tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 448/1000] [D loss: 0.970214] [G loss: 0.190180] [FAKE loss: 1.753822]  tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 449/1000] [D loss: 0.959762] [G loss: 0.195364] [FAKE loss: 1.729448]  tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 450/1000] [D loss: 0.949896] [G loss: 0.200491] [FAKE loss: 1.706025]  tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 451/1000] [D loss: 0.939547] [G loss: 0.206037] [FAKE loss: 1.681409]  tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 452/1000] [D loss: 0.929039] [G loss: 0.211890] [FAKE loss: 1.656244]  tensor(0.8091, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 453/1000] [D loss: 0.918272] [G loss: 0.218112] [FAKE loss: 1.630326]  tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 454/1000] [D loss: 0.907653] [G loss: 0.224524] [FAKE loss: 1.604466]  tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 455/1000] [D loss: 0.897130] [G loss: 0.231151] [FAKE loss: 1.578553]  tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 456/1000] [D loss: 0.886782] [G loss: 0.237981] [FAKE loss: 1.552745]  tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 457/1000] [D loss: 0.876426] [G loss: 0.245109] [FAKE loss: 1.526668]  tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 458/1000] [D loss: 0.866320] [G loss: 0.252409] [FAKE loss: 1.500835]  tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 459/1000] [D loss: 0.855853] [G loss: 0.260256] [FAKE loss: 1.474021]  tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 460/1000] [D loss: 0.846487] [G loss: 0.267769] [FAKE loss: 1.449148]  tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 461/1000] [D loss: 0.836419] [G loss: 0.276078] [FAKE loss: 1.422604]  tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 462/1000] [D loss: 0.827047] [G loss: 0.284314] [FAKE loss: 1.397183]  tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 463/1000] [D loss: 0.817940] [G loss: 0.292732] [FAKE loss: 1.372025]  tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 464/1000] [D loss: 0.809025] [G loss: 0.301400] [FAKE loss: 1.346978]  tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 465/1000] [D loss: 0.800317] [G loss: 0.310323] [FAKE loss: 1.322073]  tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 466/1000] [D loss: 0.791858] [G loss: 0.319471] [FAKE loss: 1.297391]  tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 467/1000] [D loss: 0.783929] [G loss: 0.328617] [FAKE loss: 1.273498]  tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 468/1000] [D loss: 0.776445] [G loss: 0.337824] [FAKE loss: 1.250225]  tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 469/1000] [D loss: 0.768371] [G loss: 0.347947] [FAKE loss: 1.225503]  tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 470/1000] [D loss: 0.761270] [G loss: 0.357688] [FAKE loss: 1.202460]  tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 471/1000] [D loss: 0.753875] [G loss: 0.368155] [FAKE loss: 1.178567]  tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 472/1000] [D loss: 0.747334] [G loss: 0.378307] [FAKE loss: 1.156128]  tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 473/1000] [D loss: 0.740270] [G loss: 0.389410] [FAKE loss: 1.132393]  tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 474/1000] [D loss: 0.734481] [G loss: 0.399750] [FAKE loss: 1.110977]  tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 475/1000] [D loss: 0.728140] [G loss: 0.411122] [FAKE loss: 1.088228]  tensor(0.6630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 476/1000] [D loss: 0.722476] [G loss: 0.422271] [FAKE loss: 1.066623]  tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 477/1000] [D loss: 0.717021] [G loss: 0.433661] [FAKE loss: 1.045243]  tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 478/1000] [D loss: 0.711575] [G loss: 0.445528] [FAKE loss: 1.023706]  tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 479/1000] [D loss: 0.706331] [G loss: 0.457680] [FAKE loss: 1.002415]  tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 480/1000] [D loss: 0.701665] [G loss: 0.469604] [FAKE loss: 0.982146]  tensor(0.6253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 481/1000] [D loss: 0.697216] [G loss: 0.481719] [FAKE loss: 0.962212]  tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 482/1000] [D loss: 0.693099] [G loss: 0.493846] [FAKE loss: 0.942872]  tensor(0.6104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 483/1000] [D loss: 0.688966] [G loss: 0.506429] [FAKE loss: 0.923464]  tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 484/1000] [D loss: 0.685827] [G loss: 0.518041] [FAKE loss: 0.906046]  tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 485/1000] [D loss: 0.682347] [G loss: 0.530461] [FAKE loss: 0.887987]  tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 486/1000] [D loss: 0.679495] [G loss: 0.542314] [FAKE loss: 0.871266]  tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 487/1000] [D loss: 0.676960] [G loss: 0.553930] [FAKE loss: 0.855305]  tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 488/1000] [D loss: 0.674943] [G loss: 0.564950] [FAKE loss: 0.840561]  tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 489/1000] [D loss: 0.673020] [G loss: 0.575954] [FAKE loss: 0.826240]  tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 490/1000] [D loss: 0.671606] [G loss: 0.586176] [FAKE loss: 0.813227]  tensor(0.5565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 491/1000] [D loss: 0.670640] [G loss: 0.595632] [FAKE loss: 0.801461]  tensor(0.5513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 492/1000] [D loss: 0.669916] [G loss: 0.604561] [FAKE loss: 0.790589]  tensor(0.5464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 493/1000] [D loss: 0.669637] [G loss: 0.612505] [FAKE loss: 0.781084]  tensor(0.5420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 494/1000] [D loss: 0.669774] [G loss: 0.619422] [FAKE loss: 0.772943]  tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 495/1000] [D loss: 0.670128] [G loss: 0.625549] [FAKE loss: 0.765832]  tensor(0.5350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 496/1000] [D loss: 0.670867] [G loss: 0.630511] [FAKE loss: 0.760148]  tensor(0.5324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 497/1000] [D loss: 0.672139] [G loss: 0.633943] [FAKE loss: 0.756249]  tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 498/1000] [D loss: 0.673867] [G loss: 0.635902] [FAKE loss: 0.754033]  tensor(0.5295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 499/1000] [D loss: 0.675739] [G loss: 0.636894] [FAKE loss: 0.752924]  tensor(0.5290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 500/1000] [D loss: 0.678370] [G loss: 0.635751] [FAKE loss: 0.754198]  tensor(0.5296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 501/1000] [D loss: 0.680869] [G loss: 0.634055] [FAKE loss: 0.756116]  tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 502/1000] [D loss: 0.684007] [G loss: 0.630414] [FAKE loss: 0.760249]  tensor(0.5324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 503/1000] [D loss: 0.687396] [G loss: 0.625518] [FAKE loss: 0.765850]  tensor(0.5350, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 504/1000] [D loss: 0.691239] [G loss: 0.619067] [FAKE loss: 0.773339]  tensor(0.5385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 505/1000] [D loss: 0.695531] [G loss: 0.611100] [FAKE loss: 0.782714]  tensor(0.5428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 506/1000] [D loss: 0.700097] [G loss: 0.602017] [FAKE loss: 0.793627]  tensor(0.5477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 507/1000] [D loss: 0.705126] [G loss: 0.591561] [FAKE loss: 0.806445]  tensor(0.5535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 508/1000] [D loss: 0.710866] [G loss: 0.579470] [FAKE loss: 0.821645]  tensor(0.5602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 509/1000] [D loss: 0.717087] [G loss: 0.566262] [FAKE loss: 0.838741]  tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 510/1000] [D loss: 0.723457] [G loss: 0.552561] [FAKE loss: 0.857037]  tensor(0.5755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 511/1000] [D loss: 0.730320] [G loss: 0.537970] [FAKE loss: 0.877181]  tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 512/1000] [D loss: 0.737928] [G loss: 0.522288] [FAKE loss: 0.899630]  tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 513/1000] [D loss: 0.745849] [G loss: 0.506272] [FAKE loss: 0.923476]  tensor(0.6028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 514/1000] [D loss: 0.754577] [G loss: 0.489401] [FAKE loss: 0.949650]  tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 515/1000] [D loss: 0.763477] [G loss: 0.472635] [FAKE loss: 0.976823]  tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 516/1000] [D loss: 0.773243] [G loss: 0.455242] [FAKE loss: 1.006322]  tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 517/1000] [D loss: 0.783149] [G loss: 0.438205] [FAKE loss: 1.036632]  tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 518/1000] [D loss: 0.793847] [G loss: 0.420870] [FAKE loss: 1.068987]  tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 519/1000] [D loss: 0.805247] [G loss: 0.403473] [FAKE loss: 1.103159]  tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 520/1000] [D loss: 0.817587] [G loss: 0.385897] [FAKE loss: 1.139555]  tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 521/1000] [D loss: 0.830310] [G loss: 0.368762] [FAKE loss: 1.176999]  tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 522/1000] [D loss: 0.844276] [G loss: 0.351405] [FAKE loss: 1.217145]  tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 523/1000] [D loss: 0.858147] [G loss: 0.335020] [FAKE loss: 1.257267]  tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 524/1000] [D loss: 0.873793] [G loss: 0.318160] [FAKE loss: 1.301051]  tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 525/1000] [D loss: 0.890222] [G loss: 0.301718] [FAKE loss: 1.346458]  tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 526/1000] [D loss: 0.907420] [G loss: 0.285724] [FAKE loss: 1.393418]  tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 527/1000] [D loss: 0.925725] [G loss: 0.270031] [FAKE loss: 1.442542]  tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 528/1000] [D loss: 0.944745] [G loss: 0.254929] [FAKE loss: 1.492999]  tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 529/1000] [D loss: 0.964355] [G loss: 0.240502] [FAKE loss: 1.544503]  tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 530/1000] [D loss: 0.984646] [G loss: 0.226660] [FAKE loss: 1.597210]  tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 531/1000] [D loss: 1.005989] [G loss: 0.213258] [FAKE loss: 1.651827]  tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 532/1000] [D loss: 1.027192] [G loss: 0.200854] [FAKE loss: 1.705941]  tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 533/1000] [D loss: 1.049507] [G loss: 0.188807] [FAKE loss: 1.762023]  tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 534/1000] [D loss: 1.071728] [G loss: 0.177658] [FAKE loss: 1.817645]  tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 535/1000] [D loss: 1.094440] [G loss: 0.167097] [FAKE loss: 1.873953]  tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 536/1000] [D loss: 1.117572] [G loss: 0.157120] [FAKE loss: 1.930789]  tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 537/1000] [D loss: 1.141214] [G loss: 0.147676] [FAKE loss: 1.988312]  tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 538/1000] [D loss: 1.164688] [G loss: 0.138930] [FAKE loss: 2.045160]  tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 539/1000] [D loss: 1.188257] [G loss: 0.130768] [FAKE loss: 2.101848]  tensor(0.8775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 540/1000] [D loss: 1.210982] [G loss: 0.123375] [FAKE loss: 2.156492]  tensor(0.8840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 541/1000] [D loss: 1.233721] [G loss: 0.116472] [FAKE loss: 2.210800]  tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 542/1000] [D loss: 1.257272] [G loss: 0.109810] [FAKE loss: 2.266369]  tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 543/1000] [D loss: 1.278805] [G loss: 0.104042] [FAKE loss: 2.317533]  tensor(0.9012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 544/1000] [D loss: 1.301314] [G loss: 0.098431] [FAKE loss: 2.370283]  tensor(0.9063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 545/1000] [D loss: 1.322006] [G loss: 0.093521] [FAKE loss: 2.419029]  tensor(0.9107, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 546/1000] [D loss: 1.342491] [G loss: 0.088952] [FAKE loss: 2.466991]  tensor(0.9149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 547/1000] [D loss: 1.362493] [G loss: 0.084716] [FAKE loss: 2.513619]  tensor(0.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 548/1000] [D loss: 1.382203] [G loss: 0.080769] [FAKE loss: 2.559299]  tensor(0.9224, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 549/1000] [D loss: 1.399572] [G loss: 0.077430] [FAKE loss: 2.599935]  tensor(0.9255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 550/1000] [D loss: 1.417019] [G loss: 0.074240] [FAKE loss: 2.640371]  tensor(0.9285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 551/1000] [D loss: 1.432688] [G loss: 0.071478] [FAKE loss: 2.676897]  tensor(0.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 552/1000] [D loss: 1.448710] [G loss: 0.068794] [FAKE loss: 2.713780]  tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 553/1000] [D loss: 1.462241] [G loss: 0.066585] [FAKE loss: 2.745337]  tensor(0.9356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 554/1000] [D loss: 1.475632] [G loss: 0.064483] [FAKE loss: 2.776280]  tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 555/1000] [D loss: 1.487324] [G loss: 0.062691] [FAKE loss: 2.803494]  tensor(0.9392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 556/1000] [D loss: 1.497096] [G loss: 0.061217] [FAKE loss: 2.826539]  tensor(0.9406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 557/1000] [D loss: 1.506915] [G loss: 0.059791] [FAKE loss: 2.849357]  tensor(0.9420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 558/1000] [D loss: 1.514840] [G loss: 0.058646] [FAKE loss: 2.868071]  tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 559/1000] [D loss: 1.520781] [G loss: 0.057777] [FAKE loss: 2.882506]  tensor(0.9439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 560/1000] [D loss: 1.525473] [G loss: 0.057089] [FAKE loss: 2.894138]  tensor(0.9445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 561/1000] [D loss: 1.528739] [G loss: 0.056592] [FAKE loss: 2.902620]  tensor(0.9450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 562/1000] [D loss: 1.531285] [G loss: 0.056194] [FAKE loss: 2.909366]  tensor(0.9454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 563/1000] [D loss: 1.531784] [G loss: 0.056051] [FAKE loss: 2.911728]  tensor(0.9455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 564/1000] [D loss: 1.531290] [G loss: 0.056046] [FAKE loss: 2.911820]  tensor(0.9455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 565/1000] [D loss: 1.528933] [G loss: 0.056265] [FAKE loss: 2.907906]  tensor(0.9453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 566/1000] [D loss: 1.525172] [G loss: 0.056672] [FAKE loss: 2.900905]  tensor(0.9449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 567/1000] [D loss: 1.520422] [G loss: 0.057208] [FAKE loss: 2.891652]  tensor(0.9444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 568/1000] [D loss: 1.514770] [G loss: 0.057872] [FAKE loss: 2.880322]  tensor(0.9438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 569/1000] [D loss: 1.506757] [G loss: 0.058849] [FAKE loss: 2.864003]  tensor(0.9429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 570/1000] [D loss: 1.497845] [G loss: 0.059973] [FAKE loss: 2.845621]  tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 571/1000] [D loss: 1.487919] [G loss: 0.061263] [FAKE loss: 2.824946]  tensor(0.9406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 572/1000] [D loss: 1.477070] [G loss: 0.062713] [FAKE loss: 2.802165]  tensor(0.9392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 573/1000] [D loss: 1.464597] [G loss: 0.064435] [FAKE loss: 2.775875]  tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 574/1000] [D loss: 1.451634] [G loss: 0.066288] [FAKE loss: 2.748347]  tensor(0.9359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 575/1000] [D loss: 1.436894] [G loss: 0.068471] [FAKE loss: 2.717010]  tensor(0.9338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 576/1000] [D loss: 1.422374] [G loss: 0.070712] [FAKE loss: 2.685860]  tensor(0.9317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 577/1000] [D loss: 1.406503] [G loss: 0.073252] [FAKE loss: 2.651754]  tensor(0.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 578/1000] [D loss: 1.390336] [G loss: 0.075954] [FAKE loss: 2.616805]  tensor(0.9269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 579/1000] [D loss: 1.373241] [G loss: 0.078933] [FAKE loss: 2.579751]  tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 580/1000] [D loss: 1.355350] [G loss: 0.082195] [FAKE loss: 2.540855]  tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 581/1000] [D loss: 1.336723] [G loss: 0.085749] [FAKE loss: 2.500244]  tensor(0.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 582/1000] [D loss: 1.318578] [G loss: 0.089390] [FAKE loss: 2.460350]  tensor(0.9145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 583/1000] [D loss: 1.299620] [G loss: 0.093382] [FAKE loss: 2.418587]  tensor(0.9109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 584/1000] [D loss: 1.280177] [G loss: 0.097684] [FAKE loss: 2.375616]  tensor(0.9069, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 585/1000] [D loss: 1.260947] [G loss: 0.102175] [FAKE loss: 2.332831]  tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 586/1000] [D loss: 1.241143] [G loss: 0.107042] [FAKE loss: 2.288666]  tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 587/1000] [D loss: 1.221113] [G loss: 0.112234] [FAKE loss: 2.243819]  tensor(0.8938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 588/1000] [D loss: 1.201564] [G loss: 0.117601] [FAKE loss: 2.199707]  tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 589/1000] [D loss: 1.182065] [G loss: 0.123258] [FAKE loss: 2.155472]  tensor(0.8840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 590/1000] [D loss: 1.162944] [G loss: 0.129125] [FAKE loss: 2.111777]  tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 591/1000] [D loss: 1.143353] [G loss: 0.135463] [FAKE loss: 2.066931]  tensor(0.8733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 592/1000] [D loss: 1.124839] [G loss: 0.141838] [FAKE loss: 2.024033]  tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 593/1000] [D loss: 1.105616] [G loss: 0.148791] [FAKE loss: 1.979521]  tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 594/1000] [D loss: 1.087137] [G loss: 0.155899] [FAKE loss: 1.936306]  tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 595/1000] [D loss: 1.069056] [G loss: 0.163263] [FAKE loss: 1.893704]  tensor(0.8494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 596/1000] [D loss: 1.051181] [G loss: 0.170963] [FAKE loss: 1.851338]  tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 597/1000] [D loss: 1.033435] [G loss: 0.179041] [FAKE loss: 1.809065]  tensor(0.8361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 598/1000] [D loss: 1.016765] [G loss: 0.187125] [FAKE loss: 1.768788]  tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 599/1000] [D loss: 1.000163] [G loss: 0.195622] [FAKE loss: 1.728501]  tensor(0.8223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 600/1000] [D loss: 0.983988] [G loss: 0.204371] [FAKE loss: 1.688931]  tensor(0.8152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 601/1000] [D loss: 0.968553] [G loss: 0.213236] [FAKE loss: 1.650716]  tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 602/1000] [D loss: 0.953350] [G loss: 0.222447] [FAKE loss: 1.612850]  tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 603/1000] [D loss: 0.938903] [G loss: 0.231729] [FAKE loss: 1.576391]  tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 604/1000] [D loss: 0.924725] [G loss: 0.241331] [FAKE loss: 1.540381]  tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 605/1000] [D loss: 0.910992] [G loss: 0.251151] [FAKE loss: 1.505181]  tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 606/1000] [D loss: 0.897878] [G loss: 0.261080] [FAKE loss: 1.471151]  tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 607/1000] [D loss: 0.885424] [G loss: 0.271053] [FAKE loss: 1.438385]  tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 608/1000] [D loss: 0.873431] [G loss: 0.281188] [FAKE loss: 1.406495]  tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 609/1000] [D loss: 0.861739] [G loss: 0.291561] [FAKE loss: 1.375178]  tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 610/1000] [D loss: 0.850388] [G loss: 0.302146] [FAKE loss: 1.344524]  tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 611/1000] [D loss: 0.839870] [G loss: 0.312571] [FAKE loss: 1.315527]  tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 612/1000] [D loss: 0.829394] [G loss: 0.323387] [FAKE loss: 1.286616]  tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 613/1000] [D loss: 0.819978] [G loss: 0.333790] [FAKE loss: 1.259839]  tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 614/1000] [D loss: 0.810510] [G loss: 0.344631] [FAKE loss: 1.232986]  tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 615/1000] [D loss: 0.801718] [G loss: 0.355293] [FAKE loss: 1.207520]  tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 616/1000] [D loss: 0.793164] [G loss: 0.366117] [FAKE loss: 1.182581]  tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 617/1000] [D loss: 0.785173] [G loss: 0.376795] [FAKE loss: 1.158824]  tensor(0.6861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 618/1000] [D loss: 0.777517] [G loss: 0.387502] [FAKE loss: 1.135806]  tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 619/1000] [D loss: 0.770371] [G loss: 0.398034] [FAKE loss: 1.113888]  tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 620/1000] [D loss: 0.763493] [G loss: 0.408606] [FAKE loss: 1.092595]  tensor(0.6646, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 621/1000] [D loss: 0.757002] [G loss: 0.419068] [FAKE loss: 1.072171]  tensor(0.6577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 622/1000] [D loss: 0.750824] [G loss: 0.429464] [FAKE loss: 1.052481]  tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 623/1000] [D loss: 0.744883] [G loss: 0.439853] [FAKE loss: 1.033382]  tensor(0.6442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 624/1000] [D loss: 0.739497] [G loss: 0.449854] [FAKE loss: 1.015515]  tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 625/1000] [D loss: 0.734077] [G loss: 0.460105] [FAKE loss: 0.997712]  tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 626/1000] [D loss: 0.729254] [G loss: 0.469845] [FAKE loss: 0.981242]  tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 627/1000] [D loss: 0.724605] [G loss: 0.479541] [FAKE loss: 0.965267]  tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 628/1000] [D loss: 0.720180] [G loss: 0.489110] [FAKE loss: 0.949893]  tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 629/1000] [D loss: 0.715948] [G loss: 0.498574] [FAKE loss: 0.935064]  tensor(0.6074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 630/1000] [D loss: 0.711835] [G loss: 0.508001] [FAKE loss: 0.920641]  tensor(0.6017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 631/1000] [D loss: 0.708115] [G loss: 0.517008] [FAKE loss: 0.907177]  tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 632/1000] [D loss: 0.704607] [G loss: 0.525804] [FAKE loss: 0.894314]  tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 633/1000] [D loss: 0.701235] [G loss: 0.534472] [FAKE loss: 0.881905]  tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 634/1000] [D loss: 0.697983] [G loss: 0.543019] [FAKE loss: 0.869924]  tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 635/1000] [D loss: 0.694955] [G loss: 0.551271] [FAKE loss: 0.858586]  tensor(0.5762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 636/1000] [D loss: 0.692187] [G loss: 0.559152] [FAKE loss: 0.847963]  tensor(0.5717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 637/1000] [D loss: 0.689458] [G loss: 0.566963] [FAKE loss: 0.837623]  tensor(0.5673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 638/1000] [D loss: 0.686966] [G loss: 0.574395] [FAKE loss: 0.827959]  tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 639/1000] [D loss: 0.684566] [G loss: 0.581644] [FAKE loss: 0.818689]  tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 640/1000] [D loss: 0.682352] [G loss: 0.588548] [FAKE loss: 0.810003]  tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 641/1000] [D loss: 0.680328] [G loss: 0.595077] [FAKE loss: 0.801911]  tensor(0.5515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 642/1000] [D loss: 0.678362] [G loss: 0.601428] [FAKE loss: 0.794152]  tensor(0.5480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 643/1000] [D loss: 0.676510] [G loss: 0.607496] [FAKE loss: 0.786842]  tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 644/1000] [D loss: 0.674835] [G loss: 0.613159] [FAKE loss: 0.780105]  tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 645/1000] [D loss: 0.673251] [G loss: 0.618546] [FAKE loss: 0.773775]  tensor(0.5387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 646/1000] [D loss: 0.671815] [G loss: 0.623546] [FAKE loss: 0.767966]  tensor(0.5360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 647/1000] [D loss: 0.670462] [G loss: 0.628259] [FAKE loss: 0.762546]  tensor(0.5335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 648/1000] [D loss: 0.669246] [G loss: 0.632578] [FAKE loss: 0.757628]  tensor(0.5312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 649/1000] [D loss: 0.668129] [G loss: 0.636561] [FAKE loss: 0.753134]  tensor(0.5291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 650/1000] [D loss: 0.667151] [G loss: 0.640126] [FAKE loss: 0.749143]  tensor(0.5272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 651/1000] [D loss: 0.666259] [G loss: 0.643358] [FAKE loss: 0.745551]  tensor(0.5255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 652/1000] [D loss: 0.665428] [G loss: 0.646298] [FAKE loss: 0.742305]  tensor(0.5240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 653/1000] [D loss: 0.664710] [G loss: 0.648847] [FAKE loss: 0.739506]  tensor(0.5226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 654/1000] [D loss: 0.664111] [G loss: 0.650989] [FAKE loss: 0.737167]  tensor(0.5215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 655/1000] [D loss: 0.663553] [G loss: 0.652861] [FAKE loss: 0.735131]  tensor(0.5206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 656/1000] [D loss: 0.663161] [G loss: 0.654235] [FAKE loss: 0.733642]  tensor(0.5198, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 657/1000] [D loss: 0.662818] [G loss: 0.655326] [FAKE loss: 0.732463]  tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 658/1000] [D loss: 0.662612] [G loss: 0.655970] [FAKE loss: 0.731770]  tensor(0.5189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 659/1000] [D loss: 0.662485] [G loss: 0.656278] [FAKE loss: 0.731439]  tensor(0.5188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 660/1000] [D loss: 0.662429] [G loss: 0.656270] [FAKE loss: 0.731448]  tensor(0.5188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 661/1000] [D loss: 0.662488] [G loss: 0.655871] [FAKE loss: 0.731881]  tensor(0.5190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 662/1000] [D loss: 0.662605] [G loss: 0.655184] [FAKE loss: 0.732624]  tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 663/1000] [D loss: 0.662843] [G loss: 0.654103] [FAKE loss: 0.733795]  tensor(0.5199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 664/1000] [D loss: 0.663207] [G loss: 0.652624] [FAKE loss: 0.735403]  tensor(0.5207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 665/1000] [D loss: 0.663610] [G loss: 0.650913] [FAKE loss: 0.737266]  tensor(0.5216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 666/1000] [D loss: 0.664241] [G loss: 0.648639] [FAKE loss: 0.739753]  tensor(0.5228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 667/1000] [D loss: 0.664903] [G loss: 0.646170] [FAKE loss: 0.742466]  tensor(0.5241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 668/1000] [D loss: 0.665739] [G loss: 0.643260] [FAKE loss: 0.745683]  tensor(0.5256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 669/1000] [D loss: 0.666778] [G loss: 0.639871] [FAKE loss: 0.749454]  tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 670/1000] [D loss: 0.667809] [G loss: 0.636392] [FAKE loss: 0.753350]  tensor(0.5292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 671/1000] [D loss: 0.669034] [G loss: 0.632472] [FAKE loss: 0.757777]  tensor(0.5313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 672/1000] [D loss: 0.670365] [G loss: 0.628274] [FAKE loss: 0.762556]  tensor(0.5335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 673/1000] [D loss: 0.671700] [G loss: 0.623993] [FAKE loss: 0.767473]  tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 674/1000] [D loss: 0.672832] [G loss: 0.619995] [FAKE loss: 0.772108]  tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 675/1000] [D loss: 0.674090] [G loss: 0.615716] [FAKE loss: 0.777113]  tensor(0.5403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 676/1000] [D loss: 0.675580] [G loss: 0.610990] [FAKE loss: 0.782698]  tensor(0.5428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 677/1000] [D loss: 0.677056] [G loss: 0.606245] [FAKE loss: 0.788364]  tensor(0.5454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 678/1000] [D loss: 0.678734] [G loss: 0.601131] [FAKE loss: 0.794536]  tensor(0.5482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 679/1000] [D loss: 0.680596] [G loss: 0.595689] [FAKE loss: 0.801180]  tensor(0.5512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 680/1000] [D loss: 0.682577] [G loss: 0.590051] [FAKE loss: 0.808151]  tensor(0.5543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 681/1000] [D loss: 0.684705] [G loss: 0.584177] [FAKE loss: 0.815509]  tensor(0.5576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 682/1000] [D loss: 0.686987] [G loss: 0.578068] [FAKE loss: 0.823265]  tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 683/1000] [D loss: 0.689402] [G loss: 0.571763] [FAKE loss: 0.831380]  tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 684/1000] [D loss: 0.691873] [G loss: 0.565393] [FAKE loss: 0.839702]  tensor(0.5681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 685/1000] [D loss: 0.694550] [G loss: 0.558744] [FAKE loss: 0.848519]  tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 686/1000] [D loss: 0.697411] [G loss: 0.551867] [FAKE loss: 0.857783]  tensor(0.5759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 687/1000] [D loss: 0.700331] [G loss: 0.544954] [FAKE loss: 0.867249]  tensor(0.5799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 688/1000] [D loss: 0.703253] [G loss: 0.538094] [FAKE loss: 0.876796]  tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 689/1000] [D loss: 0.706368] [G loss: 0.531024] [FAKE loss: 0.886804]  tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 690/1000] [D loss: 0.709703] [G loss: 0.523721] [FAKE loss: 0.897324]  tensor(0.5923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 691/1000] [D loss: 0.713297] [G loss: 0.516149] [FAKE loss: 0.908430]  tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 692/1000] [D loss: 0.716776] [G loss: 0.508825] [FAKE loss: 0.919374]  tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 693/1000] [D loss: 0.720889] [G loss: 0.500765] [FAKE loss: 0.931655]  tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 694/1000] [D loss: 0.724932] [G loss: 0.492911] [FAKE loss: 0.943862]  tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 695/1000] [D loss: 0.729382] [G loss: 0.484665] [FAKE loss: 0.956945]  tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 696/1000] [D loss: 0.733953] [G loss: 0.476409] [FAKE loss: 0.970331]  tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 697/1000] [D loss: 0.738790] [G loss: 0.467970] [FAKE loss: 0.984316]  tensor(0.6263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 698/1000] [D loss: 0.743740] [G loss: 0.459547] [FAKE loss: 0.998593]  tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 699/1000] [D loss: 0.749188] [G loss: 0.450712] [FAKE loss: 1.013924]  tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 700/1000] [D loss: 0.754911] [G loss: 0.441751] [FAKE loss: 1.029862]  tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 701/1000] [D loss: 0.760717] [G loss: 0.432885] [FAKE loss: 1.046028]  tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 702/1000] [D loss: 0.767090] [G loss: 0.423607] [FAKE loss: 1.063385]  tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 703/1000] [D loss: 0.773792] [G loss: 0.414205] [FAKE loss: 1.081459]  tensor(0.6609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 704/1000] [D loss: 0.780490] [G loss: 0.405028] [FAKE loss: 1.099584]  tensor(0.6670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 705/1000] [D loss: 0.787593] [G loss: 0.395678] [FAKE loss: 1.118575]  tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 706/1000] [D loss: 0.794912] [G loss: 0.386356] [FAKE loss: 1.138058]  tensor(0.6795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 707/1000] [D loss: 0.802467] [G loss: 0.377056] [FAKE loss: 1.158069]  tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 708/1000] [D loss: 0.810318] [G loss: 0.367739] [FAKE loss: 1.178722]  tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 709/1000] [D loss: 0.818682] [G loss: 0.358235] [FAKE loss: 1.200453]  tensor(0.6989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 710/1000] [D loss: 0.827439] [G loss: 0.348670] [FAKE loss: 1.223017]  tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 711/1000] [D loss: 0.836520] [G loss: 0.339126] [FAKE loss: 1.246276]  tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 712/1000] [D loss: 0.846223] [G loss: 0.329387] [FAKE loss: 1.270826]  tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 713/1000] [D loss: 0.856403] [G loss: 0.319597] [FAKE loss: 1.296368]  tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 714/1000] [D loss: 0.866747] [G loss: 0.310015] [FAKE loss: 1.322273]  tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 715/1000] [D loss: 0.877433] [G loss: 0.300512] [FAKE loss: 1.348893]  tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 716/1000] [D loss: 0.888443] [G loss: 0.291117] [FAKE loss: 1.376186]  tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 717/1000] [D loss: 0.899452] [G loss: 0.282054] [FAKE loss: 1.403499]  tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 718/1000] [D loss: 0.910904] [G loss: 0.273029] [FAKE loss: 1.431714]  tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 719/1000] [D loss: 0.922641] [G loss: 0.264158] [FAKE loss: 1.460514]  tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 720/1000] [D loss: 0.934344] [G loss: 0.255630] [FAKE loss: 1.489256]  tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 721/1000] [D loss: 0.946508] [G loss: 0.247153] [FAKE loss: 1.518920]  tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 722/1000] [D loss: 0.958940] [G loss: 0.238849] [FAKE loss: 1.549117]  tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 723/1000] [D loss: 0.971418] [G loss: 0.230837] [FAKE loss: 1.579395]  tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 724/1000] [D loss: 0.984011] [G loss: 0.223069] [FAKE loss: 1.609892]  tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 725/1000] [D loss: 0.996956] [G loss: 0.215427] [FAKE loss: 1.641072]  tensor(0.8062, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 726/1000] [D loss: 1.009856] [G loss: 0.208101] [FAKE loss: 1.672138]  tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 727/1000] [D loss: 1.022941] [G loss: 0.200975] [FAKE loss: 1.703544]  tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 728/1000] [D loss: 1.036226] [G loss: 0.194040] [FAKE loss: 1.735312]  tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 729/1000] [D loss: 1.049422] [G loss: 0.187413] [FAKE loss: 1.766860]  tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 730/1000] [D loss: 1.062724] [G loss: 0.180998] [FAKE loss: 1.798575]  tensor(0.8344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 731/1000] [D loss: 1.076109] [G loss: 0.174803] [FAKE loss: 1.830397]  tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 732/1000] [D loss: 1.089197] [G loss: 0.168961] [FAKE loss: 1.861564]  tensor(0.8445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 733/1000] [D loss: 1.102450] [G loss: 0.163281] [FAKE loss: 1.892992]  tensor(0.8494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 734/1000] [D loss: 1.115690] [G loss: 0.157825] [FAKE loss: 1.924323]  tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 735/1000] [D loss: 1.128492] [G loss: 0.152725] [FAKE loss: 1.954695]  tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 736/1000] [D loss: 1.141323] [G loss: 0.147805] [FAKE loss: 1.985040]  tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 737/1000] [D loss: 1.153908] [G loss: 0.143146] [FAKE loss: 2.014800]  tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 738/1000] [D loss: 1.166342] [G loss: 0.138703] [FAKE loss: 2.044157]  tensor(0.8705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 739/1000] [D loss: 1.178343] [G loss: 0.134548] [FAKE loss: 2.072546]  tensor(0.8741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 740/1000] [D loss: 1.190199] [G loss: 0.130580] [FAKE loss: 2.100533]  tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 741/1000] [D loss: 1.201642] [G loss: 0.126865] [FAKE loss: 2.127580]  tensor(0.8809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 742/1000] [D loss: 1.212784] [G loss: 0.123357] [FAKE loss: 2.153902]  tensor(0.8840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 743/1000] [D loss: 1.223186] [G loss: 0.120157] [FAKE loss: 2.178618]  tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 744/1000] [D loss: 1.233549] [G loss: 0.117070] [FAKE loss: 2.203125]  tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 745/1000] [D loss: 1.243185] [G loss: 0.114261] [FAKE loss: 2.226042]  tensor(0.8920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 746/1000] [D loss: 1.252245] [G loss: 0.111675] [FAKE loss: 2.247667]  tensor(0.8943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 747/1000] [D loss: 1.260900] [G loss: 0.109261] [FAKE loss: 2.268335]  tensor(0.8965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 748/1000] [D loss: 1.268915] [G loss: 0.107062] [FAKE loss: 2.287574]  tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 749/1000] [D loss: 1.276268] [G loss: 0.105075] [FAKE loss: 2.305338]  tensor(0.9003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 750/1000] [D loss: 1.282850] [G loss: 0.103310] [FAKE loss: 2.321404]  tensor(0.9018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 751/1000] [D loss: 1.289023] [G loss: 0.101682] [FAKE loss: 2.336493]  tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 752/1000] [D loss: 1.294179] [G loss: 0.100312] [FAKE loss: 2.349385]  tensor(0.9046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 753/1000] [D loss: 1.298561] [G loss: 0.099139] [FAKE loss: 2.360565]  tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 754/1000] [D loss: 1.302470] [G loss: 0.098095] [FAKE loss: 2.370632]  tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 755/1000] [D loss: 1.305219] [G loss: 0.097318] [FAKE loss: 2.378209]  tensor(0.9073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 756/1000] [D loss: 1.307688] [G loss: 0.096621] [FAKE loss: 2.385055]  tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 757/1000] [D loss: 1.308800] [G loss: 0.096220] [FAKE loss: 2.389011]  tensor(0.9083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 758/1000] [D loss: 1.309477] [G loss: 0.095927] [FAKE loss: 2.391922]  tensor(0.9085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 759/1000] [D loss: 1.309098] [G loss: 0.095864] [FAKE loss: 2.392546]  tensor(0.9086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 760/1000] [D loss: 1.308021] [G loss: 0.095960] [FAKE loss: 2.391593]  tensor(0.9085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 761/1000] [D loss: 1.305879] [G loss: 0.096289] [FAKE loss: 2.388331]  tensor(0.9082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 762/1000] [D loss: 1.303194] [G loss: 0.096748] [FAKE loss: 2.383801]  tensor(0.9078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 763/1000] [D loss: 1.299373] [G loss: 0.097461] [FAKE loss: 2.376817]  tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 764/1000] [D loss: 1.294884] [G loss: 0.098335] [FAKE loss: 2.368314]  tensor(0.9063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 765/1000] [D loss: 1.289510] [G loss: 0.099422] [FAKE loss: 2.357858]  tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 766/1000] [D loss: 1.283404] [G loss: 0.100698] [FAKE loss: 2.345752]  tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 767/1000] [D loss: 1.276427] [G loss: 0.102195] [FAKE loss: 2.331717]  tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 768/1000] [D loss: 1.268667] [G loss: 0.103909] [FAKE loss: 2.315933]  tensor(0.9013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 769/1000] [D loss: 1.260221] [G loss: 0.105827] [FAKE loss: 2.298591]  tensor(0.8996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 770/1000] [D loss: 1.251107] [G loss: 0.107955] [FAKE loss: 2.279724]  tensor(0.8977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 771/1000] [D loss: 1.241087] [G loss: 0.110362] [FAKE loss: 2.258861]  tensor(0.8955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 772/1000] [D loss: 1.230681] [G loss: 0.112939] [FAKE loss: 2.237038]  tensor(0.8932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 773/1000] [D loss: 1.219601] [G loss: 0.115770] [FAKE loss: 2.213682]  tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 774/1000] [D loss: 1.207534] [G loss: 0.118947] [FAKE loss: 2.188165]  tensor(0.8879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 775/1000] [D loss: 1.195351] [G loss: 0.122272] [FAKE loss: 2.162230]  tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 776/1000] [D loss: 1.182355] [G loss: 0.125939] [FAKE loss: 2.134483]  tensor(0.8817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 777/1000] [D loss: 1.169172] [G loss: 0.129800] [FAKE loss: 2.106177]  tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 778/1000] [D loss: 1.155265] [G loss: 0.134021] [FAKE loss: 2.076237]  tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 779/1000] [D loss: 1.141354] [G loss: 0.138420] [FAKE loss: 2.046106]  tensor(0.8707, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 780/1000] [D loss: 1.126515] [G loss: 0.143284] [FAKE loss: 2.013935]  tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 781/1000] [D loss: 1.111605] [G loss: 0.148387] [FAKE loss: 1.981438]  tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 782/1000] [D loss: 1.096666] [G loss: 0.153726] [FAKE loss: 1.948703]  tensor(0.8575, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 783/1000] [D loss: 1.081226] [G loss: 0.159475] [FAKE loss: 1.914786]  tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 784/1000] [D loss: 1.065299] [G loss: 0.165666] [FAKE loss: 1.879713]  tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 785/1000] [D loss: 1.049443] [G loss: 0.172125] [FAKE loss: 1.844604]  tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 786/1000] [D loss: 1.033674] [G loss: 0.178862] [FAKE loss: 1.809493]  tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 787/1000] [D loss: 1.017431] [G loss: 0.186114] [FAKE loss: 1.773259]  tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 788/1000] [D loss: 1.001443] [G loss: 0.193620] [FAKE loss: 1.737360]  tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 789/1000] [D loss: 0.985166] [G loss: 0.201626] [FAKE loss: 1.700712]  tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 790/1000] [D loss: 0.969053] [G loss: 0.209965] [FAKE loss: 1.664222]  tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 791/1000] [D loss: 0.952780] [G loss: 0.218805] [FAKE loss: 1.627245]  tensor(0.8035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 792/1000] [D loss: 0.937057] [G loss: 0.227822] [FAKE loss: 1.591203]  tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 793/1000] [D loss: 0.921064] [G loss: 0.237443] [FAKE loss: 1.554461]  tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 794/1000] [D loss: 0.905422] [G loss: 0.247373] [FAKE loss: 1.518261]  tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 795/1000] [D loss: 0.889766] [G loss: 0.257825] [FAKE loss: 1.481879]  tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 796/1000] [D loss: 0.874192] [G loss: 0.268777] [FAKE loss: 1.445510]  tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 797/1000] [D loss: 0.859100] [G loss: 0.280002] [FAKE loss: 1.409957]  tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 798/1000] [D loss: 0.844435] [G loss: 0.291526] [FAKE loss: 1.375113]  tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 799/1000] [D loss: 0.829774] [G loss: 0.303647] [FAKE loss: 1.340138]  tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 800/1000] [D loss: 0.815230] [G loss: 0.316312] [FAKE loss: 1.305263]  tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 801/1000] [D loss: 0.801413] [G loss: 0.329089] [FAKE loss: 1.271716]  tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 802/1000] [D loss: 0.787668] [G loss: 0.342461] [FAKE loss: 1.238190]  tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 803/1000] [D loss: 0.774214] [G loss: 0.356282] [FAKE loss: 1.205132]  tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 804/1000] [D loss: 0.761464] [G loss: 0.370192] [FAKE loss: 1.173371]  tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 805/1000] [D loss: 0.748509] [G loss: 0.384989] [FAKE loss: 1.141101]  tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 806/1000] [D loss: 0.736263] [G loss: 0.399857] [FAKE loss: 1.110157]  tensor(0.6704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 807/1000] [D loss: 0.724366] [G loss: 0.415111] [FAKE loss: 1.079827]  tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 808/1000] [D loss: 0.712777] [G loss: 0.430787] [FAKE loss: 1.050040]  tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 809/1000] [D loss: 0.701505] [G loss: 0.446874] [FAKE loss: 1.020822]  tensor(0.6397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 810/1000] [D loss: 0.690840] [G loss: 0.463036] [FAKE loss: 0.992766]  tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 811/1000] [D loss: 0.680519] [G loss: 0.479537] [FAKE loss: 0.965355]  tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 812/1000] [D loss: 0.670649] [G loss: 0.496221] [FAKE loss: 0.938820]  tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 813/1000] [D loss: 0.661048] [G loss: 0.513299] [FAKE loss: 0.912806]  tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 814/1000] [D loss: 0.651908] [G loss: 0.530485] [FAKE loss: 0.887716]  tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 815/1000] [D loss: 0.643072] [G loss: 0.547974] [FAKE loss: 0.863246]  tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 816/1000] [D loss: 0.634816] [G loss: 0.565307] [FAKE loss: 0.839969]  tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 817/1000] [D loss: 0.627001] [G loss: 0.582636] [FAKE loss: 0.817622]  tensor(0.5585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 818/1000] [D loss: 0.619344] [G loss: 0.600352] [FAKE loss: 0.795657]  tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 819/1000] [D loss: 0.612259] [G loss: 0.617744] [FAKE loss: 0.774923]  tensor(0.5392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 820/1000] [D loss: 0.605647] [G loss: 0.634884] [FAKE loss: 0.755242]  tensor(0.5300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 821/1000] [D loss: 0.599259] [G loss: 0.652142] [FAKE loss: 0.736136]  tensor(0.5210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 822/1000] [D loss: 0.593288] [G loss: 0.669097] [FAKE loss: 0.718016]  tensor(0.5122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 823/1000] [D loss: 0.587680] [G loss: 0.685788] [FAKE loss: 0.700796]  tensor(0.5038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 824/1000] [D loss: 0.582607] [G loss: 0.701773] [FAKE loss: 0.684844]  tensor(0.4958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 825/1000] [D loss: 0.578009] [G loss: 0.717046] [FAKE loss: 0.670067]  tensor(0.4883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 826/1000] [D loss: 0.573587] [G loss: 0.732125] [FAKE loss: 0.655895]  tensor(0.4810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 827/1000] [D loss: 0.569685] [G loss: 0.746205] [FAKE loss: 0.643040]  tensor(0.4742, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 828/1000] [D loss: 0.566141] [G loss: 0.759509] [FAKE loss: 0.631206]  tensor(0.4680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 829/1000] [D loss: 0.562854] [G loss: 0.772151] [FAKE loss: 0.620220]  tensor(0.4621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 830/1000] [D loss: 0.560173] [G loss: 0.783254] [FAKE loss: 0.610805]  tensor(0.4570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 831/1000] [D loss: 0.557547] [G loss: 0.793965] [FAKE loss: 0.601887]  tensor(0.4521, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 832/1000] [D loss: 0.555564] [G loss: 0.802796] [FAKE loss: 0.594670]  tensor(0.4482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 833/1000] [D loss: 0.553838] [G loss: 0.810570] [FAKE loss: 0.588407]  tensor(0.4447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 834/1000] [D loss: 0.552405] [G loss: 0.817132] [FAKE loss: 0.583195]  tensor(0.4418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 835/1000] [D loss: 0.551467] [G loss: 0.821884] [FAKE loss: 0.579464]  tensor(0.4397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 836/1000] [D loss: 0.550625] [G loss: 0.825769] [FAKE loss: 0.576433]  tensor(0.4380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 837/1000] [D loss: 0.550419] [G loss: 0.827350] [FAKE loss: 0.575203]  tensor(0.4373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 838/1000] [D loss: 0.550371] [G loss: 0.827820] [FAKE loss: 0.574838]  tensor(0.4371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 839/1000] [D loss: 0.550606] [G loss: 0.826858] [FAKE loss: 0.575601]  tensor(0.4375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 840/1000] [D loss: 0.551203] [G loss: 0.824228] [FAKE loss: 0.577657]  tensor(0.4387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 841/1000] [D loss: 0.552397] [G loss: 0.819365] [FAKE loss: 0.581489]  tensor(0.4408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 842/1000] [D loss: 0.553828] [G loss: 0.813194] [FAKE loss: 0.586380]  tensor(0.4436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 843/1000] [D loss: 0.555497] [G loss: 0.805788] [FAKE loss: 0.592332]  tensor(0.4469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 844/1000] [D loss: 0.557680] [G loss: 0.796505] [FAKE loss: 0.599894]  tensor(0.4510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 845/1000] [D loss: 0.560279] [G loss: 0.785700] [FAKE loss: 0.608863]  tensor(0.4559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 846/1000] [D loss: 0.563414] [G loss: 0.773207] [FAKE loss: 0.619467]  tensor(0.4617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 847/1000] [D loss: 0.566975] [G loss: 0.759384] [FAKE loss: 0.631474]  tensor(0.4681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 848/1000] [D loss: 0.570673] [G loss: 0.745015] [FAKE loss: 0.644288]  tensor(0.4749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 849/1000] [D loss: 0.575196] [G loss: 0.728709] [FAKE loss: 0.659267]  tensor(0.4827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 850/1000] [D loss: 0.580348] [G loss: 0.711081] [FAKE loss: 0.675990]  tensor(0.4912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 851/1000] [D loss: 0.585757] [G loss: 0.693044] [FAKE loss: 0.693686]  tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 852/1000] [D loss: 0.591590] [G loss: 0.674413] [FAKE loss: 0.712658]  tensor(0.5096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 853/1000] [D loss: 0.597846] [G loss: 0.655312] [FAKE loss: 0.732877]  tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 854/1000] [D loss: 0.604528] [G loss: 0.635859] [FAKE loss: 0.754314]  tensor(0.5296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 855/1000] [D loss: 0.611765] [G loss: 0.615953] [FAKE loss: 0.777197]  tensor(0.5402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 856/1000] [D loss: 0.619090] [G loss: 0.596479] [FAKE loss: 0.800554]  tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 857/1000] [D loss: 0.626825] [G loss: 0.576970] [FAKE loss: 0.824992]  tensor(0.5617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 858/1000] [D loss: 0.635211] [G loss: 0.557152] [FAKE loss: 0.850957]  tensor(0.5729, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 859/1000] [D loss: 0.643799] [G loss: 0.537788] [FAKE loss: 0.877518]  tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 860/1000] [D loss: 0.652836] [G loss: 0.518562] [FAKE loss: 0.905137]  tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 861/1000] [D loss: 0.661981] [G loss: 0.499994] [FAKE loss: 0.933092]  tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 862/1000] [D loss: 0.671584] [G loss: 0.481644] [FAKE loss: 0.962051]  tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 863/1000] [D loss: 0.681127] [G loss: 0.464170] [FAKE loss: 0.990950]  tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 864/1000] [D loss: 0.691428] [G loss: 0.446605] [FAKE loss: 1.021392]  tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 865/1000] [D loss: 0.701569] [G loss: 0.430037] [FAKE loss: 1.051507]  tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 866/1000] [D loss: 0.712017] [G loss: 0.413920] [FAKE loss: 1.082208]  tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 867/1000] [D loss: 0.722938] [G loss: 0.398093] [FAKE loss: 1.113796]  tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 868/1000] [D loss: 0.733582] [G loss: 0.383287] [FAKE loss: 1.144750]  tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 869/1000] [D loss: 0.743690] [G loss: 0.369664] [FAKE loss: 1.174532]  tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 870/1000] [D loss: 0.753869] [G loss: 0.356607] [FAKE loss: 1.204337]  tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 871/1000] [D loss: 0.763731] [G loss: 0.344415] [FAKE loss: 1.233370]  tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 872/1000] [D loss: 0.773553] [G loss: 0.332802] [FAKE loss: 1.262169]  tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 873/1000] [D loss: 0.783629] [G loss: 0.321526] [FAKE loss: 1.291305]  tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 874/1000] [D loss: 0.793671] [G loss: 0.310781] [FAKE loss: 1.320193]  tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 875/1000] [D loss: 0.803572] [G loss: 0.300618] [FAKE loss: 1.348606]  tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 876/1000] [D loss: 0.813432] [G loss: 0.290933] [FAKE loss: 1.376738]  tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 877/1000] [D loss: 0.822962] [G loss: 0.281890] [FAKE loss: 1.404003]  tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 878/1000] [D loss: 0.832769] [G loss: 0.273061] [FAKE loss: 1.431610]  tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 879/1000] [D loss: 0.842471] [G loss: 0.264676] [FAKE loss: 1.458793]  tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 880/1000] [D loss: 0.852226] [G loss: 0.256615] [FAKE loss: 1.485868]  tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 881/1000] [D loss: 0.862012] [G loss: 0.248874] [FAKE loss: 1.512789]  tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 882/1000] [D loss: 0.872263] [G loss: 0.241201] [FAKE loss: 1.540425]  tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 883/1000] [D loss: 0.882607] [G loss: 0.233803] [FAKE loss: 1.568029]  tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 884/1000] [D loss: 0.893099] [G loss: 0.226639] [FAKE loss: 1.595713]  tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 885/1000] [D loss: 0.903741] [G loss: 0.219695] [FAKE loss: 1.623485]  tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 886/1000] [D loss: 0.914652] [G loss: 0.212912] [FAKE loss: 1.651583]  tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 887/1000] [D loss: 0.925723] [G loss: 0.206335] [FAKE loss: 1.679791]  tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 888/1000] [D loss: 0.936918] [G loss: 0.199973] [FAKE loss: 1.708042]  tensor(0.8188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 889/1000] [D loss: 0.948369] [G loss: 0.193762] [FAKE loss: 1.736601]  tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 890/1000] [D loss: 0.959866] [G loss: 0.187783] [FAKE loss: 1.765051]  tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 891/1000] [D loss: 0.971507] [G loss: 0.181990] [FAKE loss: 1.793590]  tensor(0.8336, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 892/1000] [D loss: 0.983223] [G loss: 0.176399] [FAKE loss: 1.822085]  tensor(0.8383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 893/1000] [D loss: 0.995108] [G loss: 0.170968] [FAKE loss: 1.850726]  tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 894/1000] [D loss: 1.007118] [G loss: 0.165708] [FAKE loss: 1.879430]  tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 895/1000] [D loss: 1.018988] [G loss: 0.160702] [FAKE loss: 1.907673]  tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 896/1000] [D loss: 1.030913] [G loss: 0.155874] [FAKE loss: 1.935846]  tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 897/1000] [D loss: 1.042763] [G loss: 0.151252] [FAKE loss: 1.963694]  tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 898/1000] [D loss: 1.054520] [G loss: 0.146835] [FAKE loss: 1.991189]  tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 899/1000] [D loss: 1.066095] [G loss: 0.142637] [FAKE loss: 2.018155]  tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 900/1000] [D loss: 1.077719] [G loss: 0.138576] [FAKE loss: 2.045058]  tensor(0.8706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 901/1000] [D loss: 1.089505] [G loss: 0.134617] [FAKE loss: 2.072129]  tensor(0.8741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 902/1000] [D loss: 1.101338] [G loss: 0.130785] [FAKE loss: 2.099145]  tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 903/1000] [D loss: 1.112766] [G loss: 0.127197] [FAKE loss: 2.125202]  tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 904/1000] [D loss: 1.124493] [G loss: 0.123658] [FAKE loss: 2.151716]  tensor(0.8837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 905/1000] [D loss: 1.136135] [G loss: 0.120260] [FAKE loss: 2.177924]  tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 906/1000] [D loss: 1.147260] [G loss: 0.117105] [FAKE loss: 2.202963]  tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 907/1000] [D loss: 1.158647] [G loss: 0.113992] [FAKE loss: 2.228397]  tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 908/1000] [D loss: 1.169845] [G loss: 0.111025] [FAKE loss: 2.253329]  tensor(0.8949, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 909/1000] [D loss: 1.180647] [G loss: 0.108242] [FAKE loss: 2.277350]  tensor(0.8974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 910/1000] [D loss: 1.191463] [G loss: 0.105543] [FAKE loss: 2.301281]  tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 911/1000] [D loss: 1.202420] [G loss: 0.102899] [FAKE loss: 2.325380]  tensor(0.9022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 912/1000] [D loss: 1.212589] [G loss: 0.100500] [FAKE loss: 2.347796]  tensor(0.9044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 913/1000] [D loss: 1.223114] [G loss: 0.098097] [FAKE loss: 2.370819]  tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 914/1000] [D loss: 1.232919] [G loss: 0.095910] [FAKE loss: 2.392299]  tensor(0.9085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 915/1000] [D loss: 1.243089] [G loss: 0.093714] [FAKE loss: 2.414413]  tensor(0.9105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 916/1000] [D loss: 1.252447] [G loss: 0.091732] [FAKE loss: 2.434806]  tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 917/1000] [D loss: 1.261845] [G loss: 0.089797] [FAKE loss: 2.455185]  tensor(0.9141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 918/1000] [D loss: 1.270708] [G loss: 0.088012] [FAKE loss: 2.474408]  tensor(0.9158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 919/1000] [D loss: 1.279271] [G loss: 0.086324] [FAKE loss: 2.492942]  tensor(0.9173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 920/1000] [D loss: 1.287625] [G loss: 0.084715] [FAKE loss: 2.510972]  tensor(0.9188, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 921/1000] [D loss: 1.295472] [G loss: 0.083233] [FAKE loss: 2.527907]  tensor(0.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 922/1000] [D loss: 1.303574] [G loss: 0.081741] [FAKE loss: 2.545269]  tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 923/1000] [D loss: 1.310673] [G loss: 0.080451] [FAKE loss: 2.560549]  tensor(0.9227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 924/1000] [D loss: 1.317216] [G loss: 0.079279] [FAKE loss: 2.574641]  tensor(0.9238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 925/1000] [D loss: 1.323680] [G loss: 0.078146] [FAKE loss: 2.588500]  tensor(0.9248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 926/1000] [D loss: 1.329608] [G loss: 0.077119] [FAKE loss: 2.601213]  tensor(0.9258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 927/1000] [D loss: 1.335307] [G loss: 0.076152] [FAKE loss: 2.613397]  tensor(0.9267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 928/1000] [D loss: 1.340085] [G loss: 0.075342] [FAKE loss: 2.623668]  tensor(0.9274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 929/1000] [D loss: 1.344978] [G loss: 0.074532] [FAKE loss: 2.634100]  tensor(0.9282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 930/1000] [D loss: 1.349175] [G loss: 0.073842] [FAKE loss: 2.643075]  tensor(0.9288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 931/1000] [D loss: 1.352791] [G loss: 0.073251] [FAKE loss: 2.650820]  tensor(0.9294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 932/1000] [D loss: 1.355956] [G loss: 0.072740] [FAKE loss: 2.657597]  tensor(0.9298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 933/1000] [D loss: 1.358585] [G loss: 0.072315] [FAKE loss: 2.663238]  tensor(0.9302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 934/1000] [D loss: 1.361046] [G loss: 0.071925] [FAKE loss: 2.668479]  tensor(0.9306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 935/1000] [D loss: 1.362762] [G loss: 0.071651] [FAKE loss: 2.672167]  tensor(0.9309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 936/1000] [D loss: 1.363797] [G loss: 0.071484] [FAKE loss: 2.674428]  tensor(0.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 937/1000] [D loss: 1.364597] [G loss: 0.071358] [FAKE loss: 2.676157]  tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 938/1000] [D loss: 1.364962] [G loss: 0.071299] [FAKE loss: 2.676955]  tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 939/1000] [D loss: 1.364612] [G loss: 0.071351] [FAKE loss: 2.676258]  tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 940/1000] [D loss: 1.363972] [G loss: 0.071450] [FAKE loss: 2.674919]  tensor(0.9310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 941/1000] [D loss: 1.362647] [G loss: 0.071658] [FAKE loss: 2.672148]  tensor(0.9309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 942/1000] [D loss: 1.361238] [G loss: 0.071881] [FAKE loss: 2.669147]  tensor(0.9306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 943/1000] [D loss: 1.358652] [G loss: 0.072287] [FAKE loss: 2.663725]  tensor(0.9303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 944/1000] [D loss: 1.356226] [G loss: 0.072676] [FAKE loss: 2.658561]  tensor(0.9299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 945/1000] [D loss: 1.353296] [G loss: 0.073147] [FAKE loss: 2.652325]  tensor(0.9295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 946/1000] [D loss: 1.349811] [G loss: 0.073716] [FAKE loss: 2.644913]  tensor(0.9289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 947/1000] [D loss: 1.345197] [G loss: 0.074463] [FAKE loss: 2.635176]  tensor(0.9282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 948/1000] [D loss: 1.340780] [G loss: 0.075196] [FAKE loss: 2.625764]  tensor(0.9276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 949/1000] [D loss: 1.336207] [G loss: 0.075965] [FAKE loss: 2.615974]  tensor(0.9269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 950/1000] [D loss: 1.330785] [G loss: 0.076882] [FAKE loss: 2.604416]  tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 951/1000] [D loss: 1.324935] [G loss: 0.077887] [FAKE loss: 2.591929]  tensor(0.9251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 952/1000] [D loss: 1.319247] [G loss: 0.078887] [FAKE loss: 2.579693]  tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 953/1000] [D loss: 1.312544] [G loss: 0.080072] [FAKE loss: 2.565354]  tensor(0.9231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 954/1000] [D loss: 1.305869] [G loss: 0.081278] [FAKE loss: 2.550993]  tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 955/1000] [D loss: 1.298651] [G loss: 0.082605] [FAKE loss: 2.535469]  tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 956/1000] [D loss: 1.291036] [G loss: 0.084030] [FAKE loss: 2.519068]  tensor(0.9194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 957/1000] [D loss: 1.283396] [G loss: 0.085492] [FAKE loss: 2.502538]  tensor(0.9181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 958/1000] [D loss: 1.275348] [G loss: 0.087063] [FAKE loss: 2.485106]  tensor(0.9166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 959/1000] [D loss: 1.267011] [G loss: 0.088729] [FAKE loss: 2.467010]  tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 960/1000] [D loss: 1.258012] [G loss: 0.090556] [FAKE loss: 2.447499]  tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 961/1000] [D loss: 1.249772] [G loss: 0.092290] [FAKE loss: 2.429416]  tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 962/1000] [D loss: 1.240530] [G loss: 0.094264] [FAKE loss: 2.409231]  tensor(0.9100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 963/1000] [D loss: 1.231619] [G loss: 0.096224] [FAKE loss: 2.389612]  tensor(0.9083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 964/1000] [D loss: 1.222559] [G loss: 0.098268] [FAKE loss: 2.369594]  tensor(0.9064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 965/1000] [D loss: 1.212829] [G loss: 0.100515] [FAKE loss: 2.348131]  tensor(0.9044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 966/1000] [D loss: 1.202695] [G loss: 0.102905] [FAKE loss: 2.325753]  tensor(0.9022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 967/1000] [D loss: 1.193389] [G loss: 0.105192] [FAKE loss: 2.304923]  tensor(0.9002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 968/1000] [D loss: 1.183810] [G loss: 0.107604] [FAKE loss: 2.283431]  tensor(0.8980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 969/1000] [D loss: 1.173841] [G loss: 0.110182] [FAKE loss: 2.261045]  tensor(0.8957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 970/1000] [D loss: 1.163736] [G loss: 0.112871] [FAKE loss: 2.238266]  tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 971/1000] [D loss: 1.154059] [G loss: 0.115537] [FAKE loss: 2.216219]  tensor(0.8909, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 972/1000] [D loss: 1.144500] [G loss: 0.118259] [FAKE loss: 2.194284]  tensor(0.8885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 973/1000] [D loss: 1.134673] [G loss: 0.121130] [FAKE loss: 2.171681]  tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 974/1000] [D loss: 1.124618] [G loss: 0.124157] [FAKE loss: 2.148489]  tensor(0.8833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 975/1000] [D loss: 1.115164] [G loss: 0.127121] [FAKE loss: 2.126363]  tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 976/1000] [D loss: 1.105019] [G loss: 0.130368] [FAKE loss: 2.102714]  tensor(0.8778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 977/1000] [D loss: 1.095291] [G loss: 0.133606] [FAKE loss: 2.079755]  tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 978/1000] [D loss: 1.086094] [G loss: 0.136806] [FAKE loss: 2.057711]  tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 979/1000] [D loss: 1.076458] [G loss: 0.140228] [FAKE loss: 2.034638]  tensor(0.8692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 980/1000] [D loss: 1.066993] [G loss: 0.143719] [FAKE loss: 2.011756]  tensor(0.8661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 981/1000] [D loss: 1.057735] [G loss: 0.147262] [FAKE loss: 1.989130]  tensor(0.8631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 982/1000] [D loss: 1.049418] [G loss: 0.150625] [FAKE loss: 1.968225]  tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 983/1000] [D loss: 1.040161] [G loss: 0.154405] [FAKE loss: 1.945280]  tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 984/1000] [D loss: 1.031405] [G loss: 0.158148] [FAKE loss: 1.923169]  tensor(0.8537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 985/1000] [D loss: 1.022727] [G loss: 0.161992] [FAKE loss: 1.901044]  tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 986/1000] [D loss: 1.014721] [G loss: 0.165722] [FAKE loss: 1.880090]  tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 987/1000] [D loss: 1.006562] [G loss: 0.169640] [FAKE loss: 1.858654]  tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 988/1000] [D loss: 0.998938] [G loss: 0.173488] [FAKE loss: 1.838110]  tensor(0.8408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 989/1000] [D loss: 0.991366] [G loss: 0.177451] [FAKE loss: 1.817487]  tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 990/1000] [D loss: 0.983674] [G loss: 0.181591] [FAKE loss: 1.796440]  tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 991/1000] [D loss: 0.976451] [G loss: 0.185689] [FAKE loss: 1.776148]  tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 992/1000] [D loss: 0.969763] [G loss: 0.189688] [FAKE loss: 1.756734]  tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 993/1000] [D loss: 0.962940] [G loss: 0.193897] [FAKE loss: 1.736859]  tensor(0.8238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 994/1000] [D loss: 0.956246] [G loss: 0.198193] [FAKE loss: 1.717050]  tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 995/1000] [D loss: 0.949268] [G loss: 0.202765] [FAKE loss: 1.696477]  tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 996/1000] [D loss: 0.943017] [G loss: 0.207162] [FAKE loss: 1.677166]  tensor(0.8129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 997/1000] [D loss: 0.936750] [G loss: 0.211712] [FAKE loss: 1.657625]  tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 998/1000] [D loss: 0.930116] [G loss: 0.216610] [FAKE loss: 1.637153]  tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 999/1000] [D loss: 0.923515] [G loss: 0.221653] [FAKE loss: 1.616547]  tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata[1][20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxGbIq8foM9G",
        "outputId": "4f8810ff-24fc-4b40-9702-b26da1098c10"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6706, 0.5291, 0.4776, 0.7575, 0.4628, 0.7214, 0.5276, 0.3733, 0.4033])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newday0[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m11B0YRNoM6D",
        "outputId": "6d9b6bb9-9582-4191-daf2-7f2d787511ec"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.86956522, 0.69230885, 0.97745217, 0.38405288, 0.45395526,\n",
              "       0.04371511, 0.00603349, 0.00466667, 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim \n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input = 9 \n",
        "    self.output= 1\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input, 32), # input size, hidden size\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(32, 64),\n",
        "        nn.LeakyReLU(0.8),\n",
        "        nn.Linear(64, 128),\n",
        "        nn.LeakyReLU(0.5),\n",
        "        nn.Linear(128, self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.features = 9 # 피쳐수\n",
        "    self.output = 9  # 데이터수\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.features, 128), # input size, hidden size\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(128, 32),\n",
        "        nn.Sigmoid(),\n",
        "        #nn.LeakyReLU(0.2),\n",
        "        nn.Linear(32, self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print('generator',x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "# 모델 정의\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
        "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
        "\n",
        "criterion = nn.BCELoss().to(device)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=g_optim, mode='min', verbose=True, patience=10, factor=0.5)\n",
        "\n",
        "import time\n",
        "n_epochs = 1000\n",
        "noise = 9\n",
        "start_time = time.time()\n",
        "newdata = []\n",
        "testdata = []\n",
        "#print(real_data)\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  test = day0.iloc[:28].values\n",
        "  \n",
        "  nptonn = torch.from_numpy(newday0).float()\n",
        "\n",
        "  real = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(1.0) # \n",
        "  fake = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(0.0) # \n",
        "\n",
        "  real_data = nptonn.cuda()\n",
        "  g_optim.zero_grad()\n",
        "\n",
        "  z0 = torch.normal(mean=11.5, std=6.9, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z1 = torch.normal(mean=25.78, std=4.3, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z2 = torch.normal(mean=54.91, std=12.2, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z3 = torch.normal(mean=533.833, std=144.1, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z4 = torch.normal(mean=1.273, std=0.932, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z5 = torch.normal(mean=430.600, std=491.308, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z6 = torch.normal(mean=6765.408, std=9450.28, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z7 = torch.normal(mean=1309.564, std=2653.722, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z8 = torch.normal(mean=856.852, std=1938.17, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  zz = torch.normal(mean=0, std=1, size=(nptonn.shape[0], noise)).cuda()\n",
        "\n",
        "  z = torch.cat([z0,z1,z2,z3,z4,z5,z6,z7,z8], dim=1) #[M, N+N, K]\n",
        "  #print(z.size())\n",
        "\n",
        "  generated_dis = generator(z) # create distribution\n",
        "  #print(generated_dis.size())\n",
        "  #print(real_data.size())\n",
        "  generated_dis_value = generated_dis.detach().cpu()\n",
        "  g_loss =  criterion(discriminator(generated_dis), real) # calculate generator loss\n",
        "  \n",
        "  # update generator\n",
        "  g_loss.backward()\n",
        "  g_optim.step()\n",
        "\n",
        "  # update discriminator\n",
        "  real_loss = criterion(discriminator(real_data), real)\n",
        "  r_score = discriminator(real_data).mean()\n",
        "  fake_loss = criterion(discriminator(generated_dis.detach()), fake)\n",
        "  g_score = discriminator(generated_dis).mean()\n",
        "  d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "  if g_score > 0.8 :\n",
        "    newdata.append(generated_dis_value)\n",
        "\n",
        "  d_loss.backward()\n",
        "  d_optim.step()\n",
        "\n",
        "  print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [FAKE loss: {fake_loss.item():.6f}] \",\n",
        "        g_score, r_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7sBFUQpoM3E",
        "outputId": "a518fc75-aeab-4fe5-f213-7777f1b37f47"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/1000] [D loss: 0.699701] [G loss: 0.608103] [FAKE loss: 0.786441]  tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 1/1000] [D loss: 0.700927] [G loss: 0.601284] [FAKE loss: 0.794602]  tensor(0.5482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 2/1000] [D loss: 0.702200] [G loss: 0.594715] [FAKE loss: 0.802637]  tensor(0.5517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 3/1000] [D loss: 0.703381] [G loss: 0.588613] [FAKE loss: 0.810652]  tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 4/1000] [D loss: 0.704363] [G loss: 0.581906] [FAKE loss: 0.818443]  tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 5/1000] [D loss: 0.705943] [G loss: 0.575607] [FAKE loss: 0.826991]  tensor(0.5625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 6/1000] [D loss: 0.707265] [G loss: 0.568972] [FAKE loss: 0.835148]  tensor(0.5661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 7/1000] [D loss: 0.708925] [G loss: 0.562624] [FAKE loss: 0.844003]  tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 8/1000] [D loss: 0.710649] [G loss: 0.556042] [FAKE loss: 0.853297]  tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 9/1000] [D loss: 0.712123] [G loss: 0.549509] [FAKE loss: 0.862014]  tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 10/1000] [D loss: 0.713904] [G loss: 0.542063] [FAKE loss: 0.871283]  tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 11/1000] [D loss: 0.716026] [G loss: 0.536007] [FAKE loss: 0.881242]  tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 12/1000] [D loss: 0.717680] [G loss: 0.528545] [FAKE loss: 0.890772]  tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 13/1000] [D loss: 0.719915] [G loss: 0.521368] [FAKE loss: 0.900704]  tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 14/1000] [D loss: 0.722443] [G loss: 0.514231] [FAKE loss: 0.911928]  tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 15/1000] [D loss: 0.724750] [G loss: 0.507332] [FAKE loss: 0.922387]  tensor(0.6023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 16/1000] [D loss: 0.727519] [G loss: 0.499706] [FAKE loss: 0.934166]  tensor(0.6067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 17/1000] [D loss: 0.730068] [G loss: 0.492887] [FAKE loss: 0.945178]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 18/1000] [D loss: 0.733218] [G loss: 0.485338] [FAKE loss: 0.957673]  tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 19/1000] [D loss: 0.735798] [G loss: 0.477713] [FAKE loss: 0.969168]  tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 20/1000] [D loss: 0.738868] [G loss: 0.470258] [FAKE loss: 0.981725]  tensor(0.6253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 21/1000] [D loss: 0.742297] [G loss: 0.462729] [FAKE loss: 0.994659]  tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 22/1000] [D loss: 0.745919] [G loss: 0.455397] [FAKE loss: 1.008363]  tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 23/1000] [D loss: 0.749208] [G loss: 0.446642] [FAKE loss: 1.021361]  tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 24/1000] [D loss: 0.753573] [G loss: 0.439671] [FAKE loss: 1.036274]  tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 25/1000] [D loss: 0.757902] [G loss: 0.431271] [FAKE loss: 1.051264]  tensor(0.6497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 26/1000] [D loss: 0.761946] [G loss: 0.423312] [FAKE loss: 1.065867]  tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 27/1000] [D loss: 0.766148] [G loss: 0.416032] [FAKE loss: 1.081244]  tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 28/1000] [D loss: 0.771084] [G loss: 0.407891] [FAKE loss: 1.097276]  tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 29/1000] [D loss: 0.776396] [G loss: 0.399640] [FAKE loss: 1.114427]  tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 30/1000] [D loss: 0.781528] [G loss: 0.391952] [FAKE loss: 1.131634]  tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 31/1000] [D loss: 0.787048] [G loss: 0.383900] [FAKE loss: 1.148582]  tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 32/1000] [D loss: 0.792006] [G loss: 0.376396] [FAKE loss: 1.166021]  tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 33/1000] [D loss: 0.798111] [G loss: 0.367088] [FAKE loss: 1.184432]  tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 34/1000] [D loss: 0.804399] [G loss: 0.359075] [FAKE loss: 1.203612]  tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 35/1000] [D loss: 0.810818] [G loss: 0.351570] [FAKE loss: 1.223576]  tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 36/1000] [D loss: 0.817497] [G loss: 0.342725] [FAKE loss: 1.242825]  tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 37/1000] [D loss: 0.824360] [G loss: 0.334826] [FAKE loss: 1.263670]  tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 38/1000] [D loss: 0.832051] [G loss: 0.326270] [FAKE loss: 1.285107]  tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 39/1000] [D loss: 0.837968] [G loss: 0.318768] [FAKE loss: 1.304862]  tensor(0.7274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 40/1000] [D loss: 0.846594] [G loss: 0.310761] [FAKE loss: 1.328593]  tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 41/1000] [D loss: 0.854663] [G loss: 0.303902] [FAKE loss: 1.350641]  tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 42/1000] [D loss: 0.862261] [G loss: 0.295765] [FAKE loss: 1.372618]  tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 43/1000] [D loss: 0.870683] [G loss: 0.288228] [FAKE loss: 1.395907]  tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 44/1000] [D loss: 0.880636] [G loss: 0.281456] [FAKE loss: 1.422944]  tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 45/1000] [D loss: 0.886589] [G loss: 0.272894] [FAKE loss: 1.440895]  tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 46/1000] [D loss: 0.896556] [G loss: 0.266040] [FAKE loss: 1.467860]  tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 47/1000] [D loss: 0.905564] [G loss: 0.259399] [FAKE loss: 1.492031]  tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 48/1000] [D loss: 0.915370] [G loss: 0.251420] [FAKE loss: 1.517910]  tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 49/1000] [D loss: 0.924501] [G loss: 0.245562] [FAKE loss: 1.542039]  tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 50/1000] [D loss: 0.934501] [G loss: 0.239260] [FAKE loss: 1.567932]  tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 51/1000] [D loss: 0.945031] [G loss: 0.233212] [FAKE loss: 1.595050]  tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 52/1000] [D loss: 0.952933] [G loss: 0.225668] [FAKE loss: 1.617208]  tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 53/1000] [D loss: 0.961988] [G loss: 0.221022] [FAKE loss: 1.640952]  tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 54/1000] [D loss: 0.972889] [G loss: 0.214725] [FAKE loss: 1.668355]  tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 55/1000] [D loss: 0.981187] [G loss: 0.208932] [FAKE loss: 1.690977]  tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 56/1000] [D loss: 0.993109] [G loss: 0.204042] [FAKE loss: 1.718956]  tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 57/1000] [D loss: 1.000066] [G loss: 0.200005] [FAKE loss: 1.738423]  tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 58/1000] [D loss: 1.010205] [G loss: 0.193338] [FAKE loss: 1.763876]  tensor(0.8247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 59/1000] [D loss: 1.016857] [G loss: 0.189957] [FAKE loss: 1.780717]  tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 60/1000] [D loss: 1.024125] [G loss: 0.185546] [FAKE loss: 1.800327]  tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 61/1000] [D loss: 1.033082] [G loss: 0.182020] [FAKE loss: 1.823080]  tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 62/1000] [D loss: 1.041996] [G loss: 0.178477] [FAKE loss: 1.844419]  tensor(0.8379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 63/1000] [D loss: 1.047756] [G loss: 0.174920] [FAKE loss: 1.859636]  tensor(0.8409, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 64/1000] [D loss: 1.054731] [G loss: 0.171478] [FAKE loss: 1.876872]  tensor(0.8426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 65/1000] [D loss: 1.059769] [G loss: 0.169459] [FAKE loss: 1.891056]  tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 66/1000] [D loss: 1.065759] [G loss: 0.167826] [FAKE loss: 1.906116]  tensor(0.8472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 67/1000] [D loss: 1.069113] [G loss: 0.165028] [FAKE loss: 1.914442]  tensor(0.8490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 68/1000] [D loss: 1.072739] [G loss: 0.162778] [FAKE loss: 1.924807]  tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 69/1000] [D loss: 1.077793] [G loss: 0.161359] [FAKE loss: 1.937690]  tensor(0.8509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 70/1000] [D loss: 1.077193] [G loss: 0.161078] [FAKE loss: 1.938490]  tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 71/1000] [D loss: 1.081607] [G loss: 0.159467] [FAKE loss: 1.948495]  tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 72/1000] [D loss: 1.083465] [G loss: 0.158953] [FAKE loss: 1.952845]  tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 73/1000] [D loss: 1.080759] [G loss: 0.159409] [FAKE loss: 1.949332]  tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 74/1000] [D loss: 1.079624] [G loss: 0.159114] [FAKE loss: 1.948726]  tensor(0.8538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 75/1000] [D loss: 1.079219] [G loss: 0.158839] [FAKE loss: 1.947226]  tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 76/1000] [D loss: 1.078373] [G loss: 0.159948] [FAKE loss: 1.946405]  tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 77/1000] [D loss: 1.076147] [G loss: 0.160684] [FAKE loss: 1.942013]  tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 78/1000] [D loss: 1.069909] [G loss: 0.161727] [FAKE loss: 1.930032]  tensor(0.8509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 79/1000] [D loss: 1.067118] [G loss: 0.163549] [FAKE loss: 1.923122]  tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 80/1000] [D loss: 1.062746] [G loss: 0.164342] [FAKE loss: 1.913824]  tensor(0.8487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 81/1000] [D loss: 1.055249] [G loss: 0.166883] [FAKE loss: 1.897658]  tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 82/1000] [D loss: 1.050686] [G loss: 0.168578] [FAKE loss: 1.887530]  tensor(0.8455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 83/1000] [D loss: 1.045877] [G loss: 0.171521] [FAKE loss: 1.876048]  tensor(0.8434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 84/1000] [D loss: 1.037997] [G loss: 0.173851] [FAKE loss: 1.858835]  tensor(0.8408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 85/1000] [D loss: 1.028981] [G loss: 0.177888] [FAKE loss: 1.838536]  tensor(0.8386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 86/1000] [D loss: 1.021690] [G loss: 0.180155] [FAKE loss: 1.821987]  tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 87/1000] [D loss: 1.015362] [G loss: 0.184289] [FAKE loss: 1.807283]  tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 88/1000] [D loss: 1.009943] [G loss: 0.188298] [FAKE loss: 1.793498]  tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 89/1000] [D loss: 0.997502] [G loss: 0.191504] [FAKE loss: 1.765611]  tensor(0.8264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 90/1000] [D loss: 0.987857] [G loss: 0.195728] [FAKE loss: 1.744220]  tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 91/1000] [D loss: 0.981598] [G loss: 0.199407] [FAKE loss: 1.728342]  tensor(0.8189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 92/1000] [D loss: 0.971176] [G loss: 0.204948] [FAKE loss: 1.704215]  tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 93/1000] [D loss: 0.961956] [G loss: 0.209907] [FAKE loss: 1.681994]  tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 94/1000] [D loss: 0.953252] [G loss: 0.214443] [FAKE loss: 1.661052]  tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 95/1000] [D loss: 0.943598] [G loss: 0.218628] [FAKE loss: 1.639061]  tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 96/1000] [D loss: 0.933889] [G loss: 0.224812] [FAKE loss: 1.615251]  tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 97/1000] [D loss: 0.923877] [G loss: 0.229845] [FAKE loss: 1.591726]  tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 98/1000] [D loss: 0.916103] [G loss: 0.236049] [FAKE loss: 1.571482]  tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 99/1000] [D loss: 0.907808] [G loss: 0.241937] [FAKE loss: 1.551130]  tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 100/1000] [D loss: 0.898355] [G loss: 0.247003] [FAKE loss: 1.527952]  tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 101/1000] [D loss: 0.889007] [G loss: 0.253874] [FAKE loss: 1.505788]  tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 102/1000] [D loss: 0.881105] [G loss: 0.259935] [FAKE loss: 1.485295]  tensor(0.7716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 103/1000] [D loss: 0.872589] [G loss: 0.265823] [FAKE loss: 1.464005]  tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 104/1000] [D loss: 0.863057] [G loss: 0.272598] [FAKE loss: 1.440028]  tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 105/1000] [D loss: 0.856578] [G loss: 0.278761] [FAKE loss: 1.422338]  tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 106/1000] [D loss: 0.848336] [G loss: 0.284791] [FAKE loss: 1.401621]  tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 107/1000] [D loss: 0.840539] [G loss: 0.291929] [FAKE loss: 1.381269]  tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 108/1000] [D loss: 0.833389] [G loss: 0.297876] [FAKE loss: 1.362691]  tensor(0.7429, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 109/1000] [D loss: 0.826724] [G loss: 0.304521] [FAKE loss: 1.344310]  tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 110/1000] [D loss: 0.818866] [G loss: 0.311339] [FAKE loss: 1.324779]  tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 111/1000] [D loss: 0.812360] [G loss: 0.317527] [FAKE loss: 1.307571]  tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 112/1000] [D loss: 0.806660] [G loss: 0.324137] [FAKE loss: 1.290691]  tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 113/1000] [D loss: 0.799066] [G loss: 0.331022] [FAKE loss: 1.271096]  tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 114/1000] [D loss: 0.793644] [G loss: 0.337109] [FAKE loss: 1.255700]  tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 115/1000] [D loss: 0.787780] [G loss: 0.343296] [FAKE loss: 1.239748]  tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 116/1000] [D loss: 0.782268] [G loss: 0.349397] [FAKE loss: 1.224293]  tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 117/1000] [D loss: 0.777268] [G loss: 0.356489] [FAKE loss: 1.209820]  tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 118/1000] [D loss: 0.771405] [G loss: 0.361873] [FAKE loss: 1.193995]  tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 119/1000] [D loss: 0.766094] [G loss: 0.368433] [FAKE loss: 1.179707]  tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 120/1000] [D loss: 0.762210] [G loss: 0.374132] [FAKE loss: 1.167219]  tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 121/1000] [D loss: 0.757107] [G loss: 0.380055] [FAKE loss: 1.152953]  tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 122/1000] [D loss: 0.752984] [G loss: 0.386855] [FAKE loss: 1.140873]  tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 123/1000] [D loss: 0.749251] [G loss: 0.391555] [FAKE loss: 1.129262]  tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 124/1000] [D loss: 0.744619] [G loss: 0.397868] [FAKE loss: 1.116870]  tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 125/1000] [D loss: 0.741373] [G loss: 0.403171] [FAKE loss: 1.105794]  tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 126/1000] [D loss: 0.737826] [G loss: 0.408304] [FAKE loss: 1.095212]  tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 127/1000] [D loss: 0.733613] [G loss: 0.414537] [FAKE loss: 1.083584]  tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 128/1000] [D loss: 0.730485] [G loss: 0.419450] [FAKE loss: 1.073535]  tensor(0.6579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 129/1000] [D loss: 0.727964] [G loss: 0.424049] [FAKE loss: 1.064827]  tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 130/1000] [D loss: 0.725268] [G loss: 0.429686] [FAKE loss: 1.056404]  tensor(0.6513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 131/1000] [D loss: 0.721556] [G loss: 0.434046] [FAKE loss: 1.046839]  tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 132/1000] [D loss: 0.719225] [G loss: 0.438289] [FAKE loss: 1.038825]  tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 133/1000] [D loss: 0.716178] [G loss: 0.442755] [FAKE loss: 1.030136]  tensor(0.6428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 134/1000] [D loss: 0.714204] [G loss: 0.447001] [FAKE loss: 1.023485]  tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 135/1000] [D loss: 0.711651] [G loss: 0.450566] [FAKE loss: 1.015920]  tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 136/1000] [D loss: 0.710346] [G loss: 0.454707] [FAKE loss: 1.010422]  tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 137/1000] [D loss: 0.708066] [G loss: 0.458398] [FAKE loss: 1.004097]  tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 138/1000] [D loss: 0.706286] [G loss: 0.461690] [FAKE loss: 0.998621]  tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 139/1000] [D loss: 0.703945] [G loss: 0.465184] [FAKE loss: 0.992098]  tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 140/1000] [D loss: 0.702309] [G loss: 0.467798] [FAKE loss: 0.987388]  tensor(0.6263, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 141/1000] [D loss: 0.701043] [G loss: 0.471179] [FAKE loss: 0.982537]  tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 142/1000] [D loss: 0.700138] [G loss: 0.472242] [FAKE loss: 0.979717]  tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 143/1000] [D loss: 0.699018] [G loss: 0.475480] [FAKE loss: 0.975556]  tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 144/1000] [D loss: 0.697565] [G loss: 0.478392] [FAKE loss: 0.972598]  tensor(0.6208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 145/1000] [D loss: 0.696397] [G loss: 0.479327] [FAKE loss: 0.968599]  tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 146/1000] [D loss: 0.696311] [G loss: 0.480691] [FAKE loss: 0.967330]  tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 147/1000] [D loss: 0.695018] [G loss: 0.481675] [FAKE loss: 0.964646]  tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 148/1000] [D loss: 0.694526] [G loss: 0.482819] [FAKE loss: 0.963225]  tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 149/1000] [D loss: 0.694163] [G loss: 0.483696] [FAKE loss: 0.961451]  tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 150/1000] [D loss: 0.693881] [G loss: 0.483638] [FAKE loss: 0.961187]  tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 151/1000] [D loss: 0.692977] [G loss: 0.486644] [FAKE loss: 0.959825]  tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 152/1000] [D loss: 0.692502] [G loss: 0.486038] [FAKE loss: 0.958636]  tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 153/1000] [D loss: 0.692801] [G loss: 0.486813] [FAKE loss: 0.960102]  tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 154/1000] [D loss: 0.692523] [G loss: 0.486268] [FAKE loss: 0.959390]  tensor(0.6152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 155/1000] [D loss: 0.692702] [G loss: 0.484937] [FAKE loss: 0.960951]  tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 156/1000] [D loss: 0.693048] [G loss: 0.484222] [FAKE loss: 0.962888]  tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 157/1000] [D loss: 0.693039] [G loss: 0.483045] [FAKE loss: 0.962813]  tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 158/1000] [D loss: 0.693110] [G loss: 0.481682] [FAKE loss: 0.964413]  tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 159/1000] [D loss: 0.694105] [G loss: 0.480034] [FAKE loss: 0.967855]  tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 160/1000] [D loss: 0.694437] [G loss: 0.479307] [FAKE loss: 0.970712]  tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 161/1000] [D loss: 0.695166] [G loss: 0.477897] [FAKE loss: 0.973562]  tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 162/1000] [D loss: 0.696720] [G loss: 0.475243] [FAKE loss: 0.977946]  tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 163/1000] [D loss: 0.696371] [G loss: 0.473301] [FAKE loss: 0.979541]  tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 164/1000] [D loss: 0.697931] [G loss: 0.471780] [FAKE loss: 0.985261]  tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 165/1000] [D loss: 0.699896] [G loss: 0.467703] [FAKE loss: 0.990504]  tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 166/1000] [D loss: 0.699642] [G loss: 0.465972] [FAKE loss: 0.993096]  tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 167/1000] [D loss: 0.702306] [G loss: 0.462545] [FAKE loss: 1.000761]  tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 168/1000] [D loss: 0.703600] [G loss: 0.457765] [FAKE loss: 1.005660]  tensor(0.6326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 169/1000] [D loss: 0.705494] [G loss: 0.456020] [FAKE loss: 1.012295]  tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 170/1000] [D loss: 0.707363] [G loss: 0.452127] [FAKE loss: 1.019043]  tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 171/1000] [D loss: 0.708668] [G loss: 0.447634] [FAKE loss: 1.024823]  tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 172/1000] [D loss: 0.711005] [G loss: 0.444002] [FAKE loss: 1.033416]  tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 173/1000] [D loss: 0.713447] [G loss: 0.440080] [FAKE loss: 1.041418]  tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 174/1000] [D loss: 0.715038] [G loss: 0.435455] [FAKE loss: 1.048352]  tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 175/1000] [D loss: 0.718161] [G loss: 0.431623] [FAKE loss: 1.057681]  tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 176/1000] [D loss: 0.721075] [G loss: 0.426785] [FAKE loss: 1.066798]  tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 177/1000] [D loss: 0.722682] [G loss: 0.421357] [FAKE loss: 1.074444]  tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 178/1000] [D loss: 0.727257] [G loss: 0.418144] [FAKE loss: 1.087272]  tensor(0.6597, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 179/1000] [D loss: 0.727417] [G loss: 0.411577] [FAKE loss: 1.092745]  tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 180/1000] [D loss: 0.731686] [G loss: 0.406824] [FAKE loss: 1.104780]  tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 181/1000] [D loss: 0.734660] [G loss: 0.401246] [FAKE loss: 1.114411]  tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 182/1000] [D loss: 0.737715] [G loss: 0.396114] [FAKE loss: 1.125672]  tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 183/1000] [D loss: 0.742200] [G loss: 0.391070] [FAKE loss: 1.137988]  tensor(0.6771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 184/1000] [D loss: 0.744858] [G loss: 0.384780] [FAKE loss: 1.147867]  tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 185/1000] [D loss: 0.748365] [G loss: 0.380491] [FAKE loss: 1.158961]  tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 186/1000] [D loss: 0.753051] [G loss: 0.374541] [FAKE loss: 1.173020]  tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 187/1000] [D loss: 0.757416] [G loss: 0.369380] [FAKE loss: 1.185988]  tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 188/1000] [D loss: 0.761672] [G loss: 0.363716] [FAKE loss: 1.200050]  tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 189/1000] [D loss: 0.765229] [G loss: 0.357202] [FAKE loss: 1.212490]  tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 190/1000] [D loss: 0.769478] [G loss: 0.351337] [FAKE loss: 1.225289]  tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 191/1000] [D loss: 0.773649] [G loss: 0.345586] [FAKE loss: 1.238961]  tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 192/1000] [D loss: 0.779928] [G loss: 0.340444] [FAKE loss: 1.255557]  tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 193/1000] [D loss: 0.785530] [G loss: 0.333866] [FAKE loss: 1.270848]  tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 194/1000] [D loss: 0.790207] [G loss: 0.329234] [FAKE loss: 1.284397]  tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 195/1000] [D loss: 0.796322] [G loss: 0.321551] [FAKE loss: 1.302558]  tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 196/1000] [D loss: 0.801418] [G loss: 0.316531] [FAKE loss: 1.318292]  tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 197/1000] [D loss: 0.808518] [G loss: 0.310330] [FAKE loss: 1.337538]  tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 198/1000] [D loss: 0.812714] [G loss: 0.304957] [FAKE loss: 1.350675]  tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 199/1000] [D loss: 0.819374] [G loss: 0.299659] [FAKE loss: 1.369392]  tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 200/1000] [D loss: 0.826903] [G loss: 0.292447] [FAKE loss: 1.388328]  tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 201/1000] [D loss: 0.833842] [G loss: 0.286590] [FAKE loss: 1.407138]  tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 202/1000] [D loss: 0.840170] [G loss: 0.281208] [FAKE loss: 1.425303]  tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 203/1000] [D loss: 0.847510] [G loss: 0.275915] [FAKE loss: 1.443883]  tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 204/1000] [D loss: 0.855722] [G loss: 0.270048] [FAKE loss: 1.464604]  tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 205/1000] [D loss: 0.861454] [G loss: 0.264701] [FAKE loss: 1.482075]  tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 206/1000] [D loss: 0.868435] [G loss: 0.258364] [FAKE loss: 1.499460]  tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 207/1000] [D loss: 0.876111] [G loss: 0.253165] [FAKE loss: 1.519750]  tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 208/1000] [D loss: 0.884164] [G loss: 0.246728] [FAKE loss: 1.540377]  tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 209/1000] [D loss: 0.890133] [G loss: 0.241476] [FAKE loss: 1.557368]  tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 210/1000] [D loss: 0.899266] [G loss: 0.236680] [FAKE loss: 1.579577]  tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 211/1000] [D loss: 0.907910] [G loss: 0.232762] [FAKE loss: 1.600786]  tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 212/1000] [D loss: 0.913741] [G loss: 0.227620] [FAKE loss: 1.616740]  tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 213/1000] [D loss: 0.922493] [G loss: 0.222421] [FAKE loss: 1.639376]  tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 214/1000] [D loss: 0.930927] [G loss: 0.217346] [FAKE loss: 1.658424]  tensor(0.8056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8168, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 215/1000] [D loss: 0.937211] [G loss: 0.213336] [FAKE loss: 1.674993]  tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 216/1000] [D loss: 0.944874] [G loss: 0.208783] [FAKE loss: 1.694851]  tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 217/1000] [D loss: 0.955048] [G loss: 0.204312] [FAKE loss: 1.717722]  tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 218/1000] [D loss: 0.961306] [G loss: 0.200972] [FAKE loss: 1.734062]  tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 219/1000] [D loss: 0.966028] [G loss: 0.196758] [FAKE loss: 1.748139]  tensor(0.8222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 220/1000] [D loss: 0.974182] [G loss: 0.193766] [FAKE loss: 1.766343]  tensor(0.8247, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 221/1000] [D loss: 0.983284] [G loss: 0.191006] [FAKE loss: 1.787700]  tensor(0.8282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 222/1000] [D loss: 0.988702] [G loss: 0.186392] [FAKE loss: 1.801726]  tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 223/1000] [D loss: 0.993178] [G loss: 0.184244] [FAKE loss: 1.812354]  tensor(0.8331, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 224/1000] [D loss: 1.001912] [G loss: 0.181193] [FAKE loss: 1.833883]  tensor(0.8349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 225/1000] [D loss: 1.005056] [G loss: 0.179264] [FAKE loss: 1.841640]  tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 226/1000] [D loss: 1.011788] [G loss: 0.176500] [FAKE loss: 1.856827]  tensor(0.8392, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 227/1000] [D loss: 1.014381] [G loss: 0.174603] [FAKE loss: 1.864539]  tensor(0.8406, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 228/1000] [D loss: 1.018630] [G loss: 0.172643] [FAKE loss: 1.875463]  tensor(0.8423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 229/1000] [D loss: 1.021305] [G loss: 0.172287] [FAKE loss: 1.883500]  tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 230/1000] [D loss: 1.026742] [G loss: 0.170166] [FAKE loss: 1.894403]  tensor(0.8443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 231/1000] [D loss: 1.030702] [G loss: 0.169467] [FAKE loss: 1.903828]  tensor(0.8456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 232/1000] [D loss: 1.030555] [G loss: 0.167249] [FAKE loss: 1.904799]  tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 233/1000] [D loss: 1.032142] [G loss: 0.166863] [FAKE loss: 1.908477]  tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 234/1000] [D loss: 1.033714] [G loss: 0.165561] [FAKE loss: 1.912969]  tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 235/1000] [D loss: 1.034950] [G loss: 0.166603] [FAKE loss: 1.915115]  tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 236/1000] [D loss: 1.035613] [G loss: 0.166262] [FAKE loss: 1.916569]  tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 237/1000] [D loss: 1.034343] [G loss: 0.166001] [FAKE loss: 1.915014]  tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 238/1000] [D loss: 1.033108] [G loss: 0.166750] [FAKE loss: 1.913144]  tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 239/1000] [D loss: 1.032223] [G loss: 0.166702] [FAKE loss: 1.910969]  tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 240/1000] [D loss: 1.031304] [G loss: 0.168209] [FAKE loss: 1.909027]  tensor(0.8468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 241/1000] [D loss: 1.026426] [G loss: 0.168907] [FAKE loss: 1.898215]  tensor(0.8460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 242/1000] [D loss: 1.024137] [G loss: 0.170094] [FAKE loss: 1.893210]  tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 243/1000] [D loss: 1.021265] [G loss: 0.169927] [FAKE loss: 1.887507]  tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 244/1000] [D loss: 1.019838] [G loss: 0.173117] [FAKE loss: 1.882957]  tensor(0.8423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 245/1000] [D loss: 1.015578] [G loss: 0.173808] [FAKE loss: 1.873560]  tensor(0.8414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 246/1000] [D loss: 1.010456] [G loss: 0.176056] [FAKE loss: 1.862228]  tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 247/1000] [D loss: 1.005598] [G loss: 0.178960] [FAKE loss: 1.850676]  tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 248/1000] [D loss: 0.999592] [G loss: 0.180088] [FAKE loss: 1.836704]  tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 249/1000] [D loss: 0.994625] [G loss: 0.182987] [FAKE loss: 1.824206]  tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 250/1000] [D loss: 0.987527] [G loss: 0.186278] [FAKE loss: 1.808758]  tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 251/1000] [D loss: 0.981367] [G loss: 0.188721] [FAKE loss: 1.793915]  tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 252/1000] [D loss: 0.974239] [G loss: 0.191736] [FAKE loss: 1.777443]  tensor(0.8266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 253/1000] [D loss: 0.968981] [G loss: 0.194026] [FAKE loss: 1.764794]  tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 254/1000] [D loss: 0.962432] [G loss: 0.197558] [FAKE loss: 1.747743]  tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 255/1000] [D loss: 0.954953] [G loss: 0.202115] [FAKE loss: 1.730399]  tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 256/1000] [D loss: 0.947645] [G loss: 0.205524] [FAKE loss: 1.712753]  tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 257/1000] [D loss: 0.939854] [G loss: 0.209990] [FAKE loss: 1.694744]  tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 258/1000] [D loss: 0.932903] [G loss: 0.212995] [FAKE loss: 1.676103]  tensor(0.8089, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 259/1000] [D loss: 0.926954] [G loss: 0.217395] [FAKE loss: 1.661069]  tensor(0.8056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 260/1000] [D loss: 0.917720] [G loss: 0.220484] [FAKE loss: 1.639939]  tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 261/1000] [D loss: 0.910266] [G loss: 0.226383] [FAKE loss: 1.620823]  tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 262/1000] [D loss: 0.903809] [G loss: 0.230322] [FAKE loss: 1.603605]  tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 263/1000] [D loss: 0.897004] [G loss: 0.235909] [FAKE loss: 1.585993]  tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 264/1000] [D loss: 0.888402] [G loss: 0.241218] [FAKE loss: 1.564811]  tensor(0.7870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 265/1000] [D loss: 0.882783] [G loss: 0.245307] [FAKE loss: 1.549022]  tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 266/1000] [D loss: 0.874642] [G loss: 0.250632] [FAKE loss: 1.528680]  tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 267/1000] [D loss: 0.867571] [G loss: 0.255807] [FAKE loss: 1.510037]  tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 268/1000] [D loss: 0.860466] [G loss: 0.261243] [FAKE loss: 1.491309]  tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 269/1000] [D loss: 0.852400] [G loss: 0.266164] [FAKE loss: 1.471026]  tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 270/1000] [D loss: 0.844007] [G loss: 0.272703] [FAKE loss: 1.449647]  tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 271/1000] [D loss: 0.839389] [G loss: 0.277581] [FAKE loss: 1.435100]  tensor(0.7582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 272/1000] [D loss: 0.831990] [G loss: 0.284585] [FAKE loss: 1.415044]  tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 273/1000] [D loss: 0.824845] [G loss: 0.289605] [FAKE loss: 1.396426]  tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 274/1000] [D loss: 0.818840] [G loss: 0.295153] [FAKE loss: 1.379505]  tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 275/1000] [D loss: 0.813662] [G loss: 0.301373] [FAKE loss: 1.364443]  tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 276/1000] [D loss: 0.807089] [G loss: 0.306878] [FAKE loss: 1.346098]  tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 277/1000] [D loss: 0.801504] [G loss: 0.312683] [FAKE loss: 1.329730]  tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 278/1000] [D loss: 0.795199] [G loss: 0.317707] [FAKE loss: 1.313235]  tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 279/1000] [D loss: 0.791252] [G loss: 0.323308] [FAKE loss: 1.299317]  tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 280/1000] [D loss: 0.786213] [G loss: 0.328547] [FAKE loss: 1.283966]  tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 281/1000] [D loss: 0.780286] [G loss: 0.334149] [FAKE loss: 1.266746]  tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 282/1000] [D loss: 0.776300] [G loss: 0.341014] [FAKE loss: 1.254257]  tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 283/1000] [D loss: 0.772640] [G loss: 0.345596] [FAKE loss: 1.241378]  tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 284/1000] [D loss: 0.768432] [G loss: 0.351116] [FAKE loss: 1.227471]  tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 285/1000] [D loss: 0.763410] [G loss: 0.356182] [FAKE loss: 1.212594]  tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 286/1000] [D loss: 0.759758] [G loss: 0.361209] [FAKE loss: 1.200355]  tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 287/1000] [D loss: 0.754388] [G loss: 0.367014] [FAKE loss: 1.185852]  tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 288/1000] [D loss: 0.752875] [G loss: 0.372630] [FAKE loss: 1.177525]  tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 289/1000] [D loss: 0.749093] [G loss: 0.377100] [FAKE loss: 1.164417]  tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 290/1000] [D loss: 0.745949] [G loss: 0.382864] [FAKE loss: 1.152551]  tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 291/1000] [D loss: 0.742306] [G loss: 0.388165] [FAKE loss: 1.141754]  tensor(0.6795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 292/1000] [D loss: 0.739596] [G loss: 0.392480] [FAKE loss: 1.131359]  tensor(0.6763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 293/1000] [D loss: 0.736725] [G loss: 0.397407] [FAKE loss: 1.120665]  tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 294/1000] [D loss: 0.734170] [G loss: 0.402326] [FAKE loss: 1.111058]  tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 295/1000] [D loss: 0.731303] [G loss: 0.406495] [FAKE loss: 1.101155]  tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 296/1000] [D loss: 0.729008] [G loss: 0.411638] [FAKE loss: 1.091853]  tensor(0.6632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 297/1000] [D loss: 0.726705] [G loss: 0.414950] [FAKE loss: 1.082877]  tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 298/1000] [D loss: 0.725727] [G loss: 0.420114] [FAKE loss: 1.076334]  tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 299/1000] [D loss: 0.722996] [G loss: 0.424283] [FAKE loss: 1.067413]  tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 300/1000] [D loss: 0.720842] [G loss: 0.428534] [FAKE loss: 1.058716]  tensor(0.6518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 301/1000] [D loss: 0.718758] [G loss: 0.433002] [FAKE loss: 1.051121]  tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 302/1000] [D loss: 0.716847] [G loss: 0.436318] [FAKE loss: 1.042814]  tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 303/1000] [D loss: 0.716084] [G loss: 0.440048] [FAKE loss: 1.037638]  tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 304/1000] [D loss: 0.714058] [G loss: 0.443425] [FAKE loss: 1.029928]  tensor(0.6422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 305/1000] [D loss: 0.712784] [G loss: 0.447585] [FAKE loss: 1.023966]  tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 306/1000] [D loss: 0.711385] [G loss: 0.451217] [FAKE loss: 1.017517]  tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 307/1000] [D loss: 0.710425] [G loss: 0.453327] [FAKE loss: 1.012587]  tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 308/1000] [D loss: 0.708684] [G loss: 0.457037] [FAKE loss: 1.006037]  tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 309/1000] [D loss: 0.707597] [G loss: 0.459746] [FAKE loss: 1.000491]  tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 310/1000] [D loss: 0.706382] [G loss: 0.462739] [FAKE loss: 0.995632]  tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 311/1000] [D loss: 0.705999] [G loss: 0.465687] [FAKE loss: 0.991259]  tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 312/1000] [D loss: 0.705103] [G loss: 0.468626] [FAKE loss: 0.986906]  tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 313/1000] [D loss: 0.703680] [G loss: 0.470514] [FAKE loss: 0.981732]  tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 314/1000] [D loss: 0.703328] [G loss: 0.473104] [FAKE loss: 0.978285]  tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 315/1000] [D loss: 0.702836] [G loss: 0.475453] [FAKE loss: 0.974876]  tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 316/1000] [D loss: 0.701804] [G loss: 0.476980] [FAKE loss: 0.970333]  tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 317/1000] [D loss: 0.701337] [G loss: 0.479860] [FAKE loss: 0.967119]  tensor(0.6199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 318/1000] [D loss: 0.701182] [G loss: 0.480996] [FAKE loss: 0.964965]  tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 319/1000] [D loss: 0.700529] [G loss: 0.482373] [FAKE loss: 0.962085]  tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 320/1000] [D loss: 0.700771] [G loss: 0.484232] [FAKE loss: 0.960242]  tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 321/1000] [D loss: 0.700135] [G loss: 0.485321] [FAKE loss: 0.957385]  tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 322/1000] [D loss: 0.699440] [G loss: 0.487019] [FAKE loss: 0.954546]  tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 323/1000] [D loss: 0.699548] [G loss: 0.488166] [FAKE loss: 0.953813]  tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 324/1000] [D loss: 0.699034] [G loss: 0.489164] [FAKE loss: 0.951384]  tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 325/1000] [D loss: 0.698973] [G loss: 0.490055] [FAKE loss: 0.950171]  tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 326/1000] [D loss: 0.699147] [G loss: 0.490893] [FAKE loss: 0.949354]  tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 327/1000] [D loss: 0.698695] [G loss: 0.491173] [FAKE loss: 0.947805]  tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 328/1000] [D loss: 0.698479] [G loss: 0.491743] [FAKE loss: 0.946707]  tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 329/1000] [D loss: 0.698544] [G loss: 0.492268] [FAKE loss: 0.946239]  tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 330/1000] [D loss: 0.698446] [G loss: 0.492308] [FAKE loss: 0.945635]  tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 331/1000] [D loss: 0.698610] [G loss: 0.492433] [FAKE loss: 0.945808]  tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 332/1000] [D loss: 0.698569] [G loss: 0.493297] [FAKE loss: 0.945580]  tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 333/1000] [D loss: 0.698846] [G loss: 0.492127] [FAKE loss: 0.946043]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 334/1000] [D loss: 0.698589] [G loss: 0.492125] [FAKE loss: 0.945608]  tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 335/1000] [D loss: 0.698378] [G loss: 0.492075] [FAKE loss: 0.945802]  tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 336/1000] [D loss: 0.699151] [G loss: 0.491308] [FAKE loss: 0.947554]  tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 337/1000] [D loss: 0.699338] [G loss: 0.490963] [FAKE loss: 0.948330]  tensor(0.6122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 338/1000] [D loss: 0.699555] [G loss: 0.490410] [FAKE loss: 0.949330]  tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 339/1000] [D loss: 0.699368] [G loss: 0.489048] [FAKE loss: 0.950397]  tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 340/1000] [D loss: 0.700388] [G loss: 0.488254] [FAKE loss: 0.952738]  tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 341/1000] [D loss: 0.701004] [G loss: 0.486850] [FAKE loss: 0.955038]  tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 342/1000] [D loss: 0.701659] [G loss: 0.485586] [FAKE loss: 0.957137]  tensor(0.6152, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 343/1000] [D loss: 0.701650] [G loss: 0.484102] [FAKE loss: 0.958644]  tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 344/1000] [D loss: 0.701970] [G loss: 0.482284] [FAKE loss: 0.960949]  tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 345/1000] [D loss: 0.703022] [G loss: 0.480723] [FAKE loss: 0.964500]  tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 346/1000] [D loss: 0.703688] [G loss: 0.478529] [FAKE loss: 0.967540]  tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 347/1000] [D loss: 0.704507] [G loss: 0.477098] [FAKE loss: 0.971010]  tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 348/1000] [D loss: 0.705322] [G loss: 0.474494] [FAKE loss: 0.974608]  tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 349/1000] [D loss: 0.705953] [G loss: 0.472298] [FAKE loss: 0.978164]  tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 350/1000] [D loss: 0.707269] [G loss: 0.469424] [FAKE loss: 0.982771]  tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 351/1000] [D loss: 0.708190] [G loss: 0.466951] [FAKE loss: 0.986878]  tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 352/1000] [D loss: 0.709396] [G loss: 0.464352] [FAKE loss: 0.991602]  tensor(0.6286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 353/1000] [D loss: 0.710284] [G loss: 0.461666] [FAKE loss: 0.996043]  tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 354/1000] [D loss: 0.711996] [G loss: 0.458455] [FAKE loss: 1.001606]  tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 355/1000] [D loss: 0.713069] [G loss: 0.455374] [FAKE loss: 1.006703]  tensor(0.6344, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 356/1000] [D loss: 0.714256] [G loss: 0.452626] [FAKE loss: 1.012287]  tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 357/1000] [D loss: 0.715566] [G loss: 0.449047] [FAKE loss: 1.018143]  tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 358/1000] [D loss: 0.717504] [G loss: 0.445841] [FAKE loss: 1.024652]  tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 359/1000] [D loss: 0.718979] [G loss: 0.442143] [FAKE loss: 1.031130]  tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 360/1000] [D loss: 0.720094] [G loss: 0.438627] [FAKE loss: 1.036250]  tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 361/1000] [D loss: 0.722202] [G loss: 0.434801] [FAKE loss: 1.043864]  tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 362/1000] [D loss: 0.724546] [G loss: 0.430503] [FAKE loss: 1.051980]  tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 363/1000] [D loss: 0.726203] [G loss: 0.426698] [FAKE loss: 1.058900]  tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 364/1000] [D loss: 0.728549] [G loss: 0.422622] [FAKE loss: 1.067104]  tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 365/1000] [D loss: 0.730932] [G loss: 0.418704] [FAKE loss: 1.075927]  tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 366/1000] [D loss: 0.732503] [G loss: 0.413972] [FAKE loss: 1.082543]  tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 367/1000] [D loss: 0.734962] [G loss: 0.409774] [FAKE loss: 1.091732]  tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 368/1000] [D loss: 0.737425] [G loss: 0.405303] [FAKE loss: 1.100078]  tensor(0.6670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 369/1000] [D loss: 0.740726] [G loss: 0.400705] [FAKE loss: 1.111333]  tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 370/1000] [D loss: 0.742582] [G loss: 0.395931] [FAKE loss: 1.118983]  tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 371/1000] [D loss: 0.745796] [G loss: 0.391310] [FAKE loss: 1.129845]  tensor(0.6763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 372/1000] [D loss: 0.748923] [G loss: 0.386497] [FAKE loss: 1.139889]  tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 373/1000] [D loss: 0.751860] [G loss: 0.381876] [FAKE loss: 1.150773]  tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 374/1000] [D loss: 0.754955] [G loss: 0.376568] [FAKE loss: 1.161244]  tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 375/1000] [D loss: 0.758512] [G loss: 0.371289] [FAKE loss: 1.172677]  tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 376/1000] [D loss: 0.762211] [G loss: 0.366305] [FAKE loss: 1.184432]  tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 377/1000] [D loss: 0.765743] [G loss: 0.360676] [FAKE loss: 1.196265]  tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 378/1000] [D loss: 0.769933] [G loss: 0.355468] [FAKE loss: 1.209545]  tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 379/1000] [D loss: 0.775201] [G loss: 0.349928] [FAKE loss: 1.224468]  tensor(0.7052, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 380/1000] [D loss: 0.778502] [G loss: 0.344172] [FAKE loss: 1.235994]  tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 381/1000] [D loss: 0.784560] [G loss: 0.338633] [FAKE loss: 1.252717]  tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 382/1000] [D loss: 0.789093] [G loss: 0.333063] [FAKE loss: 1.266383]  tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 383/1000] [D loss: 0.793947] [G loss: 0.326966] [FAKE loss: 1.281039]  tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 384/1000] [D loss: 0.799081] [G loss: 0.321319] [FAKE loss: 1.296483]  tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 385/1000] [D loss: 0.804686] [G loss: 0.315632] [FAKE loss: 1.312095]  tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 386/1000] [D loss: 0.810996] [G loss: 0.309601] [FAKE loss: 1.328882]  tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 387/1000] [D loss: 0.815817] [G loss: 0.304327] [FAKE loss: 1.343935]  tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 388/1000] [D loss: 0.822072] [G loss: 0.298283] [FAKE loss: 1.361157]  tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 389/1000] [D loss: 0.827513] [G loss: 0.292810] [FAKE loss: 1.376996]  tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 390/1000] [D loss: 0.833026] [G loss: 0.287392] [FAKE loss: 1.392823]  tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 391/1000] [D loss: 0.839935] [G loss: 0.281806] [FAKE loss: 1.411384]  tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 392/1000] [D loss: 0.846515] [G loss: 0.276496] [FAKE loss: 1.429138]  tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 393/1000] [D loss: 0.851929] [G loss: 0.270858] [FAKE loss: 1.444685]  tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 394/1000] [D loss: 0.858629] [G loss: 0.265276] [FAKE loss: 1.462766]  tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 395/1000] [D loss: 0.865760] [G loss: 0.259875] [FAKE loss: 1.482592]  tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 396/1000] [D loss: 0.873365] [G loss: 0.254740] [FAKE loss: 1.501493]  tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 397/1000] [D loss: 0.880547] [G loss: 0.249871] [FAKE loss: 1.520630]  tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 398/1000] [D loss: 0.886263] [G loss: 0.243967] [FAKE loss: 1.536493]  tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 399/1000] [D loss: 0.895079] [G loss: 0.239112] [FAKE loss: 1.558405]  tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 400/1000] [D loss: 0.902686] [G loss: 0.234826] [FAKE loss: 1.578497]  tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 401/1000] [D loss: 0.909441] [G loss: 0.229318] [FAKE loss: 1.595997]  tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 402/1000] [D loss: 0.917595] [G loss: 0.224580] [FAKE loss: 1.616409]  tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 403/1000] [D loss: 0.924072] [G loss: 0.219715] [FAKE loss: 1.633483]  tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 404/1000] [D loss: 0.933058] [G loss: 0.214870] [FAKE loss: 1.655145]  tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 405/1000] [D loss: 0.940885] [G loss: 0.211195] [FAKE loss: 1.674868]  tensor(0.8103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 406/1000] [D loss: 0.949263] [G loss: 0.205760] [FAKE loss: 1.695383]  tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 407/1000] [D loss: 0.956985] [G loss: 0.201802] [FAKE loss: 1.714642]  tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 408/1000] [D loss: 0.965183] [G loss: 0.197063] [FAKE loss: 1.734711]  tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 409/1000] [D loss: 0.971112] [G loss: 0.193192] [FAKE loss: 1.750394]  tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 410/1000] [D loss: 0.980643] [G loss: 0.189883] [FAKE loss: 1.771958]  tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 411/1000] [D loss: 0.988247] [G loss: 0.185971] [FAKE loss: 1.791315]  tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 412/1000] [D loss: 0.996522] [G loss: 0.182029] [FAKE loss: 1.810671]  tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 413/1000] [D loss: 1.003525] [G loss: 0.179099] [FAKE loss: 1.827888]  tensor(0.8367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 414/1000] [D loss: 1.009262] [G loss: 0.175372] [FAKE loss: 1.842036]  tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 415/1000] [D loss: 1.017960] [G loss: 0.172607] [FAKE loss: 1.862082]  tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 416/1000] [D loss: 1.025395] [G loss: 0.169558] [FAKE loss: 1.879362]  tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 417/1000] [D loss: 1.030953] [G loss: 0.166702] [FAKE loss: 1.893057]  tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 418/1000] [D loss: 1.036803] [G loss: 0.163876] [FAKE loss: 1.907625]  tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 419/1000] [D loss: 1.044429] [G loss: 0.162131] [FAKE loss: 1.924510]  tensor(0.8508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 420/1000] [D loss: 1.049054] [G loss: 0.159441] [FAKE loss: 1.936291]  tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 421/1000] [D loss: 1.054282] [G loss: 0.156462] [FAKE loss: 1.949117]  tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 422/1000] [D loss: 1.060199] [G loss: 0.155656] [FAKE loss: 1.961831]  tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 423/1000] [D loss: 1.065207] [G loss: 0.153202] [FAKE loss: 1.974165]  tensor(0.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 424/1000] [D loss: 1.070245] [G loss: 0.152011] [FAKE loss: 1.985586]  tensor(0.8600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 425/1000] [D loss: 1.073686] [G loss: 0.150799] [FAKE loss: 1.993994]  tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 426/1000] [D loss: 1.076517] [G loss: 0.149118] [FAKE loss: 2.000279]  tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 427/1000] [D loss: 1.080628] [G loss: 0.147800] [FAKE loss: 2.009686]  tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 428/1000] [D loss: 1.083846] [G loss: 0.146916] [FAKE loss: 2.017214]  tensor(0.8637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 429/1000] [D loss: 1.085253] [G loss: 0.146323] [FAKE loss: 2.020865]  tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 430/1000] [D loss: 1.087519] [G loss: 0.145872] [FAKE loss: 2.025726]  tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 431/1000] [D loss: 1.088796] [G loss: 0.145389] [FAKE loss: 2.028807]  tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 432/1000] [D loss: 1.087916] [G loss: 0.144714] [FAKE loss: 2.027418]  tensor(0.8659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 433/1000] [D loss: 1.089346] [G loss: 0.144396] [FAKE loss: 2.029804]  tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 434/1000] [D loss: 1.087553] [G loss: 0.144861] [FAKE loss: 2.026139]  tensor(0.8659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 435/1000] [D loss: 1.085668] [G loss: 0.146358] [FAKE loss: 2.022208]  tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 436/1000] [D loss: 1.085489] [G loss: 0.146347] [FAKE loss: 2.021694]  tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 437/1000] [D loss: 1.083364] [G loss: 0.146631] [FAKE loss: 2.016221]  tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 438/1000] [D loss: 1.080727] [G loss: 0.147355] [FAKE loss: 2.010495]  tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 439/1000] [D loss: 1.077104] [G loss: 0.148629] [FAKE loss: 2.002234]  tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 440/1000] [D loss: 1.072702] [G loss: 0.150088] [FAKE loss: 1.992651]  tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 441/1000] [D loss: 1.068607] [G loss: 0.151635] [FAKE loss: 1.982441]  tensor(0.8601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 442/1000] [D loss: 1.063863] [G loss: 0.154113] [FAKE loss: 1.971577]  tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 443/1000] [D loss: 1.058871] [G loss: 0.155494] [FAKE loss: 1.959388]  tensor(0.8564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 444/1000] [D loss: 1.054149] [G loss: 0.157463] [FAKE loss: 1.948753]  tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 445/1000] [D loss: 1.048273] [G loss: 0.160030] [FAKE loss: 1.935010]  tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 446/1000] [D loss: 1.041503] [G loss: 0.162553] [FAKE loss: 1.918964]  tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 447/1000] [D loss: 1.033906] [G loss: 0.166027] [FAKE loss: 1.901793]  tensor(0.8481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 448/1000] [D loss: 1.027634] [G loss: 0.168641] [FAKE loss: 1.886383]  tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 449/1000] [D loss: 1.021132] [G loss: 0.171099] [FAKE loss: 1.871078]  tensor(0.8431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 450/1000] [D loss: 1.011564] [G loss: 0.175098] [FAKE loss: 1.848840]  tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 451/1000] [D loss: 1.004145] [G loss: 0.178634] [FAKE loss: 1.830872]  tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 452/1000] [D loss: 0.996278] [G loss: 0.182111] [FAKE loss: 1.812159]  tensor(0.8339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 453/1000] [D loss: 0.986653] [G loss: 0.186548] [FAKE loss: 1.789369]  tensor(0.8307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 454/1000] [D loss: 0.978863] [G loss: 0.190987] [FAKE loss: 1.770212]  tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 455/1000] [D loss: 0.969617] [G loss: 0.194185] [FAKE loss: 1.748432]  tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 456/1000] [D loss: 0.962018] [G loss: 0.198330] [FAKE loss: 1.729203]  tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 457/1000] [D loss: 0.953399] [G loss: 0.204086] [FAKE loss: 1.707541]  tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 458/1000] [D loss: 0.945579] [G loss: 0.207781] [FAKE loss: 1.687646]  tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 459/1000] [D loss: 0.935160] [G loss: 0.212673] [FAKE loss: 1.662690]  tensor(0.8086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 460/1000] [D loss: 0.926503] [G loss: 0.217966] [FAKE loss: 1.640940]  tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 461/1000] [D loss: 0.917263] [G loss: 0.223317] [FAKE loss: 1.617890]  tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 462/1000] [D loss: 0.910162] [G loss: 0.228995] [FAKE loss: 1.598274]  tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 463/1000] [D loss: 0.901393] [G loss: 0.234705] [FAKE loss: 1.575975]  tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 464/1000] [D loss: 0.893069] [G loss: 0.240301] [FAKE loss: 1.554397]  tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 465/1000] [D loss: 0.884643] [G loss: 0.246051] [FAKE loss: 1.532805]  tensor(0.7825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 466/1000] [D loss: 0.877092] [G loss: 0.251777] [FAKE loss: 1.512092]  tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 467/1000] [D loss: 0.868955] [G loss: 0.257896] [FAKE loss: 1.490656]  tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 468/1000] [D loss: 0.860932] [G loss: 0.263856] [FAKE loss: 1.469190]  tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 469/1000] [D loss: 0.854097] [G loss: 0.270214] [FAKE loss: 1.449573]  tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 470/1000] [D loss: 0.845951] [G loss: 0.277243] [FAKE loss: 1.427903]  tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 471/1000] [D loss: 0.838581] [G loss: 0.283305] [FAKE loss: 1.406352]  tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 472/1000] [D loss: 0.832105] [G loss: 0.290234] [FAKE loss: 1.388094]  tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 473/1000] [D loss: 0.825118] [G loss: 0.297087] [FAKE loss: 1.367701]  tensor(0.7439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 474/1000] [D loss: 0.817999] [G loss: 0.303817] [FAKE loss: 1.347098]  tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 475/1000] [D loss: 0.811930] [G loss: 0.309779] [FAKE loss: 1.329327]  tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 476/1000] [D loss: 0.804311] [G loss: 0.316944] [FAKE loss: 1.307492]  tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 477/1000] [D loss: 0.798888] [G loss: 0.323373] [FAKE loss: 1.290184]  tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 478/1000] [D loss: 0.792525] [G loss: 0.330706] [FAKE loss: 1.271174]  tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 479/1000] [D loss: 0.786910] [G loss: 0.338180] [FAKE loss: 1.254161]  tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 480/1000] [D loss: 0.781307] [G loss: 0.345181] [FAKE loss: 1.236512]  tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 481/1000] [D loss: 0.776621] [G loss: 0.351909] [FAKE loss: 1.220030]  tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 482/1000] [D loss: 0.771317] [G loss: 0.359462] [FAKE loss: 1.202642]  tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 483/1000] [D loss: 0.766028] [G loss: 0.366448] [FAKE loss: 1.185528]  tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 484/1000] [D loss: 0.760860] [G loss: 0.373717] [FAKE loss: 1.169329]  tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 485/1000] [D loss: 0.755502] [G loss: 0.380197] [FAKE loss: 1.152482]  tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 486/1000] [D loss: 0.752311] [G loss: 0.387600] [FAKE loss: 1.139025]  tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 487/1000] [D loss: 0.748394] [G loss: 0.394375] [FAKE loss: 1.124643]  tensor(0.6744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 488/1000] [D loss: 0.743738] [G loss: 0.401630] [FAKE loss: 1.109178]  tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 489/1000] [D loss: 0.740673] [G loss: 0.408542] [FAKE loss: 1.096600]  tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 490/1000] [D loss: 0.737164] [G loss: 0.415075] [FAKE loss: 1.083228]  tensor(0.6605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 491/1000] [D loss: 0.732576] [G loss: 0.422152] [FAKE loss: 1.067620]  tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 492/1000] [D loss: 0.729967] [G loss: 0.428369] [FAKE loss: 1.056047]  tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 493/1000] [D loss: 0.727249] [G loss: 0.435653] [FAKE loss: 1.044637]  tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 494/1000] [D loss: 0.724363] [G loss: 0.441551] [FAKE loss: 1.032497]  tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 495/1000] [D loss: 0.721257] [G loss: 0.447278] [FAKE loss: 1.020115]  tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 496/1000] [D loss: 0.719560] [G loss: 0.453777] [FAKE loss: 1.010794]  tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 497/1000] [D loss: 0.717341] [G loss: 0.460076] [FAKE loss: 1.000489]  tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 498/1000] [D loss: 0.715090] [G loss: 0.465031] [FAKE loss: 0.990891]  tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 499/1000] [D loss: 0.713593] [G loss: 0.470667] [FAKE loss: 0.981753]  tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 500/1000] [D loss: 0.711593] [G loss: 0.476114] [FAKE loss: 0.972400]  tensor(0.6215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 501/1000] [D loss: 0.709577] [G loss: 0.481602] [FAKE loss: 0.963291]  tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 502/1000] [D loss: 0.708565] [G loss: 0.486700] [FAKE loss: 0.955791]  tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 503/1000] [D loss: 0.707374] [G loss: 0.491583] [FAKE loss: 0.947996]  tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 504/1000] [D loss: 0.705580] [G loss: 0.495737] [FAKE loss: 0.939771]  tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 505/1000] [D loss: 0.704284] [G loss: 0.500217] [FAKE loss: 0.932891]  tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 506/1000] [D loss: 0.703850] [G loss: 0.505052] [FAKE loss: 0.927054]  tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 507/1000] [D loss: 0.702425] [G loss: 0.509581] [FAKE loss: 0.919532]  tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 508/1000] [D loss: 0.701639] [G loss: 0.513384] [FAKE loss: 0.914032]  tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 509/1000] [D loss: 0.700450] [G loss: 0.516951] [FAKE loss: 0.907572]  tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 510/1000] [D loss: 0.700107] [G loss: 0.520292] [FAKE loss: 0.902818]  tensor(0.5944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 511/1000] [D loss: 0.699796] [G loss: 0.524253] [FAKE loss: 0.899029]  tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 512/1000] [D loss: 0.698663] [G loss: 0.526946] [FAKE loss: 0.893109]  tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 513/1000] [D loss: 0.698626] [G loss: 0.529856] [FAKE loss: 0.889861]  tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 514/1000] [D loss: 0.698276] [G loss: 0.532069] [FAKE loss: 0.886047]  tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 515/1000] [D loss: 0.698006] [G loss: 0.534193] [FAKE loss: 0.882803]  tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 516/1000] [D loss: 0.698161] [G loss: 0.535737] [FAKE loss: 0.880258]  tensor(0.5850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 517/1000] [D loss: 0.698018] [G loss: 0.538277] [FAKE loss: 0.877714]  tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 518/1000] [D loss: 0.697786] [G loss: 0.539511] [FAKE loss: 0.875371]  tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 519/1000] [D loss: 0.698048] [G loss: 0.540696] [FAKE loss: 0.874306]  tensor(0.5826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 520/1000] [D loss: 0.698163] [G loss: 0.541714] [FAKE loss: 0.872500]  tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 521/1000] [D loss: 0.698221] [G loss: 0.542247] [FAKE loss: 0.871780]  tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 522/1000] [D loss: 0.698513] [G loss: 0.543081] [FAKE loss: 0.870953]  tensor(0.5812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 523/1000] [D loss: 0.699033] [G loss: 0.543002] [FAKE loss: 0.870597]  tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 524/1000] [D loss: 0.699127] [G loss: 0.542905] [FAKE loss: 0.870522]  tensor(0.5811, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 525/1000] [D loss: 0.699192] [G loss: 0.542975] [FAKE loss: 0.870599]  tensor(0.5812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 526/1000] [D loss: 0.699750] [G loss: 0.542764] [FAKE loss: 0.871365]  tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 527/1000] [D loss: 0.700280] [G loss: 0.541800] [FAKE loss: 0.872373]  tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 528/1000] [D loss: 0.700746] [G loss: 0.540915] [FAKE loss: 0.873323]  tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 529/1000] [D loss: 0.701391] [G loss: 0.539582] [FAKE loss: 0.875234]  tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 530/1000] [D loss: 0.701740] [G loss: 0.538130] [FAKE loss: 0.876942]  tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 531/1000] [D loss: 0.702326] [G loss: 0.536832] [FAKE loss: 0.878891]  tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 532/1000] [D loss: 0.703149] [G loss: 0.535142] [FAKE loss: 0.881583]  tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 533/1000] [D loss: 0.703812] [G loss: 0.532768] [FAKE loss: 0.884529]  tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 534/1000] [D loss: 0.704623] [G loss: 0.531023] [FAKE loss: 0.887515]  tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 535/1000] [D loss: 0.705709] [G loss: 0.528501] [FAKE loss: 0.891004]  tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 536/1000] [D loss: 0.706585] [G loss: 0.525918] [FAKE loss: 0.895182]  tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 537/1000] [D loss: 0.707546] [G loss: 0.523069] [FAKE loss: 0.899194]  tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 538/1000] [D loss: 0.708331] [G loss: 0.520007] [FAKE loss: 0.903020]  tensor(0.5945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 539/1000] [D loss: 0.709487] [G loss: 0.516973] [FAKE loss: 0.907797]  tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 540/1000] [D loss: 0.710678] [G loss: 0.514173] [FAKE loss: 0.912821]  tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 541/1000] [D loss: 0.711553] [G loss: 0.510412] [FAKE loss: 0.917318]  tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 542/1000] [D loss: 0.712851] [G loss: 0.507076] [FAKE loss: 0.922713]  tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 543/1000] [D loss: 0.714163] [G loss: 0.503153] [FAKE loss: 0.928643]  tensor(0.6047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 544/1000] [D loss: 0.715741] [G loss: 0.499313] [FAKE loss: 0.934870]  tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 545/1000] [D loss: 0.716652] [G loss: 0.495684] [FAKE loss: 0.940021]  tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 546/1000] [D loss: 0.718668] [G loss: 0.491249] [FAKE loss: 0.947361]  tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 547/1000] [D loss: 0.720032] [G loss: 0.487135] [FAKE loss: 0.953617]  tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 548/1000] [D loss: 0.721575] [G loss: 0.482754] [FAKE loss: 0.960351]  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 549/1000] [D loss: 0.723029] [G loss: 0.478824] [FAKE loss: 0.967017]  tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 550/1000] [D loss: 0.724441] [G loss: 0.474436] [FAKE loss: 0.973974]  tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 551/1000] [D loss: 0.725971] [G loss: 0.470378] [FAKE loss: 0.980627]  tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 552/1000] [D loss: 0.727541] [G loss: 0.466317] [FAKE loss: 0.987672]  tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 553/1000] [D loss: 0.729175] [G loss: 0.461765] [FAKE loss: 0.995029]  tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 554/1000] [D loss: 0.731209] [G loss: 0.457431] [FAKE loss: 1.002941]  tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 555/1000] [D loss: 0.733018] [G loss: 0.452775] [FAKE loss: 1.010764]  tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 556/1000] [D loss: 0.734617] [G loss: 0.448484] [FAKE loss: 1.018691]  tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 557/1000] [D loss: 0.736732] [G loss: 0.443894] [FAKE loss: 1.026681]  tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 558/1000] [D loss: 0.738546] [G loss: 0.439235] [FAKE loss: 1.034461]  tensor(0.6444, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 559/1000] [D loss: 0.740457] [G loss: 0.434860] [FAKE loss: 1.042669]  tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 560/1000] [D loss: 0.742562] [G loss: 0.430357] [FAKE loss: 1.051403]  tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 561/1000] [D loss: 0.744842] [G loss: 0.425531] [FAKE loss: 1.060001]  tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 562/1000] [D loss: 0.747082] [G loss: 0.420864] [FAKE loss: 1.068755]  tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 563/1000] [D loss: 0.749288] [G loss: 0.416530] [FAKE loss: 1.077812]  tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 564/1000] [D loss: 0.751754] [G loss: 0.411790] [FAKE loss: 1.086828]  tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 565/1000] [D loss: 0.754184] [G loss: 0.407312] [FAKE loss: 1.095715]  tensor(0.6655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 566/1000] [D loss: 0.756580] [G loss: 0.402516] [FAKE loss: 1.104867]  tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 567/1000] [D loss: 0.759194] [G loss: 0.398114] [FAKE loss: 1.114595]  tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 568/1000] [D loss: 0.761496] [G loss: 0.393486] [FAKE loss: 1.123630]  tensor(0.6749, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 569/1000] [D loss: 0.764433] [G loss: 0.388870] [FAKE loss: 1.133550]  tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 570/1000] [D loss: 0.767139] [G loss: 0.384473] [FAKE loss: 1.142983]  tensor(0.6809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 571/1000] [D loss: 0.770047] [G loss: 0.380194] [FAKE loss: 1.152906]  tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 572/1000] [D loss: 0.772748] [G loss: 0.375375] [FAKE loss: 1.162702]  tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 573/1000] [D loss: 0.775393] [G loss: 0.371244] [FAKE loss: 1.172481]  tensor(0.6902, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 574/1000] [D loss: 0.778710] [G loss: 0.365887] [FAKE loss: 1.183078]  tensor(0.6932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 575/1000] [D loss: 0.781311] [G loss: 0.361869] [FAKE loss: 1.192558]  tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 576/1000] [D loss: 0.784617] [G loss: 0.357999] [FAKE loss: 1.203163]  tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 577/1000] [D loss: 0.787401] [G loss: 0.353575] [FAKE loss: 1.212755]  tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 578/1000] [D loss: 0.790129] [G loss: 0.349802] [FAKE loss: 1.222164]  tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 579/1000] [D loss: 0.793279] [G loss: 0.345312] [FAKE loss: 1.232198]  tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 580/1000] [D loss: 0.796657] [G loss: 0.341247] [FAKE loss: 1.242951]  tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 581/1000] [D loss: 0.800070] [G loss: 0.337236] [FAKE loss: 1.253512]  tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 582/1000] [D loss: 0.803311] [G loss: 0.333257] [FAKE loss: 1.263836]  tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 583/1000] [D loss: 0.805645] [G loss: 0.328759] [FAKE loss: 1.272152]  tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 584/1000] [D loss: 0.809621] [G loss: 0.325290] [FAKE loss: 1.283853]  tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 585/1000] [D loss: 0.813557] [G loss: 0.321708] [FAKE loss: 1.295138]  tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 586/1000] [D loss: 0.816340] [G loss: 0.317203] [FAKE loss: 1.304425]  tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 587/1000] [D loss: 0.820105] [G loss: 0.313514] [FAKE loss: 1.315396]  tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 588/1000] [D loss: 0.823419] [G loss: 0.309536] [FAKE loss: 1.325798]  tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 589/1000] [D loss: 0.826301] [G loss: 0.306158] [FAKE loss: 1.334983]  tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 590/1000] [D loss: 0.830341] [G loss: 0.302162] [FAKE loss: 1.346320]  tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 591/1000] [D loss: 0.834072] [G loss: 0.298797] [FAKE loss: 1.357195]  tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 592/1000] [D loss: 0.837596] [G loss: 0.294840] [FAKE loss: 1.367744]  tensor(0.7443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 593/1000] [D loss: 0.841342] [G loss: 0.291762] [FAKE loss: 1.378161]  tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 594/1000] [D loss: 0.844637] [G loss: 0.287815] [FAKE loss: 1.388342]  tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 595/1000] [D loss: 0.848149] [G loss: 0.284747] [FAKE loss: 1.398265]  tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 596/1000] [D loss: 0.850901] [G loss: 0.281389] [FAKE loss: 1.407367]  tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 597/1000] [D loss: 0.855618] [G loss: 0.277895] [FAKE loss: 1.419639]  tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 598/1000] [D loss: 0.859045] [G loss: 0.275067] [FAKE loss: 1.429916]  tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 599/1000] [D loss: 0.862895] [G loss: 0.271110] [FAKE loss: 1.440101]  tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 600/1000] [D loss: 0.866929] [G loss: 0.268057] [FAKE loss: 1.451263]  tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 601/1000] [D loss: 0.869456] [G loss: 0.265333] [FAKE loss: 1.459334]  tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 602/1000] [D loss: 0.873263] [G loss: 0.262393] [FAKE loss: 1.469784]  tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 603/1000] [D loss: 0.877681] [G loss: 0.259263] [FAKE loss: 1.481446]  tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 604/1000] [D loss: 0.881478] [G loss: 0.256165] [FAKE loss: 1.491440]  tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 605/1000] [D loss: 0.885101] [G loss: 0.253468] [FAKE loss: 1.501714]  tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 606/1000] [D loss: 0.888735] [G loss: 0.250297] [FAKE loss: 1.511538]  tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 607/1000] [D loss: 0.891718] [G loss: 0.247811] [FAKE loss: 1.520346]  tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 608/1000] [D loss: 0.896205] [G loss: 0.245144] [FAKE loss: 1.531576]  tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 609/1000] [D loss: 0.899133] [G loss: 0.242670] [FAKE loss: 1.539991]  tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 610/1000] [D loss: 0.903787] [G loss: 0.239934] [FAKE loss: 1.551749]  tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 611/1000] [D loss: 0.907383] [G loss: 0.237113] [FAKE loss: 1.561110]  tensor(0.7888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 612/1000] [D loss: 0.910750] [G loss: 0.234503] [FAKE loss: 1.570085]  tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 613/1000] [D loss: 0.913883] [G loss: 0.232576] [FAKE loss: 1.578933]  tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 614/1000] [D loss: 0.917755] [G loss: 0.229703] [FAKE loss: 1.589059]  tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 615/1000] [D loss: 0.921261] [G loss: 0.227694] [FAKE loss: 1.597905]  tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 616/1000] [D loss: 0.925228] [G loss: 0.225617] [FAKE loss: 1.608023]  tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 617/1000] [D loss: 0.927811] [G loss: 0.223014] [FAKE loss: 1.615453]  tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 618/1000] [D loss: 0.931576] [G loss: 0.220515] [FAKE loss: 1.625066]  tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 619/1000] [D loss: 0.935665] [G loss: 0.218332] [FAKE loss: 1.634698]  tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 620/1000] [D loss: 0.937238] [G loss: 0.217014] [FAKE loss: 1.639910]  tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 621/1000] [D loss: 0.941744] [G loss: 0.214989] [FAKE loss: 1.651479]  tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 622/1000] [D loss: 0.943474] [G loss: 0.213133] [FAKE loss: 1.656556]  tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 623/1000] [D loss: 0.947300] [G loss: 0.211418] [FAKE loss: 1.665355]  tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 624/1000] [D loss: 0.949974] [G loss: 0.209807] [FAKE loss: 1.672958]  tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 625/1000] [D loss: 0.951703] [G loss: 0.208724] [FAKE loss: 1.677702]  tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 626/1000] [D loss: 0.954252] [G loss: 0.206781] [FAKE loss: 1.684298]  tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 627/1000] [D loss: 0.956768] [G loss: 0.205749] [FAKE loss: 1.690692]  tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 628/1000] [D loss: 0.959847] [G loss: 0.203858] [FAKE loss: 1.697981]  tensor(0.8158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 629/1000] [D loss: 0.961944] [G loss: 0.202678] [FAKE loss: 1.703739]  tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 630/1000] [D loss: 0.963158] [G loss: 0.202191] [FAKE loss: 1.707548]  tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 631/1000] [D loss: 0.964445] [G loss: 0.200834] [FAKE loss: 1.711120]  tensor(0.8184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 632/1000] [D loss: 0.967747] [G loss: 0.199500] [FAKE loss: 1.718764]  tensor(0.8190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 633/1000] [D loss: 0.967511] [G loss: 0.199266] [FAKE loss: 1.719849]  tensor(0.8195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 634/1000] [D loss: 0.970436] [G loss: 0.197886] [FAKE loss: 1.726061]  tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 635/1000] [D loss: 0.971279] [G loss: 0.197610] [FAKE loss: 1.728859]  tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 636/1000] [D loss: 0.971783] [G loss: 0.196793] [FAKE loss: 1.730158]  tensor(0.8217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 637/1000] [D loss: 0.972361] [G loss: 0.195909] [FAKE loss: 1.732394]  tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 638/1000] [D loss: 0.973742] [G loss: 0.195849] [FAKE loss: 1.735921]  tensor(0.8222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 639/1000] [D loss: 0.973244] [G loss: 0.195658] [FAKE loss: 1.735856]  tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 640/1000] [D loss: 0.973786] [G loss: 0.195503] [FAKE loss: 1.737521]  tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 641/1000] [D loss: 0.974183] [G loss: 0.195180] [FAKE loss: 1.738320]  tensor(0.8227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 642/1000] [D loss: 0.974746] [G loss: 0.195018] [FAKE loss: 1.739662]  tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 643/1000] [D loss: 0.973787] [G loss: 0.195237] [FAKE loss: 1.738246]  tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 644/1000] [D loss: 0.973714] [G loss: 0.195346] [FAKE loss: 1.738099]  tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 645/1000] [D loss: 0.972285] [G loss: 0.195654] [FAKE loss: 1.735808]  tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 646/1000] [D loss: 0.972505] [G loss: 0.195744] [FAKE loss: 1.735873]  tensor(0.8227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 647/1000] [D loss: 0.971434] [G loss: 0.195852] [FAKE loss: 1.734001]  tensor(0.8222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 648/1000] [D loss: 0.969798] [G loss: 0.196958] [FAKE loss: 1.730577]  tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 649/1000] [D loss: 0.968486] [G loss: 0.197437] [FAKE loss: 1.727135]  tensor(0.8213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 650/1000] [D loss: 0.966729] [G loss: 0.198153] [FAKE loss: 1.723760]  tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 651/1000] [D loss: 0.963931] [G loss: 0.199346] [FAKE loss: 1.717929]  tensor(0.8196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 652/1000] [D loss: 0.963422] [G loss: 0.199798] [FAKE loss: 1.716386]  tensor(0.8189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 653/1000] [D loss: 0.959783] [G loss: 0.201090] [FAKE loss: 1.708635]  tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 654/1000] [D loss: 0.959454] [G loss: 0.202210] [FAKE loss: 1.706932]  tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 655/1000] [D loss: 0.955452] [G loss: 0.203643] [FAKE loss: 1.698354]  tensor(0.8160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 656/1000] [D loss: 0.952289] [G loss: 0.204981] [FAKE loss: 1.691289]  tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 657/1000] [D loss: 0.950191] [G loss: 0.206132] [FAKE loss: 1.685892]  tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 658/1000] [D loss: 0.947274] [G loss: 0.208228] [FAKE loss: 1.679256]  tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 659/1000] [D loss: 0.944650] [G loss: 0.209885] [FAKE loss: 1.672715]  tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 660/1000] [D loss: 0.939490] [G loss: 0.211994] [FAKE loss: 1.661156]  tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 661/1000] [D loss: 0.936870] [G loss: 0.213872] [FAKE loss: 1.654616]  tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 662/1000] [D loss: 0.932509] [G loss: 0.215771] [FAKE loss: 1.644254]  tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 663/1000] [D loss: 0.927858] [G loss: 0.217980] [FAKE loss: 1.633351]  tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 664/1000] [D loss: 0.924654] [G loss: 0.220991] [FAKE loss: 1.625521]  tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 665/1000] [D loss: 0.920333] [G loss: 0.222918] [FAKE loss: 1.615045]  tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 666/1000] [D loss: 0.915825] [G loss: 0.225811] [FAKE loss: 1.604133]  tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 667/1000] [D loss: 0.910981] [G loss: 0.228837] [FAKE loss: 1.592660]  tensor(0.7959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 668/1000] [D loss: 0.906233] [G loss: 0.231602] [FAKE loss: 1.581201]  tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 669/1000] [D loss: 0.901509] [G loss: 0.234845] [FAKE loss: 1.569210]  tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 670/1000] [D loss: 0.897025] [G loss: 0.237475] [FAKE loss: 1.558119]  tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 671/1000] [D loss: 0.892556] [G loss: 0.241073] [FAKE loss: 1.546766]  tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 672/1000] [D loss: 0.886281] [G loss: 0.244618] [FAKE loss: 1.531751]  tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 673/1000] [D loss: 0.881721] [G loss: 0.248134] [FAKE loss: 1.519572]  tensor(0.7805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 674/1000] [D loss: 0.876495] [G loss: 0.251533] [FAKE loss: 1.506935]  tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 675/1000] [D loss: 0.869947] [G loss: 0.255374] [FAKE loss: 1.491455]  tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 676/1000] [D loss: 0.866170] [G loss: 0.259588] [FAKE loss: 1.480517]  tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 677/1000] [D loss: 0.860559] [G loss: 0.263828] [FAKE loss: 1.465939]  tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 678/1000] [D loss: 0.854533] [G loss: 0.268203] [FAKE loss: 1.451186]  tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 679/1000] [D loss: 0.849191] [G loss: 0.272357] [FAKE loss: 1.436993]  tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 680/1000] [D loss: 0.842683] [G loss: 0.277440] [FAKE loss: 1.420788]  tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 681/1000] [D loss: 0.837616] [G loss: 0.281701] [FAKE loss: 1.406969]  tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 682/1000] [D loss: 0.832769] [G loss: 0.287192] [FAKE loss: 1.393593]  tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 683/1000] [D loss: 0.825835] [G loss: 0.292130] [FAKE loss: 1.376629]  tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 684/1000] [D loss: 0.819945] [G loss: 0.297066] [FAKE loss: 1.361280]  tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 685/1000] [D loss: 0.815208] [G loss: 0.302730] [FAKE loss: 1.347061]  tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 686/1000] [D loss: 0.809114] [G loss: 0.308617] [FAKE loss: 1.331136]  tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 687/1000] [D loss: 0.803471] [G loss: 0.313631] [FAKE loss: 1.315883]  tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 688/1000] [D loss: 0.798184] [G loss: 0.319236] [FAKE loss: 1.301074]  tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 689/1000] [D loss: 0.792758] [G loss: 0.325413] [FAKE loss: 1.285558]  tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 690/1000] [D loss: 0.787548] [G loss: 0.331482] [FAKE loss: 1.271327]  tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 691/1000] [D loss: 0.782227] [G loss: 0.337029] [FAKE loss: 1.256163]  tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 692/1000] [D loss: 0.777469] [G loss: 0.343670] [FAKE loss: 1.241629]  tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 693/1000] [D loss: 0.771988] [G loss: 0.349641] [FAKE loss: 1.225949]  tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 694/1000] [D loss: 0.766843] [G loss: 0.356583] [FAKE loss: 1.210936]  tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 695/1000] [D loss: 0.761932] [G loss: 0.362062] [FAKE loss: 1.196061]  tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 696/1000] [D loss: 0.757179] [G loss: 0.368024] [FAKE loss: 1.181978]  tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 697/1000] [D loss: 0.752636] [G loss: 0.375287] [FAKE loss: 1.168291]  tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 698/1000] [D loss: 0.747921] [G loss: 0.381607] [FAKE loss: 1.153648]  tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 699/1000] [D loss: 0.744507] [G loss: 0.388292] [FAKE loss: 1.141110]  tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 700/1000] [D loss: 0.740800] [G loss: 0.394498] [FAKE loss: 1.129048]  tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 701/1000] [D loss: 0.735761] [G loss: 0.401206] [FAKE loss: 1.113427]  tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 702/1000] [D loss: 0.732524] [G loss: 0.407142] [FAKE loss: 1.102515]  tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 703/1000] [D loss: 0.730237] [G loss: 0.413838] [FAKE loss: 1.092530]  tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 704/1000] [D loss: 0.727012] [G loss: 0.419039] [FAKE loss: 1.081023]  tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 705/1000] [D loss: 0.723023] [G loss: 0.424292] [FAKE loss: 1.067555]  tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 706/1000] [D loss: 0.720640] [G loss: 0.430518] [FAKE loss: 1.057665]  tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 707/1000] [D loss: 0.718513] [G loss: 0.435678] [FAKE loss: 1.048296]  tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 708/1000] [D loss: 0.716033] [G loss: 0.441279] [FAKE loss: 1.038145]  tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 709/1000] [D loss: 0.713950] [G loss: 0.446998] [FAKE loss: 1.029178]  tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 710/1000] [D loss: 0.713419] [G loss: 0.451536] [FAKE loss: 1.022780]  tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 711/1000] [D loss: 0.710481] [G loss: 0.456587] [FAKE loss: 1.012935]  tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 712/1000] [D loss: 0.711033] [G loss: 0.460361] [FAKE loss: 1.008455]  tensor(0.6324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 713/1000] [D loss: 0.709136] [G loss: 0.463133] [FAKE loss: 1.000532]  tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 714/1000] [D loss: 0.710290] [G loss: 0.466508] [FAKE loss: 0.997938]  tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 715/1000] [D loss: 0.707633] [G loss: 0.469248] [FAKE loss: 0.990141]  tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 716/1000] [D loss: 0.708928] [G loss: 0.473376] [FAKE loss: 0.986864]  tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 717/1000] [D loss: 0.709520] [G loss: 0.475386] [FAKE loss: 0.984538]  tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 718/1000] [D loss: 0.710483] [G loss: 0.476392] [FAKE loss: 0.983318]  tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 719/1000] [D loss: 0.710748] [G loss: 0.477310] [FAKE loss: 0.980443]  tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 720/1000] [D loss: 0.711066] [G loss: 0.477996] [FAKE loss: 0.977480]  tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 721/1000] [D loss: 0.712003] [G loss: 0.479336] [FAKE loss: 0.976109]  tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 722/1000] [D loss: 0.712633] [G loss: 0.479961] [FAKE loss: 0.975942]  tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 723/1000] [D loss: 0.714643] [G loss: 0.480154] [FAKE loss: 0.977248]  tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 724/1000] [D loss: 0.715573] [G loss: 0.478712] [FAKE loss: 0.976761]  tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 725/1000] [D loss: 0.718938] [G loss: 0.478896] [FAKE loss: 0.980866]  tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 726/1000] [D loss: 0.720098] [G loss: 0.475407] [FAKE loss: 0.983136]  tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 727/1000] [D loss: 0.721933] [G loss: 0.472443] [FAKE loss: 0.985009]  tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 728/1000] [D loss: 0.725886] [G loss: 0.470249] [FAKE loss: 0.994308]  tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 729/1000] [D loss: 0.729686] [G loss: 0.463666] [FAKE loss: 0.998921]  tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 730/1000] [D loss: 0.734106] [G loss: 0.460743] [FAKE loss: 1.010313]  tensor(0.6320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 731/1000] [D loss: 0.738492] [G loss: 0.456565] [FAKE loss: 1.017899]  tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 732/1000] [D loss: 0.741589] [G loss: 0.451038] [FAKE loss: 1.025187]  tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 733/1000] [D loss: 0.745615] [G loss: 0.445117] [FAKE loss: 1.034286]  tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 734/1000] [D loss: 0.749766] [G loss: 0.438430] [FAKE loss: 1.045591]  tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 735/1000] [D loss: 0.755138] [G loss: 0.432823] [FAKE loss: 1.058806]  tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 736/1000] [D loss: 0.762720] [G loss: 0.424945] [FAKE loss: 1.074491]  tensor(0.6545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 737/1000] [D loss: 0.766761] [G loss: 0.419141] [FAKE loss: 1.083923]  tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 738/1000] [D loss: 0.770139] [G loss: 0.412942] [FAKE loss: 1.096028]  tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 739/1000] [D loss: 0.773510] [G loss: 0.407785] [FAKE loss: 1.104148]  tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 740/1000] [D loss: 0.777498] [G loss: 0.401719] [FAKE loss: 1.115968]  tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 741/1000] [D loss: 0.782620] [G loss: 0.395896] [FAKE loss: 1.130905]  tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 742/1000] [D loss: 0.785379] [G loss: 0.389875] [FAKE loss: 1.140474]  tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 743/1000] [D loss: 0.791315] [G loss: 0.382777] [FAKE loss: 1.156923]  tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 744/1000] [D loss: 0.794889] [G loss: 0.376699] [FAKE loss: 1.168888]  tensor(0.6873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 745/1000] [D loss: 0.799729] [G loss: 0.370251] [FAKE loss: 1.183877]  tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 746/1000] [D loss: 0.804547] [G loss: 0.363258] [FAKE loss: 1.197344]  tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 747/1000] [D loss: 0.808939] [G loss: 0.357558] [FAKE loss: 1.211491]  tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 748/1000] [D loss: 0.813014] [G loss: 0.350597] [FAKE loss: 1.225303]  tensor(0.7046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 749/1000] [D loss: 0.817676] [G loss: 0.344547] [FAKE loss: 1.241641]  tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 750/1000] [D loss: 0.823242] [G loss: 0.338987] [FAKE loss: 1.256768]  tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 751/1000] [D loss: 0.828764] [G loss: 0.332005] [FAKE loss: 1.272857]  tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 752/1000] [D loss: 0.832680] [G loss: 0.326067] [FAKE loss: 1.287773]  tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 753/1000] [D loss: 0.836624] [G loss: 0.319420] [FAKE loss: 1.302709]  tensor(0.7270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 754/1000] [D loss: 0.843288] [G loss: 0.313473] [FAKE loss: 1.320849]  tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 755/1000] [D loss: 0.846896] [G loss: 0.307234] [FAKE loss: 1.334476]  tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 756/1000] [D loss: 0.853597] [G loss: 0.301096] [FAKE loss: 1.354838]  tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 757/1000] [D loss: 0.859063] [G loss: 0.294742] [FAKE loss: 1.371620]  tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 758/1000] [D loss: 0.864753] [G loss: 0.288620] [FAKE loss: 1.390046]  tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 759/1000] [D loss: 0.872054] [G loss: 0.282591] [FAKE loss: 1.409803]  tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 760/1000] [D loss: 0.878016] [G loss: 0.276238] [FAKE loss: 1.428587]  tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 761/1000] [D loss: 0.884207] [G loss: 0.270385] [FAKE loss: 1.448000]  tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 762/1000] [D loss: 0.890212] [G loss: 0.264658] [FAKE loss: 1.465440]  tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 763/1000] [D loss: 0.897150] [G loss: 0.257814] [FAKE loss: 1.484922]  tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 764/1000] [D loss: 0.904335] [G loss: 0.252433] [FAKE loss: 1.505730]  tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 765/1000] [D loss: 0.912257] [G loss: 0.246314] [FAKE loss: 1.527750]  tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 766/1000] [D loss: 0.918527] [G loss: 0.240670] [FAKE loss: 1.546456]  tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 767/1000] [D loss: 0.927655] [G loss: 0.234913] [FAKE loss: 1.569967]  tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 768/1000] [D loss: 0.934560] [G loss: 0.229234] [FAKE loss: 1.589664]  tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 769/1000] [D loss: 0.944301] [G loss: 0.223097] [FAKE loss: 1.614732]  tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 770/1000] [D loss: 0.952330] [G loss: 0.217953] [FAKE loss: 1.637254]  tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 771/1000] [D loss: 0.959930] [G loss: 0.212800] [FAKE loss: 1.656512]  tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 772/1000] [D loss: 0.967644] [G loss: 0.207714] [FAKE loss: 1.678745]  tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 773/1000] [D loss: 0.976097] [G loss: 0.202459] [FAKE loss: 1.699863]  tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 774/1000] [D loss: 0.984047] [G loss: 0.197362] [FAKE loss: 1.721358]  tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 775/1000] [D loss: 0.992629] [G loss: 0.192844] [FAKE loss: 1.743852]  tensor(0.8246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 776/1000] [D loss: 1.001397] [G loss: 0.188417] [FAKE loss: 1.765284]  tensor(0.8285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 777/1000] [D loss: 1.010023] [G loss: 0.183486] [FAKE loss: 1.787811]  tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 778/1000] [D loss: 1.018974] [G loss: 0.178938] [FAKE loss: 1.809901]  tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 779/1000] [D loss: 1.027507] [G loss: 0.174793] [FAKE loss: 1.832204]  tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 780/1000] [D loss: 1.036340] [G loss: 0.170572] [FAKE loss: 1.853213]  tensor(0.8431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 781/1000] [D loss: 1.044454] [G loss: 0.166807] [FAKE loss: 1.874836]  tensor(0.8463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 782/1000] [D loss: 1.053286] [G loss: 0.162992] [FAKE loss: 1.895687]  tensor(0.8495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 783/1000] [D loss: 1.060858] [G loss: 0.159448] [FAKE loss: 1.914864]  tensor(0.8525, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 784/1000] [D loss: 1.068885] [G loss: 0.156176] [FAKE loss: 1.934446]  tensor(0.8553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 785/1000] [D loss: 1.076247] [G loss: 0.153180] [FAKE loss: 1.952927]  tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 786/1000] [D loss: 1.083711] [G loss: 0.150214] [FAKE loss: 1.971356]  tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 787/1000] [D loss: 1.091018] [G loss: 0.147284] [FAKE loss: 1.988685]  tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 788/1000] [D loss: 1.096998] [G loss: 0.144706] [FAKE loss: 2.004884]  tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 789/1000] [D loss: 1.103870] [G loss: 0.142095] [FAKE loss: 2.021678]  tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 790/1000] [D loss: 1.110267] [G loss: 0.139708] [FAKE loss: 2.037292]  tensor(0.8696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 791/1000] [D loss: 1.116909] [G loss: 0.137315] [FAKE loss: 2.053273]  tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 792/1000] [D loss: 1.122842] [G loss: 0.135192] [FAKE loss: 2.068401]  tensor(0.8736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 793/1000] [D loss: 1.129016] [G loss: 0.133035] [FAKE loss: 2.083180]  tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 794/1000] [D loss: 1.135328] [G loss: 0.130969] [FAKE loss: 2.098099]  tensor(0.8773, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 795/1000] [D loss: 1.140721] [G loss: 0.129115] [FAKE loss: 2.110991]  tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 796/1000] [D loss: 1.146306] [G loss: 0.127364] [FAKE loss: 2.124238]  tensor(0.8805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 797/1000] [D loss: 1.150941] [G loss: 0.125742] [FAKE loss: 2.135921]  tensor(0.8818, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 798/1000] [D loss: 1.155473] [G loss: 0.124304] [FAKE loss: 2.146930]  tensor(0.8831, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 799/1000] [D loss: 1.159404] [G loss: 0.122981] [FAKE loss: 2.156757]  tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 800/1000] [D loss: 1.163175] [G loss: 0.121824] [FAKE loss: 2.165618]  tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 801/1000] [D loss: 1.166257] [G loss: 0.120802] [FAKE loss: 2.173492]  tensor(0.8862, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 802/1000] [D loss: 1.168941] [G loss: 0.119911] [FAKE loss: 2.180409]  tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 803/1000] [D loss: 1.171221] [G loss: 0.119159] [FAKE loss: 2.186485]  tensor(0.8877, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 804/1000] [D loss: 1.173231] [G loss: 0.118523] [FAKE loss: 2.191442]  tensor(0.8882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 805/1000] [D loss: 1.174785] [G loss: 0.118065] [FAKE loss: 2.195117]  tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 806/1000] [D loss: 1.175742] [G loss: 0.117689] [FAKE loss: 2.198277]  tensor(0.8890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 807/1000] [D loss: 1.176069] [G loss: 0.117383] [FAKE loss: 2.200448]  tensor(0.8892, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 808/1000] [D loss: 1.176571] [G loss: 0.117217] [FAKE loss: 2.201976]  tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 809/1000] [D loss: 1.176706] [G loss: 0.117102] [FAKE loss: 2.202795]  tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 810/1000] [D loss: 1.176521] [G loss: 0.117084] [FAKE loss: 2.202938]  tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 811/1000] [D loss: 1.175874] [G loss: 0.117171] [FAKE loss: 2.202291]  tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 812/1000] [D loss: 1.175178] [G loss: 0.117328] [FAKE loss: 2.200953]  tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 813/1000] [D loss: 1.174072] [G loss: 0.117581] [FAKE loss: 2.199036]  tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 814/1000] [D loss: 1.172643] [G loss: 0.117933] [FAKE loss: 2.196338]  tensor(0.8888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 815/1000] [D loss: 1.170935] [G loss: 0.118370] [FAKE loss: 2.192768]  tensor(0.8884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 816/1000] [D loss: 1.168902] [G loss: 0.118875] [FAKE loss: 2.188711]  tensor(0.8879, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 817/1000] [D loss: 1.166610] [G loss: 0.119480] [FAKE loss: 2.183932]  tensor(0.8874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 818/1000] [D loss: 1.163931] [G loss: 0.120160] [FAKE loss: 2.178150]  tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 819/1000] [D loss: 1.161243] [G loss: 0.120984] [FAKE loss: 2.172081]  tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 820/1000] [D loss: 1.157738] [G loss: 0.121865] [FAKE loss: 2.165090]  tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 821/1000] [D loss: 1.154598] [G loss: 0.122854] [FAKE loss: 2.157647]  tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 822/1000] [D loss: 1.150693] [G loss: 0.123946] [FAKE loss: 2.149382]  tensor(0.8834, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 823/1000] [D loss: 1.146772] [G loss: 0.125096] [FAKE loss: 2.140489]  tensor(0.8824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 824/1000] [D loss: 1.142454] [G loss: 0.126376] [FAKE loss: 2.130931]  tensor(0.8813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 825/1000] [D loss: 1.137938] [G loss: 0.127758] [FAKE loss: 2.120717]  tensor(0.8801, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 826/1000] [D loss: 1.133090] [G loss: 0.129248] [FAKE loss: 2.109782]  tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 827/1000] [D loss: 1.128188] [G loss: 0.130841] [FAKE loss: 2.098737]  tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 828/1000] [D loss: 1.123107] [G loss: 0.132489] [FAKE loss: 2.086732]  tensor(0.8759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 829/1000] [D loss: 1.117629] [G loss: 0.134285] [FAKE loss: 2.074320]  tensor(0.8743, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 830/1000] [D loss: 1.111754] [G loss: 0.136190] [FAKE loss: 2.060971]  tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 831/1000] [D loss: 1.106045] [G loss: 0.138172] [FAKE loss: 2.047597]  tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 832/1000] [D loss: 1.099871] [G loss: 0.140282] [FAKE loss: 2.033649]  tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 833/1000] [D loss: 1.093669] [G loss: 0.142482] [FAKE loss: 2.019057]  tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 834/1000] [D loss: 1.087277] [G loss: 0.144765] [FAKE loss: 2.004308]  tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 835/1000] [D loss: 1.080926] [G loss: 0.147167] [FAKE loss: 1.989038]  tensor(0.8632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 836/1000] [D loss: 1.074159] [G loss: 0.149656] [FAKE loss: 1.973277]  tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 837/1000] [D loss: 1.067511] [G loss: 0.152245] [FAKE loss: 1.957508]  tensor(0.8588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 838/1000] [D loss: 1.060533] [G loss: 0.154970] [FAKE loss: 1.941094]  tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 839/1000] [D loss: 1.053578] [G loss: 0.157788] [FAKE loss: 1.924366]  tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 840/1000] [D loss: 1.046611] [G loss: 0.160715] [FAKE loss: 1.907387]  tensor(0.8515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 841/1000] [D loss: 1.039437] [G loss: 0.163747] [FAKE loss: 1.890346]  tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 842/1000] [D loss: 1.032107] [G loss: 0.166902] [FAKE loss: 1.872860]  tensor(0.8463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 843/1000] [D loss: 1.024887] [G loss: 0.170115] [FAKE loss: 1.855115]  tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 844/1000] [D loss: 1.017658] [G loss: 0.173463] [FAKE loss: 1.837186]  tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 845/1000] [D loss: 1.010166] [G loss: 0.176951] [FAKE loss: 1.818960]  tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 846/1000] [D loss: 1.002872] [G loss: 0.180540] [FAKE loss: 1.800592]  tensor(0.8348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 847/1000] [D loss: 0.995346] [G loss: 0.184276] [FAKE loss: 1.782162]  tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 848/1000] [D loss: 0.987974] [G loss: 0.188066] [FAKE loss: 1.763535]  tensor(0.8285, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 849/1000] [D loss: 0.980424] [G loss: 0.192018] [FAKE loss: 1.744745]  tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 850/1000] [D loss: 0.973034] [G loss: 0.196069] [FAKE loss: 1.725773]  tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 851/1000] [D loss: 0.965617] [G loss: 0.200260] [FAKE loss: 1.706639]  tensor(0.8185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 852/1000] [D loss: 0.958042] [G loss: 0.204557] [FAKE loss: 1.687545]  tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 853/1000] [D loss: 0.950668] [G loss: 0.208938] [FAKE loss: 1.668315]  tensor(0.8114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 854/1000] [D loss: 0.943204] [G loss: 0.213478] [FAKE loss: 1.649224]  tensor(0.8078, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 855/1000] [D loss: 0.935954] [G loss: 0.218105] [FAKE loss: 1.629919]  tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 856/1000] [D loss: 0.928629] [G loss: 0.222827] [FAKE loss: 1.610736]  tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 857/1000] [D loss: 0.921293] [G loss: 0.227711] [FAKE loss: 1.591480]  tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 858/1000] [D loss: 0.914153] [G loss: 0.232644] [FAKE loss: 1.572304]  tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 859/1000] [D loss: 0.906948] [G loss: 0.237773] [FAKE loss: 1.553055]  tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 860/1000] [D loss: 0.899697] [G loss: 0.242959] [FAKE loss: 1.533915]  tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 861/1000] [D loss: 0.893070] [G loss: 0.248232] [FAKE loss: 1.514938]  tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 862/1000] [D loss: 0.886301] [G loss: 0.253574] [FAKE loss: 1.496100]  tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 863/1000] [D loss: 0.879419] [G loss: 0.259076] [FAKE loss: 1.477363]  tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 864/1000] [D loss: 0.872973] [G loss: 0.264645] [FAKE loss: 1.458815]  tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 865/1000] [D loss: 0.866379] [G loss: 0.270297] [FAKE loss: 1.440389]  tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 866/1000] [D loss: 0.860016] [G loss: 0.276044] [FAKE loss: 1.422142]  tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 867/1000] [D loss: 0.853811] [G loss: 0.281838] [FAKE loss: 1.404105]  tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 868/1000] [D loss: 0.847861] [G loss: 0.287695] [FAKE loss: 1.386267]  tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 869/1000] [D loss: 0.841937] [G loss: 0.293644] [FAKE loss: 1.368629]  tensor(0.7456, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 870/1000] [D loss: 0.836073] [G loss: 0.299694] [FAKE loss: 1.351157]  tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 871/1000] [D loss: 0.830398] [G loss: 0.305791] [FAKE loss: 1.333848]  tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 872/1000] [D loss: 0.824742] [G loss: 0.311994] [FAKE loss: 1.316706]  tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 873/1000] [D loss: 0.819439] [G loss: 0.318258] [FAKE loss: 1.299786]  tensor(0.7274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 874/1000] [D loss: 0.814189] [G loss: 0.324561] [FAKE loss: 1.283195]  tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 875/1000] [D loss: 0.809025] [G loss: 0.330939] [FAKE loss: 1.266735]  tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 876/1000] [D loss: 0.804020] [G loss: 0.337355] [FAKE loss: 1.250569]  tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 877/1000] [D loss: 0.799283] [G loss: 0.343861] [FAKE loss: 1.234589]  tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 878/1000] [D loss: 0.794314] [G loss: 0.350405] [FAKE loss: 1.218799]  tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 879/1000] [D loss: 0.789712] [G loss: 0.356971] [FAKE loss: 1.203290]  tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 880/1000] [D loss: 0.785305] [G loss: 0.363567] [FAKE loss: 1.188096]  tensor(0.6952, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 881/1000] [D loss: 0.780915] [G loss: 0.370206] [FAKE loss: 1.173097]  tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 882/1000] [D loss: 0.776899] [G loss: 0.376855] [FAKE loss: 1.158423]  tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 883/1000] [D loss: 0.772647] [G loss: 0.383527] [FAKE loss: 1.144049]  tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 884/1000] [D loss: 0.768775] [G loss: 0.390184] [FAKE loss: 1.129952]  tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 885/1000] [D loss: 0.765039] [G loss: 0.396821] [FAKE loss: 1.116150]  tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 886/1000] [D loss: 0.761402] [G loss: 0.403427] [FAKE loss: 1.102672]  tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 887/1000] [D loss: 0.758011] [G loss: 0.410054] [FAKE loss: 1.089518]  tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 888/1000] [D loss: 0.754705] [G loss: 0.416652] [FAKE loss: 1.076673]  tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 889/1000] [D loss: 0.751398] [G loss: 0.423193] [FAKE loss: 1.064162]  tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 890/1000] [D loss: 0.748570] [G loss: 0.429689] [FAKE loss: 1.051855]  tensor(0.6507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 891/1000] [D loss: 0.745388] [G loss: 0.436165] [FAKE loss: 1.039892]  tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 892/1000] [D loss: 0.742845] [G loss: 0.442584] [FAKE loss: 1.028315]  tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 893/1000] [D loss: 0.740110] [G loss: 0.448952] [FAKE loss: 1.016918]  tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 894/1000] [D loss: 0.737416] [G loss: 0.455258] [FAKE loss: 1.005910]  tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 895/1000] [D loss: 0.735082] [G loss: 0.461510] [FAKE loss: 0.995182]  tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 896/1000] [D loss: 0.732827] [G loss: 0.467616] [FAKE loss: 0.984826]  tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 897/1000] [D loss: 0.730501] [G loss: 0.473709] [FAKE loss: 0.974780]  tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 898/1000] [D loss: 0.728259] [G loss: 0.479673] [FAKE loss: 0.964902]  tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 899/1000] [D loss: 0.726367] [G loss: 0.485560] [FAKE loss: 0.955466]  tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 900/1000] [D loss: 0.724285] [G loss: 0.491360] [FAKE loss: 0.946272]  tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 901/1000] [D loss: 0.722583] [G loss: 0.497017] [FAKE loss: 0.937369]  tensor(0.6083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 902/1000] [D loss: 0.720761] [G loss: 0.502523] [FAKE loss: 0.928919]  tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 903/1000] [D loss: 0.719152] [G loss: 0.507902] [FAKE loss: 0.920718]  tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 904/1000] [D loss: 0.717511] [G loss: 0.513162] [FAKE loss: 0.912763]  tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 905/1000] [D loss: 0.716069] [G loss: 0.518264] [FAKE loss: 0.905220]  tensor(0.5955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 906/1000] [D loss: 0.714841] [G loss: 0.523255] [FAKE loss: 0.897953]  tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 907/1000] [D loss: 0.713435] [G loss: 0.528004] [FAKE loss: 0.891103]  tensor(0.5898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 908/1000] [D loss: 0.712322] [G loss: 0.532629] [FAKE loss: 0.884483]  tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 909/1000] [D loss: 0.711099] [G loss: 0.537015] [FAKE loss: 0.878223]  tensor(0.5845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 910/1000] [D loss: 0.709955] [G loss: 0.541261] [FAKE loss: 0.872347]  tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 911/1000] [D loss: 0.709093] [G loss: 0.545325] [FAKE loss: 0.866739]  tensor(0.5797, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 912/1000] [D loss: 0.708014] [G loss: 0.549113] [FAKE loss: 0.861507]  tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 913/1000] [D loss: 0.707172] [G loss: 0.552778] [FAKE loss: 0.856492]  tensor(0.5753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 914/1000] [D loss: 0.706360] [G loss: 0.556129] [FAKE loss: 0.851918]  tensor(0.5734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 915/1000] [D loss: 0.705600] [G loss: 0.559322] [FAKE loss: 0.847658]  tensor(0.5716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 916/1000] [D loss: 0.704933] [G loss: 0.562361] [FAKE loss: 0.843788]  tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 917/1000] [D loss: 0.704306] [G loss: 0.565057] [FAKE loss: 0.840076]  tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 918/1000] [D loss: 0.703673] [G loss: 0.567641] [FAKE loss: 0.836876]  tensor(0.5668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 919/1000] [D loss: 0.702994] [G loss: 0.569885] [FAKE loss: 0.833741]  tensor(0.5656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 920/1000] [D loss: 0.702623] [G loss: 0.571918] [FAKE loss: 0.831064]  tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 921/1000] [D loss: 0.702117] [G loss: 0.573771] [FAKE loss: 0.828793]  tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 922/1000] [D loss: 0.701715] [G loss: 0.575323] [FAKE loss: 0.826704]  tensor(0.5625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 923/1000] [D loss: 0.701401] [G loss: 0.576664] [FAKE loss: 0.825146]  tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 924/1000] [D loss: 0.700844] [G loss: 0.577735] [FAKE loss: 0.823675]  tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 925/1000] [D loss: 0.700723] [G loss: 0.578418] [FAKE loss: 0.822721]  tensor(0.5608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 926/1000] [D loss: 0.700527] [G loss: 0.579040] [FAKE loss: 0.822021]  tensor(0.5605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 927/1000] [D loss: 0.700376] [G loss: 0.579394] [FAKE loss: 0.821622]  tensor(0.5602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 928/1000] [D loss: 0.700078] [G loss: 0.579394] [FAKE loss: 0.821511]  tensor(0.5602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 929/1000] [D loss: 0.700112] [G loss: 0.579134] [FAKE loss: 0.821733]  tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 930/1000] [D loss: 0.699910] [G loss: 0.578764] [FAKE loss: 0.822362]  tensor(0.5606, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 931/1000] [D loss: 0.699874] [G loss: 0.578127] [FAKE loss: 0.823298]  tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 932/1000] [D loss: 0.699872] [G loss: 0.577005] [FAKE loss: 0.824311]  tensor(0.5615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 933/1000] [D loss: 0.699940] [G loss: 0.576079] [FAKE loss: 0.825946]  tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 934/1000] [D loss: 0.700158] [G loss: 0.574546] [FAKE loss: 0.827754]  tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 935/1000] [D loss: 0.700220] [G loss: 0.572928] [FAKE loss: 0.829823]  tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 936/1000] [D loss: 0.700359] [G loss: 0.571006] [FAKE loss: 0.832377]  tensor(0.5649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 937/1000] [D loss: 0.700799] [G loss: 0.569002] [FAKE loss: 0.835123]  tensor(0.5661, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 938/1000] [D loss: 0.701073] [G loss: 0.566460] [FAKE loss: 0.838075]  tensor(0.5675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 939/1000] [D loss: 0.701462] [G loss: 0.563854] [FAKE loss: 0.841584]  tensor(0.5690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 940/1000] [D loss: 0.701678] [G loss: 0.561177] [FAKE loss: 0.845085]  tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 941/1000] [D loss: 0.702071] [G loss: 0.558220] [FAKE loss: 0.849127]  tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 942/1000] [D loss: 0.702914] [G loss: 0.555101] [FAKE loss: 0.853496]  tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 943/1000] [D loss: 0.703353] [G loss: 0.551651] [FAKE loss: 0.858054]  tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 944/1000] [D loss: 0.704071] [G loss: 0.548087] [FAKE loss: 0.862974]  tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 945/1000] [D loss: 0.704856] [G loss: 0.544458] [FAKE loss: 0.868117]  tensor(0.5802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 946/1000] [D loss: 0.705513] [G loss: 0.540429] [FAKE loss: 0.873260]  tensor(0.5825, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 947/1000] [D loss: 0.706517] [G loss: 0.536452] [FAKE loss: 0.879374]  tensor(0.5849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 948/1000] [D loss: 0.707534] [G loss: 0.532039] [FAKE loss: 0.885306]  tensor(0.5873, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 949/1000] [D loss: 0.708103] [G loss: 0.527637] [FAKE loss: 0.891218]  tensor(0.5898, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 950/1000] [D loss: 0.709670] [G loss: 0.523288] [FAKE loss: 0.898475]  tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 951/1000] [D loss: 0.710652] [G loss: 0.518468] [FAKE loss: 0.904994]  tensor(0.5953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 952/1000] [D loss: 0.711921] [G loss: 0.513870] [FAKE loss: 0.912020]  tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 953/1000] [D loss: 0.712801] [G loss: 0.509136] [FAKE loss: 0.919176]  tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 954/1000] [D loss: 0.714625] [G loss: 0.503906] [FAKE loss: 0.926994]  tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 955/1000] [D loss: 0.715906] [G loss: 0.498794] [FAKE loss: 0.934841]  tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 956/1000] [D loss: 0.717548] [G loss: 0.493455] [FAKE loss: 0.943414]  tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 957/1000] [D loss: 0.719264] [G loss: 0.488259] [FAKE loss: 0.951423]  tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 958/1000] [D loss: 0.720953] [G loss: 0.483005] [FAKE loss: 0.960023]  tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 959/1000] [D loss: 0.723096] [G loss: 0.477409] [FAKE loss: 0.969364]  tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 960/1000] [D loss: 0.724856] [G loss: 0.471866] [FAKE loss: 0.978287]  tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 961/1000] [D loss: 0.726893] [G loss: 0.466249] [FAKE loss: 0.987897]  tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 962/1000] [D loss: 0.728909] [G loss: 0.460346] [FAKE loss: 0.997005]  tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 963/1000] [D loss: 0.731483] [G loss: 0.454910] [FAKE loss: 1.007582]  tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 964/1000] [D loss: 0.733569] [G loss: 0.449165] [FAKE loss: 1.017360]  tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 965/1000] [D loss: 0.736174] [G loss: 0.443438] [FAKE loss: 1.027980]  tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 966/1000] [D loss: 0.738544] [G loss: 0.437427] [FAKE loss: 1.038013]  tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 967/1000] [D loss: 0.741529] [G loss: 0.431892] [FAKE loss: 1.049158]  tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 968/1000] [D loss: 0.743804] [G loss: 0.426049] [FAKE loss: 1.059539]  tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 969/1000] [D loss: 0.746979] [G loss: 0.419683] [FAKE loss: 1.071228]  tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 970/1000] [D loss: 0.749753] [G loss: 0.413984] [FAKE loss: 1.082244]  tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 971/1000] [D loss: 0.752685] [G loss: 0.408310] [FAKE loss: 1.093734]  tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 972/1000] [D loss: 0.755960] [G loss: 0.402956] [FAKE loss: 1.105477]  tensor(0.6686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 973/1000] [D loss: 0.758793] [G loss: 0.396789] [FAKE loss: 1.116727]  tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 974/1000] [D loss: 0.762380] [G loss: 0.391169] [FAKE loss: 1.129061]  tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 975/1000] [D loss: 0.765828] [G loss: 0.384958] [FAKE loss: 1.141431]  tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 976/1000] [D loss: 0.769163] [G loss: 0.379653] [FAKE loss: 1.153560]  tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 977/1000] [D loss: 0.772768] [G loss: 0.373723] [FAKE loss: 1.166204]  tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 978/1000] [D loss: 0.776699] [G loss: 0.368036] [FAKE loss: 1.179046]  tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 979/1000] [D loss: 0.780603] [G loss: 0.362490] [FAKE loss: 1.192326]  tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 980/1000] [D loss: 0.784436] [G loss: 0.356987] [FAKE loss: 1.205233]  tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 981/1000] [D loss: 0.788806] [G loss: 0.350959] [FAKE loss: 1.218843]  tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 982/1000] [D loss: 0.792721] [G loss: 0.345544] [FAKE loss: 1.232051]  tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 983/1000] [D loss: 0.797010] [G loss: 0.339962] [FAKE loss: 1.245417]  tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 984/1000] [D loss: 0.801179] [G loss: 0.334837] [FAKE loss: 1.259070]  tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 985/1000] [D loss: 0.805372] [G loss: 0.329386] [FAKE loss: 1.272360]  tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 986/1000] [D loss: 0.809903] [G loss: 0.323875] [FAKE loss: 1.286375]  tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 987/1000] [D loss: 0.814893] [G loss: 0.318375] [FAKE loss: 1.301004]  tensor(0.7274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 988/1000] [D loss: 0.819332] [G loss: 0.313585] [FAKE loss: 1.314727]  tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 989/1000] [D loss: 0.824024] [G loss: 0.308432] [FAKE loss: 1.329223]  tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 990/1000] [D loss: 0.829392] [G loss: 0.303153] [FAKE loss: 1.344434]  tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 991/1000] [D loss: 0.834149] [G loss: 0.298240] [FAKE loss: 1.358478]  tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 992/1000] [D loss: 0.838919] [G loss: 0.293274] [FAKE loss: 1.373053]  tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 993/1000] [D loss: 0.843841] [G loss: 0.288532] [FAKE loss: 1.387012]  tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 994/1000] [D loss: 0.849383] [G loss: 0.283335] [FAKE loss: 1.402576]  tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 995/1000] [D loss: 0.854071] [G loss: 0.278961] [FAKE loss: 1.416033]  tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 996/1000] [D loss: 0.859055] [G loss: 0.274159] [FAKE loss: 1.430652]  tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 997/1000] [D loss: 0.865187] [G loss: 0.269668] [FAKE loss: 1.446720]  tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 998/1000] [D loss: 0.869791] [G loss: 0.265589] [FAKE loss: 1.460656]  tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 999/1000] [D loss: 0.875368] [G loss: 0.260792] [FAKE loss: 1.475751]  tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata[1][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrihcghOqMW2",
        "outputId": "1782e22f-d33b-4c55-b9dd-aa68df966b58"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5201, 0.5828, 0.5117, 0.6643, 0.4171, 0.4135, 0.3808, 0.6583, 0.5251])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBn8CEg1qMR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ew2LdsnTqMOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9g2WnYvqMKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}