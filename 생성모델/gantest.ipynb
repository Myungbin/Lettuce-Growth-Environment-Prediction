{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# g"
      ],
      "metadata": {
        "id": "hMvKXWUo5zv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyJw_dEr5o3C",
        "outputId": "0689ed40-eec1-40b4-9e2b-ea9f1c887431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  6 03:15:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcOjPj6J5u--",
        "outputId": "30f43e25-0b76-4ed4-ef0b-c51caab3d20c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ6N0vwl5u8I",
        "outputId": "78f4b6de-e2a9-4ee6-b9e4-9d012ba312ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#d"
      ],
      "metadata": {
        "id": "EsVp2woY5wxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim \n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "5oQqyzrY5u5Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('drive/MyDrive/dacon/dataf/상추/train_input/CASE_01.csv')"
      ],
      "metadata": {
        "id": "5PXRLclFBmQL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "id": "kLsJNS3UGzpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(nn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nLG70r3b3eu",
        "outputId": "f07a0286-522a-49dc-f27e-589072d7457b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AdaptiveAvgPool1d', 'AdaptiveAvgPool2d', 'AdaptiveAvgPool3d', 'AdaptiveLogSoftmaxWithLoss', 'AdaptiveMaxPool1d', 'AdaptiveMaxPool2d', 'AdaptiveMaxPool3d', 'AlphaDropout', 'AvgPool1d', 'AvgPool2d', 'AvgPool3d', 'BCELoss', 'BCEWithLogitsLoss', 'BatchNorm1d', 'BatchNorm2d', 'BatchNorm3d', 'Bilinear', 'CELU', 'CTCLoss', 'ChannelShuffle', 'ConstantPad1d', 'ConstantPad2d', 'ConstantPad3d', 'Container', 'Conv1d', 'Conv2d', 'Conv3d', 'ConvTranspose1d', 'ConvTranspose2d', 'ConvTranspose3d', 'CosineEmbeddingLoss', 'CosineSimilarity', 'CrossEntropyLoss', 'CrossMapLRN2d', 'DataParallel', 'Dropout', 'Dropout1d', 'Dropout2d', 'Dropout3d', 'ELU', 'Embedding', 'EmbeddingBag', 'FeatureAlphaDropout', 'Flatten', 'Fold', 'FractionalMaxPool2d', 'FractionalMaxPool3d', 'GELU', 'GLU', 'GRU', 'GRUCell', 'GaussianNLLLoss', 'GroupNorm', 'Hardshrink', 'Hardsigmoid', 'Hardswish', 'Hardtanh', 'HingeEmbeddingLoss', 'HuberLoss', 'Identity', 'InstanceNorm1d', 'InstanceNorm2d', 'InstanceNorm3d', 'KLDivLoss', 'L1Loss', 'LPPool1d', 'LPPool2d', 'LSTM', 'LSTMCell', 'LayerNorm', 'LazyBatchNorm1d', 'LazyBatchNorm2d', 'LazyBatchNorm3d', 'LazyConv1d', 'LazyConv2d', 'LazyConv3d', 'LazyConvTranspose1d', 'LazyConvTranspose2d', 'LazyConvTranspose3d', 'LazyInstanceNorm1d', 'LazyInstanceNorm2d', 'LazyInstanceNorm3d', 'LazyLinear', 'LeakyReLU', 'Linear', 'LocalResponseNorm', 'LogSigmoid', 'LogSoftmax', 'MSELoss', 'MarginRankingLoss', 'MaxPool1d', 'MaxPool2d', 'MaxPool3d', 'MaxUnpool1d', 'MaxUnpool2d', 'MaxUnpool3d', 'Mish', 'Module', 'ModuleDict', 'ModuleList', 'MultiLabelMarginLoss', 'MultiLabelSoftMarginLoss', 'MultiMarginLoss', 'MultiheadAttention', 'NLLLoss', 'NLLLoss2d', 'PReLU', 'PairwiseDistance', 'Parameter', 'ParameterDict', 'ParameterList', 'PixelShuffle', 'PixelUnshuffle', 'PoissonNLLLoss', 'RNN', 'RNNBase', 'RNNCell', 'RNNCellBase', 'RReLU', 'ReLU', 'ReLU6', 'ReflectionPad1d', 'ReflectionPad2d', 'ReflectionPad3d', 'ReplicationPad1d', 'ReplicationPad2d', 'ReplicationPad3d', 'SELU', 'Sequential', 'SiLU', 'Sigmoid', 'SmoothL1Loss', 'SoftMarginLoss', 'Softmax', 'Softmax2d', 'Softmin', 'Softplus', 'Softshrink', 'Softsign', 'SyncBatchNorm', 'Tanh', 'Tanhshrink', 'Threshold', 'Transformer', 'TransformerDecoder', 'TransformerDecoderLayer', 'TransformerEncoder', 'TransformerEncoderLayer', 'TripletMarginLoss', 'TripletMarginWithDistanceLoss', 'Unflatten', 'Unfold', 'UninitializedBuffer', 'UninitializedParameter', 'Upsample', 'UpsamplingBilinear2d', 'UpsamplingNearest2d', 'ZeroPad2d', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_reduction', 'common_types', 'factory_kwargs', 'functional', 'grad', 'init', 'intrinsic', 'modules', 'parallel', 'parameter', 'qat', 'quantizable', 'quantized', 'utils']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftonp = test.values\n",
        "nptonn = torch.from_numpy(dftonp)\n",
        "nptonn.size(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2fKcq4ac8-t",
        "outputId": "3c61e0aa-9a20-4f94-bc49-739b36b48886"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "672"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nptonn.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyAeQoQdoTUM",
        "outputId": "69f2c738-3abe-4aeb-bf26-862d9e65f38d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([672, 23])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "r7ZStrz2kims"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input = 23\n",
        "    self.hidden = 672\n",
        "    self.output= 1\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input, self.hidden), # input size, hidden size\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(self.hidden, int(self.hidden/2)),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(int(self.hidden/2),self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.input = 672\n",
        "    self.output = 23\n",
        "    self.hidden = 128\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input, self.hidden), # input size, hidden size\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(self.hidden, int(self.hidden/2)),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(int(self.hidden/2),self.output), # hidden size, output size\n",
        "        nn.Tanh()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print('generator',x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "# 모델 정의\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
        "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
        "\n",
        "criterion = nn.BCELoss().to(device)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=g_optim, mode='min', verbose=True, patience=10, factor=0.5)\n",
        "\n",
        "import time\n",
        "n_epochs = 10\n",
        "sample_interval = 100 # 몇 번의 배치마다 결과를 출력할 것인가\n",
        "noise = 672\n",
        "start_time = time.time()\n",
        "newdata = []\n",
        "for epoch in range(n_epochs):\n",
        "  dftonp = test.values\n",
        "  nptonn = torch.from_numpy(dftonp).float()\n",
        "\n",
        "  real = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(1.0) # 진짜\n",
        "  fake = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(0.0) # 가짜\n",
        "\n",
        "  real_data = nptonn.cuda()\n",
        "  \n",
        "  g_optim.zero_grad()\n",
        "  z = torch.normal(mean=0, std=1, size=(nptonn.shape[0], noise)).cuda() # random noise\n",
        "  #print('noise',z.size())\n",
        "  generated_dis = generator(z) # create distribution\n",
        "  generated_dis_value = generated_dis.detach().cpu()\n",
        "  newdata.append(generated_dis)\n",
        "  # criterion.cuda()\n",
        "  g_loss =  criterion(discriminator(generated_dis), real) # calculate generator loss\n",
        "  \n",
        "  # update generator\n",
        "  g_loss.backward()\n",
        "  g_optim.step()\n",
        "\n",
        "  # update discriminator\n",
        "  real_loss = criterion(discriminator(real_data), real)\n",
        "  fake_loss = criterion(discriminator(generated_dis.detach()), fake)\n",
        "  d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "  d_loss.backward()\n",
        "  d_optim.step()\n",
        "\n",
        "  print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YxzovLpgULa",
        "outputId": "8a8aeaf1-558c-4182-e221-bf7169498f18"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/10] [D loss: 0.682218] [G loss: 0.676611] [Elapsed time: 0.01s]\n",
            "[Epoch 1/10] [D loss: 0.476785] [G loss: 0.658415] [Elapsed time: 0.02s]\n",
            "[Epoch 2/10] [D loss: 0.409846] [G loss: 0.641439] [Elapsed time: 0.03s]\n",
            "[Epoch 3/10] [D loss: 0.394222] [G loss: 0.625326] [Elapsed time: 0.04s]\n",
            "[Epoch 4/10] [D loss: 0.396720] [G loss: 0.608111] [Elapsed time: 0.05s]\n",
            "[Epoch 5/10] [D loss: 0.404734] [G loss: 0.591713] [Elapsed time: 0.05s]\n",
            "[Epoch 6/10] [D loss: 0.414251] [G loss: 0.574726] [Elapsed time: 0.06s]\n",
            "[Epoch 7/10] [D loss: 0.425514] [G loss: 0.556766] [Elapsed time: 0.07s]\n",
            "[Epoch 8/10] [D loss: 0.436643] [G loss: 0.540711] [Elapsed time: 0.08s]\n",
            "[Epoch 9/10] [D loss: 0.449231] [G loss: 0.523282] [Elapsed time: 0.09s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata"
      ],
      "metadata": {
        "id": "HelGyFOK0GSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nptonn[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQBDpnL00GPk",
        "outputId": "a339c9db-cd50-492c-ac3b-ae6c8baec105"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.0000, 3.2581, 4.4067, 6.2860, 0.6931, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "        0.0000, 0.0000, 0.0000, 0.6931, 6.2860])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0IU4gnCgR6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blOk0n5w1os_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqfTqGLx1poy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aoWOY2A1plk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}