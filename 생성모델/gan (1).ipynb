{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cygy69N84Gk"
      },
      "source": [
        "# grg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS1qnZGD8smn",
        "outputId": "f4ce100a-2836-4969-efa3-fe304cb552e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec  8 04:10:58 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rv-Bjso8skF",
        "outputId": "01393fbe-2e3c-475d-f893-a593ac6bcbc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Fd1r4y8shy",
        "outputId": "edf8579b-6c78-4863-a0c7-288282faf16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoM8KXCv82Er"
      },
      "source": [
        "# gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wBRWQnVp-ifk"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "def preprocessing(input_path):\n",
        "    all_input_list = sorted(glob.glob(input_path))\n",
        "    train = pd.DataFrame()\n",
        "    for datapath in all_input_list:\n",
        "        data = pd.read_csv(datapath) \n",
        "  \n",
        "        data['obs_time'] = data.index % 24 \n",
        "        df = abs(data)\n",
        "        df.loc[(df['내부온도관측치'] > 40), '내부온도관측치'] = 40\n",
        "        df.loc[(df['내부습도관측치'] > 100), '내부습도관측치'] = 100\n",
        "        df.loc[(df['co2관측치'] > 1200), 'co2관측치'] = 1200\n",
        "        df.loc[(df['ec관측치'] > 8), 'ec관측치'] = 8\n",
        "        df.loc[(df['시간당분무량'] > 3000), '시간당분무량'] = 3000\n",
        "        df.loc[(df['시간당백색광량'] > 120000), '시간당백색광량'] = 120000\n",
        "        df.loc[(df['시간당적색광량'] > 120000), '시간당적색광량'] = 120000\n",
        "        df.loc[(df['시간당청색광량'] > 120000), '시간당청색광량'] = 120000\n",
        "        df.loc[(df['시간당총광량'] > 120000), '시간당총광량'] = 120000\n",
        "        df['시간당총광량'] = df['시간당청색광량']+df['시간당백색광량']+df['시간당적색광량']\n",
        "        \n",
        "        col_list = df.columns\n",
        "        for i in range(0,len(col_list)):\n",
        "            col = col_list[i]    \n",
        "            if '누적' in col : \n",
        "                df[col] = df.groupby((df.obs_time == 0).cumsum()).agg(col_list[i-1]).cumsum()   \n",
        "            df.to_csv(datapath,index=False)\n",
        "            train = pd.concat([train,df])\n",
        "    print('finish!!')\n",
        "    return train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0djyR4b8-z7e",
        "outputId": "a27f2f8d-a5f5-425a-fc62-8fbbc69392e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish!!\n"
          ]
        }
      ],
      "source": [
        "traininput = preprocessing('drive/MyDrive/dacon/gan/상추/train_input/*.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day0 = traininput[traininput['DAT']==0].reset_index(drop=True)\n",
        "day0 = day0[['obs_time','내부온도관측치','내부습도관측치','co2관측치','ec관측치','시간당분무량','시간당백색광량','시간당적색광량','시간당청색광량']]\n",
        "day0.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ZwYZ31hm3-CV",
        "outputId": "56301450-094d-4508-91c0-480190523087"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           obs_time       내부온도관측치       내부습도관측치        co2관측치         ec관측치  \\\n",
              "count  10752.000000  10752.000000  10752.000000  10752.000000  10752.000000   \n",
              "mean      11.500000     25.781004     54.912360    533.833783      1.273970   \n",
              "std        6.922508      4.361793     12.257845    144.127605      0.932456   \n",
              "min        0.000000      0.000000      0.000000     60.400000      0.000000   \n",
              "25%        5.750000     23.595463     49.183641    446.345833      0.401136   \n",
              "50%       11.500000     26.280460     56.510000    505.883333      1.212455   \n",
              "75%       17.250000     28.717917     61.310767    578.400000      2.011237   \n",
              "max       23.000000     39.158823     81.900001   1200.000000      3.034100   \n",
              "\n",
              "             시간당분무량        시간당백색광량       시간당적색광량       시간당청색광량  \n",
              "count  10752.000000   10752.000000  10752.000000  10752.000000  \n",
              "mean     430.609479    6765.408458   1309.564887    856.852189  \n",
              "std      491.308581    9450.283141   2653.722924   1938.172567  \n",
              "min        0.000000       0.000000      0.000000      0.000000  \n",
              "25%        0.000000       0.000000      0.000000      0.000000  \n",
              "50%      242.355000       0.000000      0.000000      0.000000  \n",
              "75%      769.000000   18255.190000    976.332000    135.110625  \n",
              "max     2735.210000  120000.000000   9928.800000  18570.857500  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa7455ff-9b49-4632-bba2-9b2087ff73d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs_time</th>\n",
              "      <th>내부온도관측치</th>\n",
              "      <th>내부습도관측치</th>\n",
              "      <th>co2관측치</th>\n",
              "      <th>ec관측치</th>\n",
              "      <th>시간당분무량</th>\n",
              "      <th>시간당백색광량</th>\n",
              "      <th>시간당적색광량</th>\n",
              "      <th>시간당청색광량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "      <td>10752.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>11.500000</td>\n",
              "      <td>25.781004</td>\n",
              "      <td>54.912360</td>\n",
              "      <td>533.833783</td>\n",
              "      <td>1.273970</td>\n",
              "      <td>430.609479</td>\n",
              "      <td>6765.408458</td>\n",
              "      <td>1309.564887</td>\n",
              "      <td>856.852189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.922508</td>\n",
              "      <td>4.361793</td>\n",
              "      <td>12.257845</td>\n",
              "      <td>144.127605</td>\n",
              "      <td>0.932456</td>\n",
              "      <td>491.308581</td>\n",
              "      <td>9450.283141</td>\n",
              "      <td>2653.722924</td>\n",
              "      <td>1938.172567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.750000</td>\n",
              "      <td>23.595463</td>\n",
              "      <td>49.183641</td>\n",
              "      <td>446.345833</td>\n",
              "      <td>0.401136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.500000</td>\n",
              "      <td>26.280460</td>\n",
              "      <td>56.510000</td>\n",
              "      <td>505.883333</td>\n",
              "      <td>1.212455</td>\n",
              "      <td>242.355000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>17.250000</td>\n",
              "      <td>28.717917</td>\n",
              "      <td>61.310767</td>\n",
              "      <td>578.400000</td>\n",
              "      <td>2.011237</td>\n",
              "      <td>769.000000</td>\n",
              "      <td>18255.190000</td>\n",
              "      <td>976.332000</td>\n",
              "      <td>135.110625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>39.158823</td>\n",
              "      <td>81.900001</td>\n",
              "      <td>1200.000000</td>\n",
              "      <td>3.034100</td>\n",
              "      <td>2735.210000</td>\n",
              "      <td>120000.000000</td>\n",
              "      <td>9928.800000</td>\n",
              "      <td>18570.857500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa7455ff-9b49-4632-bba2-9b2087ff73d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa7455ff-9b49-4632-bba2-9b2087ff73d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa7455ff-9b49-4632-bba2-9b2087ff73d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tbY1c5aUzOWh",
        "outputId": "0e01de5f-a6f1-4325-b1b6-88f2214f8ac0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       obs_time    내부온도관측치    내부습도관측치      co2관측치     ec관측치  시간당분무량  시간당백색광량  \\\n",
              "0             0  25.300000  81.835000  536.016667  1.407439     0.0   0.0000   \n",
              "1             1  25.680357  81.264286  528.696429  1.409003   126.0   0.0000   \n",
              "2             2  25.273333  81.471666  532.833333  1.406913     0.0   0.0000   \n",
              "3             3  25.355000  81.398334  545.566667  1.406689   126.0   0.0000   \n",
              "4             4  25.391667  81.483333  558.583333  1.411070     0.0   0.0000   \n",
              "...         ...        ...        ...         ...       ...     ...      ...   \n",
              "10747        19  29.980000  59.256667  505.466667  1.014238     0.0   9.2823   \n",
              "10748        20  29.730000  59.458333  504.433333  1.017222     0.0   0.0000   \n",
              "10749        21  29.491667  59.801667  501.216667  1.019655   769.0   0.0000   \n",
              "10750        22  29.531667  60.031667  501.400000  1.020756     0.0   0.0000   \n",
              "10751        23  29.349999  60.906667  503.300000  1.022382     0.0   0.0000   \n",
              "\n",
              "       시간당적색광량  시간당청색광량  \n",
              "0          0.0      0.0  \n",
              "1          0.0      0.0  \n",
              "2          0.0      0.0  \n",
              "3          0.0      0.0  \n",
              "4          0.0      0.0  \n",
              "...        ...      ...  \n",
              "10747      0.0      0.0  \n",
              "10748      0.0      0.0  \n",
              "10749      0.0      0.0  \n",
              "10750      0.0      0.0  \n",
              "10751      0.0      0.0  \n",
              "\n",
              "[10752 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b72deac-f47f-4875-a616-9228361f615e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs_time</th>\n",
              "      <th>내부온도관측치</th>\n",
              "      <th>내부습도관측치</th>\n",
              "      <th>co2관측치</th>\n",
              "      <th>ec관측치</th>\n",
              "      <th>시간당분무량</th>\n",
              "      <th>시간당백색광량</th>\n",
              "      <th>시간당적색광량</th>\n",
              "      <th>시간당청색광량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>81.835000</td>\n",
              "      <td>536.016667</td>\n",
              "      <td>1.407439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>25.680357</td>\n",
              "      <td>81.264286</td>\n",
              "      <td>528.696429</td>\n",
              "      <td>1.409003</td>\n",
              "      <td>126.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>25.273333</td>\n",
              "      <td>81.471666</td>\n",
              "      <td>532.833333</td>\n",
              "      <td>1.406913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>25.355000</td>\n",
              "      <td>81.398334</td>\n",
              "      <td>545.566667</td>\n",
              "      <td>1.406689</td>\n",
              "      <td>126.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>25.391667</td>\n",
              "      <td>81.483333</td>\n",
              "      <td>558.583333</td>\n",
              "      <td>1.411070</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10747</th>\n",
              "      <td>19</td>\n",
              "      <td>29.980000</td>\n",
              "      <td>59.256667</td>\n",
              "      <td>505.466667</td>\n",
              "      <td>1.014238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.2823</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10748</th>\n",
              "      <td>20</td>\n",
              "      <td>29.730000</td>\n",
              "      <td>59.458333</td>\n",
              "      <td>504.433333</td>\n",
              "      <td>1.017222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10749</th>\n",
              "      <td>21</td>\n",
              "      <td>29.491667</td>\n",
              "      <td>59.801667</td>\n",
              "      <td>501.216667</td>\n",
              "      <td>1.019655</td>\n",
              "      <td>769.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10750</th>\n",
              "      <td>22</td>\n",
              "      <td>29.531667</td>\n",
              "      <td>60.031667</td>\n",
              "      <td>501.400000</td>\n",
              "      <td>1.020756</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10751</th>\n",
              "      <td>23</td>\n",
              "      <td>29.349999</td>\n",
              "      <td>60.906667</td>\n",
              "      <td>503.300000</td>\n",
              "      <td>1.022382</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10752 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b72deac-f47f-4875-a616-9228361f615e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b72deac-f47f-4875-a616-9228361f615e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b72deac-f47f-4875-a616-9228361f615e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "sc = MinMaxScaler()"
      ],
      "metadata": {
        "id": "ZccJOrAWiMCp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.fit(day0)\n",
        "newday0= sc.transform(day0)"
      ],
      "metadata": {
        "id": "_brVsVKuicbW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import hstack\n",
        "from numpy.random import rand\n",
        "from numpy.random import randn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "p2De1F5HFQRT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim \n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# 노이즈 -> 피쳐수만큼\n",
        "# generator input -> 노이즈가 들어감\n",
        "# generator ouput -> real data x 형태로 나와야 함.\n",
        "# discriminator input -> real data x 가 들어감\n",
        "# discriminator output -> 1\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input = 9 \n",
        "    self.output= 1\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.input, 16), # input size, hidden size\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(16, 64),\n",
        "        nn.LeakyReLU(0.8),\n",
        "        nn.Linear(64, 128),\n",
        "        nn.LeakyReLU(0.5),\n",
        "        nn.Linear(128, self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print(x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.features = 9 # 피쳐수\n",
        "    self.output = 9  # 데이터수\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(self.features, 64), # input size, hidden size\n",
        "        nn.Sigmoid(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(64, 16),\n",
        "        #nn.LeakyReLU(0.2),\n",
        "        nn.Linear(16,self.output), # hidden size, output size\n",
        "        nn.Sigmoid()\n",
        "    ).to(device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #print('generator',x.size())\n",
        "    x = self.model(x)\n",
        "    return x\n",
        "\n",
        "# 모델 정의\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
        "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
        "\n",
        "criterion = nn.BCELoss().to(device)\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=g_optim, mode='min', verbose=True, patience=10, factor=0.5)\n",
        "\n",
        "import time\n",
        "n_epochs = 1000\n",
        "noise = 9\n",
        "start_time = time.time()\n",
        "newdata = []\n",
        "testdata = []\n",
        "#print(real_data)\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  test = day0.iloc[:28].values\n",
        "  \n",
        "  nptonn = torch.from_numpy(newday0).float()\n",
        "\n",
        "  real = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(1.0) # \n",
        "  fake = torch.cuda.FloatTensor(nptonn.size(0), 1).fill_(0.0) # \n",
        "\n",
        "  real_data = nptonn.cuda()\n",
        "  g_optim.zero_grad()\n",
        "\n",
        "  z0 = torch.normal(mean=11.5, std=6.9, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z1 = torch.normal(mean=25.78, std=4.3, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z2 = torch.normal(mean=54.91, std=12.2, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z3 = torch.normal(mean=533.833, std=144.1, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z4 = torch.normal(mean=1.273, std=0.932, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z5 = torch.normal(mean=430.600, std=491.308, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z6 = torch.normal(mean=6765.408, std=9450.28, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z7 = torch.normal(mean=1309.564, std=2653.722, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  z8 = torch.normal(mean=856.852, std=1938.17, size=(nptonn.shape[0], 1)).cuda() # random noise\n",
        "  zz = torch.normal(mean=0, std=1, size=(nptonn.shape[0], noise)).cuda()\n",
        "\n",
        "  z = torch.cat([z0,z1,z2,z3,z4,z5,z6,z7,z8], dim=1) #[M, N+N, K]\n",
        "  #print(z.size())\n",
        "\n",
        "  generated_dis = generator(z) # create distribution\n",
        "  #print(generated_dis.size())\n",
        "  #print(real_data.size())\n",
        "  generated_dis_value = generated_dis.detach().cpu()\n",
        "  g_loss =  criterion(discriminator(generated_dis), real) # calculate generator loss\n",
        "  \n",
        "  # update generator\n",
        "  g_loss.backward()\n",
        "  g_optim.step()\n",
        "\n",
        "  # update discriminator\n",
        "  real_loss = criterion(discriminator(real_data), real)\n",
        "  r_score = discriminator(real_data).mean()\n",
        "  fake_loss = criterion(discriminator(generated_dis.detach()), fake)\n",
        "  g_score = discriminator(generated_dis).mean()\n",
        "  d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "  newdata.append(generated_dis_value)\n",
        "\n",
        "  d_loss.backward()\n",
        "  d_optim.step()\n",
        "\n",
        "  print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [FAKE loss: {fake_loss.item():.6f}] \",\n",
        "        g_score, r_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QDx8n0j3zYF",
        "outputId": "c85dc3b1-a654-4fc5-fc5f-3f95103bfa0b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/1000] [D loss: 0.695153] [G loss: 0.660646] [FAKE loss: 0.726829]  tensor(0.5165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 1/1000] [D loss: 0.695528] [G loss: 0.653474] [FAKE loss: 0.734561]  tensor(0.5202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 2/1000] [D loss: 0.695631] [G loss: 0.646730] [FAKE loss: 0.742016]  tensor(0.5239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 3/1000] [D loss: 0.695816] [G loss: 0.639743] [FAKE loss: 0.749466]  tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 4/1000] [D loss: 0.696291] [G loss: 0.633179] [FAKE loss: 0.757242]  tensor(0.5311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 5/1000] [D loss: 0.696843] [G loss: 0.626081] [FAKE loss: 0.765147]  tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 6/1000] [D loss: 0.697194] [G loss: 0.619188] [FAKE loss: 0.773098]  tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 7/1000] [D loss: 0.697970] [G loss: 0.612480] [FAKE loss: 0.781469]  tensor(0.5422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 8/1000] [D loss: 0.698570] [G loss: 0.605179] [FAKE loss: 0.789640]  tensor(0.5458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 9/1000] [D loss: 0.699543] [G loss: 0.598266] [FAKE loss: 0.798608]  tensor(0.5498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 10/1000] [D loss: 0.700085] [G loss: 0.590925] [FAKE loss: 0.807094]  tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 11/1000] [D loss: 0.701065] [G loss: 0.584145] [FAKE loss: 0.816016]  tensor(0.5579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 12/1000] [D loss: 0.701901] [G loss: 0.576649] [FAKE loss: 0.824900]  tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 13/1000] [D loss: 0.703040] [G loss: 0.569246] [FAKE loss: 0.834467]  tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 14/1000] [D loss: 0.704354] [G loss: 0.562049] [FAKE loss: 0.844518]  tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 15/1000] [D loss: 0.705693] [G loss: 0.554732] [FAKE loss: 0.854494]  tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 16/1000] [D loss: 0.706994] [G loss: 0.547140] [FAKE loss: 0.864883]  tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 17/1000] [D loss: 0.708710] [G loss: 0.539508] [FAKE loss: 0.875629]  tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 18/1000] [D loss: 0.710205] [G loss: 0.531866] [FAKE loss: 0.885885]  tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 19/1000] [D loss: 0.712070] [G loss: 0.524422] [FAKE loss: 0.897524]  tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 20/1000] [D loss: 0.714116] [G loss: 0.516829] [FAKE loss: 0.909024]  tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 21/1000] [D loss: 0.715543] [G loss: 0.508997] [FAKE loss: 0.920053]  tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 22/1000] [D loss: 0.717704] [G loss: 0.500995] [FAKE loss: 0.931644]  tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 23/1000] [D loss: 0.720146] [G loss: 0.493184] [FAKE loss: 0.944323]  tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 24/1000] [D loss: 0.722422] [G loss: 0.485349] [FAKE loss: 0.956672]  tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 25/1000] [D loss: 0.725131] [G loss: 0.477545] [FAKE loss: 0.969721]  tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 26/1000] [D loss: 0.727583] [G loss: 0.469686] [FAKE loss: 0.982735]  tensor(0.6256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 27/1000] [D loss: 0.730454] [G loss: 0.461455] [FAKE loss: 0.996143]  tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 28/1000] [D loss: 0.733696] [G loss: 0.453187] [FAKE loss: 1.010502]  tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 29/1000] [D loss: 0.736817] [G loss: 0.445499] [FAKE loss: 1.024282]  tensor(0.6403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 30/1000] [D loss: 0.740764] [G loss: 0.437297] [FAKE loss: 1.040126]  tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 31/1000] [D loss: 0.744133] [G loss: 0.429526] [FAKE loss: 1.054688]  tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 32/1000] [D loss: 0.747349] [G loss: 0.420973] [FAKE loss: 1.069375]  tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 33/1000] [D loss: 0.751667] [G loss: 0.413450] [FAKE loss: 1.085577]  tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 34/1000] [D loss: 0.755451] [G loss: 0.406227] [FAKE loss: 1.100695]  tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 35/1000] [D loss: 0.760709] [G loss: 0.397144] [FAKE loss: 1.119159]  tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 36/1000] [D loss: 0.765121] [G loss: 0.389148] [FAKE loss: 1.135329]  tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 37/1000] [D loss: 0.769763] [G loss: 0.381113] [FAKE loss: 1.153191]  tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 38/1000] [D loss: 0.774422] [G loss: 0.373834] [FAKE loss: 1.169647]  tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 39/1000] [D loss: 0.780255] [G loss: 0.365207] [FAKE loss: 1.188819]  tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 40/1000] [D loss: 0.785456] [G loss: 0.357181] [FAKE loss: 1.207524]  tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 41/1000] [D loss: 0.791251] [G loss: 0.349394] [FAKE loss: 1.226875]  tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 42/1000] [D loss: 0.797344] [G loss: 0.341091] [FAKE loss: 1.245617]  tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 43/1000] [D loss: 0.804168] [G loss: 0.333698] [FAKE loss: 1.266161]  tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 44/1000] [D loss: 0.810185] [G loss: 0.325867] [FAKE loss: 1.285997]  tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 45/1000] [D loss: 0.816464] [G loss: 0.318197] [FAKE loss: 1.305986]  tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 46/1000] [D loss: 0.822430] [G loss: 0.310526] [FAKE loss: 1.325827]  tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 47/1000] [D loss: 0.830792] [G loss: 0.303559] [FAKE loss: 1.348910]  tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 48/1000] [D loss: 0.837381] [G loss: 0.295261] [FAKE loss: 1.369765]  tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 49/1000] [D loss: 0.845607] [G loss: 0.288382] [FAKE loss: 1.392783]  tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 50/1000] [D loss: 0.852205] [G loss: 0.281112] [FAKE loss: 1.413597]  tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 51/1000] [D loss: 0.860619] [G loss: 0.273895] [FAKE loss: 1.437408]  tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 52/1000] [D loss: 0.868635] [G loss: 0.266890] [FAKE loss: 1.459381]  tensor(0.7658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 53/1000] [D loss: 0.877748] [G loss: 0.260225] [FAKE loss: 1.484857]  tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 54/1000] [D loss: 0.885136] [G loss: 0.253617] [FAKE loss: 1.505511]  tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 55/1000] [D loss: 0.894501] [G loss: 0.247592] [FAKE loss: 1.531622]  tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 56/1000] [D loss: 0.903367] [G loss: 0.240088] [FAKE loss: 1.555457]  tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 57/1000] [D loss: 0.913718] [G loss: 0.233988] [FAKE loss: 1.581797]  tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 58/1000] [D loss: 0.921923] [G loss: 0.228145] [FAKE loss: 1.604641]  tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 59/1000] [D loss: 0.931747] [G loss: 0.221453] [FAKE loss: 1.630671]  tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 60/1000] [D loss: 0.940028] [G loss: 0.215741] [FAKE loss: 1.651734]  tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 61/1000] [D loss: 0.950003] [G loss: 0.210668] [FAKE loss: 1.677318]  tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 62/1000] [D loss: 0.959781] [G loss: 0.205620] [FAKE loss: 1.702190]  tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 63/1000] [D loss: 0.970813] [G loss: 0.199480] [FAKE loss: 1.728982]  tensor(0.8196, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 64/1000] [D loss: 0.977889] [G loss: 0.194812] [FAKE loss: 1.748678]  tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 65/1000] [D loss: 0.987765] [G loss: 0.190342] [FAKE loss: 1.773480]  tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 66/1000] [D loss: 0.998202] [G loss: 0.184824] [FAKE loss: 1.799230]  tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 67/1000] [D loss: 1.007169] [G loss: 0.181131] [FAKE loss: 1.820869]  tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 68/1000] [D loss: 1.015661] [G loss: 0.177114] [FAKE loss: 1.842740]  tensor(0.8384, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 69/1000] [D loss: 1.024206] [G loss: 0.173305] [FAKE loss: 1.863737]  tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 70/1000] [D loss: 1.031767] [G loss: 0.169447] [FAKE loss: 1.883034]  tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 71/1000] [D loss: 1.039273] [G loss: 0.166378] [FAKE loss: 1.901268]  tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 72/1000] [D loss: 1.048354] [G loss: 0.162613] [FAKE loss: 1.922387]  tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 73/1000] [D loss: 1.057418] [G loss: 0.159745] [FAKE loss: 1.943681]  tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 74/1000] [D loss: 1.062315] [G loss: 0.156870] [FAKE loss: 1.956956]  tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 75/1000] [D loss: 1.068635] [G loss: 0.154746] [FAKE loss: 1.972462]  tensor(0.8585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 76/1000] [D loss: 1.076984] [G loss: 0.152061] [FAKE loss: 1.991045]  tensor(0.8594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 77/1000] [D loss: 1.081769] [G loss: 0.150019] [FAKE loss: 2.003450]  tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 78/1000] [D loss: 1.087559] [G loss: 0.147896] [FAKE loss: 2.015893]  tensor(0.8632, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 79/1000] [D loss: 1.089455] [G loss: 0.145322] [FAKE loss: 2.022254]  tensor(0.8647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 80/1000] [D loss: 1.095090] [G loss: 0.144991] [FAKE loss: 2.035239]  tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 81/1000] [D loss: 1.096341] [G loss: 0.143966] [FAKE loss: 2.039401]  tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 82/1000] [D loss: 1.099358] [G loss: 0.142990] [FAKE loss: 2.047230]  tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 83/1000] [D loss: 1.101432] [G loss: 0.142260] [FAKE loss: 2.050960]  tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 84/1000] [D loss: 1.104095] [G loss: 0.141735] [FAKE loss: 2.057484]  tensor(0.8684, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 85/1000] [D loss: 1.106037] [G loss: 0.141380] [FAKE loss: 2.062027]  tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 86/1000] [D loss: 1.102906] [G loss: 0.142391] [FAKE loss: 2.055866]  tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 87/1000] [D loss: 1.102540] [G loss: 0.141218] [FAKE loss: 2.055137]  tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 88/1000] [D loss: 1.102295] [G loss: 0.142052] [FAKE loss: 2.054769]  tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 89/1000] [D loss: 1.099504] [G loss: 0.142816] [FAKE loss: 2.048126]  tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 90/1000] [D loss: 1.096173] [G loss: 0.143109] [FAKE loss: 2.041291]  tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 91/1000] [D loss: 1.094198] [G loss: 0.145088] [FAKE loss: 2.036724]  tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 92/1000] [D loss: 1.089848] [G loss: 0.145856] [FAKE loss: 2.026736]  tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 93/1000] [D loss: 1.083861] [G loss: 0.147057] [FAKE loss: 2.013337]  tensor(0.8637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 94/1000] [D loss: 1.081013] [G loss: 0.149849] [FAKE loss: 2.006777]  tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 95/1000] [D loss: 1.074351] [G loss: 0.150917] [FAKE loss: 1.992170]  tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 96/1000] [D loss: 1.068845] [G loss: 0.153053] [FAKE loss: 1.979403]  tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 97/1000] [D loss: 1.064071] [G loss: 0.155647] [FAKE loss: 1.967410]  tensor(0.8566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 98/1000] [D loss: 1.057733] [G loss: 0.157143] [FAKE loss: 1.953120]  tensor(0.8550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 99/1000] [D loss: 1.050426] [G loss: 0.160232] [FAKE loss: 1.935973]  tensor(0.8523, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 100/1000] [D loss: 1.042074] [G loss: 0.163131] [FAKE loss: 1.917175]  tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 101/1000] [D loss: 1.036970] [G loss: 0.166137] [FAKE loss: 1.903890]  tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 102/1000] [D loss: 1.029505] [G loss: 0.168806] [FAKE loss: 1.885756]  tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 103/1000] [D loss: 1.019245] [G loss: 0.172941] [FAKE loss: 1.862638]  tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 104/1000] [D loss: 1.010866] [G loss: 0.175952] [FAKE loss: 1.843115]  tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 105/1000] [D loss: 1.004334] [G loss: 0.180461] [FAKE loss: 1.826661]  tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 106/1000] [D loss: 0.995224] [G loss: 0.184334] [FAKE loss: 1.805510]  tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 107/1000] [D loss: 0.986830] [G loss: 0.188349] [FAKE loss: 1.784141]  tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 108/1000] [D loss: 0.977642] [G loss: 0.192799] [FAKE loss: 1.762331]  tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 109/1000] [D loss: 0.970894] [G loss: 0.196935] [FAKE loss: 1.744153]  tensor(0.8213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 110/1000] [D loss: 0.961301] [G loss: 0.201091] [FAKE loss: 1.721488]  tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 111/1000] [D loss: 0.952103] [G loss: 0.205768] [FAKE loss: 1.699063]  tensor(0.8151, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 112/1000] [D loss: 0.943454] [G loss: 0.211584] [FAKE loss: 1.676781]  tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 113/1000] [D loss: 0.936630] [G loss: 0.216763] [FAKE loss: 1.658605]  tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 114/1000] [D loss: 0.927233] [G loss: 0.221844] [FAKE loss: 1.635092]  tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 115/1000] [D loss: 0.919275] [G loss: 0.226573] [FAKE loss: 1.615037]  tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 116/1000] [D loss: 0.910063] [G loss: 0.231115] [FAKE loss: 1.591078]  tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 117/1000] [D loss: 0.901321] [G loss: 0.236599] [FAKE loss: 1.569507]  tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 118/1000] [D loss: 0.893892] [G loss: 0.241985] [FAKE loss: 1.548675]  tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 119/1000] [D loss: 0.886816] [G loss: 0.248559] [FAKE loss: 1.529908]  tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 120/1000] [D loss: 0.877432] [G loss: 0.254309] [FAKE loss: 1.506143]  tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 121/1000] [D loss: 0.870527] [G loss: 0.259764] [FAKE loss: 1.486779]  tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 122/1000] [D loss: 0.863724] [G loss: 0.265713] [FAKE loss: 1.466992]  tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 123/1000] [D loss: 0.856239] [G loss: 0.272025] [FAKE loss: 1.446334]  tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 124/1000] [D loss: 0.849834] [G loss: 0.277294] [FAKE loss: 1.428024]  tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 125/1000] [D loss: 0.843039] [G loss: 0.284041] [FAKE loss: 1.409027]  tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 126/1000] [D loss: 0.836892] [G loss: 0.289731] [FAKE loss: 1.390560]  tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 127/1000] [D loss: 0.829976] [G loss: 0.295710] [FAKE loss: 1.371006]  tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 128/1000] [D loss: 0.824150] [G loss: 0.302452] [FAKE loss: 1.353786]  tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 129/1000] [D loss: 0.818497] [G loss: 0.308860] [FAKE loss: 1.336820]  tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 130/1000] [D loss: 0.813539] [G loss: 0.314149] [FAKE loss: 1.320122]  tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 131/1000] [D loss: 0.806161] [G loss: 0.321020] [FAKE loss: 1.300930]  tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 132/1000] [D loss: 0.802615] [G loss: 0.326333] [FAKE loss: 1.286180]  tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 133/1000] [D loss: 0.796296] [G loss: 0.332486] [FAKE loss: 1.269105]  tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 134/1000] [D loss: 0.792286] [G loss: 0.338818] [FAKE loss: 1.254342]  tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 135/1000] [D loss: 0.787323] [G loss: 0.345230] [FAKE loss: 1.238765]  tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 136/1000] [D loss: 0.782583] [G loss: 0.350883] [FAKE loss: 1.223683]  tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 137/1000] [D loss: 0.779233] [G loss: 0.357011] [FAKE loss: 1.210725]  tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 138/1000] [D loss: 0.774992] [G loss: 0.362753] [FAKE loss: 1.196696]  tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 139/1000] [D loss: 0.770112] [G loss: 0.368565] [FAKE loss: 1.181301]  tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 140/1000] [D loss: 0.766860] [G loss: 0.373919] [FAKE loss: 1.168892]  tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 141/1000] [D loss: 0.764093] [G loss: 0.379835] [FAKE loss: 1.156918]  tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 142/1000] [D loss: 0.760252] [G loss: 0.385625] [FAKE loss: 1.144117]  tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 143/1000] [D loss: 0.756545] [G loss: 0.391023] [FAKE loss: 1.130871]  tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 144/1000] [D loss: 0.753981] [G loss: 0.396894] [FAKE loss: 1.121394]  tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 145/1000] [D loss: 0.751530] [G loss: 0.402669] [FAKE loss: 1.110612]  tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 146/1000] [D loss: 0.748735] [G loss: 0.406924] [FAKE loss: 1.099185]  tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 147/1000] [D loss: 0.745624] [G loss: 0.411935] [FAKE loss: 1.088528]  tensor(0.6629, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 148/1000] [D loss: 0.744203] [G loss: 0.416943] [FAKE loss: 1.079798]  tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 149/1000] [D loss: 0.742400] [G loss: 0.422553] [FAKE loss: 1.070337]  tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 150/1000] [D loss: 0.739910] [G loss: 0.426760] [FAKE loss: 1.061558]  tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 151/1000] [D loss: 0.738322] [G loss: 0.430699] [FAKE loss: 1.053248]  tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 152/1000] [D loss: 0.735456] [G loss: 0.435463] [FAKE loss: 1.043184]  tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 153/1000] [D loss: 0.734425] [G loss: 0.439476] [FAKE loss: 1.036443]  tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 154/1000] [D loss: 0.733190] [G loss: 0.443602] [FAKE loss: 1.029462]  tensor(0.6423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 155/1000] [D loss: 0.731760] [G loss: 0.446954] [FAKE loss: 1.022079]  tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 156/1000] [D loss: 0.730697] [G loss: 0.450910] [FAKE loss: 1.015345]  tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 157/1000] [D loss: 0.729742] [G loss: 0.454691] [FAKE loss: 1.009718]  tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 158/1000] [D loss: 0.728460] [G loss: 0.457866] [FAKE loss: 1.003190]  tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 159/1000] [D loss: 0.727648] [G loss: 0.461988] [FAKE loss: 0.997592]  tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 160/1000] [D loss: 0.727224] [G loss: 0.464828] [FAKE loss: 0.993174]  tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 161/1000] [D loss: 0.725523] [G loss: 0.467228] [FAKE loss: 0.986295]  tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 162/1000] [D loss: 0.725115] [G loss: 0.470547] [FAKE loss: 0.982471]  tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 163/1000] [D loss: 0.724659] [G loss: 0.472893] [FAKE loss: 0.978189]  tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 164/1000] [D loss: 0.724347] [G loss: 0.475382] [FAKE loss: 0.974432]  tensor(0.6220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 165/1000] [D loss: 0.723701] [G loss: 0.477759] [FAKE loss: 0.969979]  tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 166/1000] [D loss: 0.723628] [G loss: 0.479600] [FAKE loss: 0.967464]  tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 167/1000] [D loss: 0.722754] [G loss: 0.481657] [FAKE loss: 0.963406]  tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 168/1000] [D loss: 0.722870] [G loss: 0.483307] [FAKE loss: 0.960239]  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 169/1000] [D loss: 0.722560] [G loss: 0.485203] [FAKE loss: 0.958030]  tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 170/1000] [D loss: 0.722869] [G loss: 0.486680] [FAKE loss: 0.956482]  tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 171/1000] [D loss: 0.722296] [G loss: 0.487603] [FAKE loss: 0.953526]  tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 172/1000] [D loss: 0.722487] [G loss: 0.488815] [FAKE loss: 0.952095]  tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 173/1000] [D loss: 0.722115] [G loss: 0.489479] [FAKE loss: 0.949901]  tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 174/1000] [D loss: 0.722885] [G loss: 0.491348] [FAKE loss: 0.949128]  tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 175/1000] [D loss: 0.722581] [G loss: 0.491435] [FAKE loss: 0.947563]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 176/1000] [D loss: 0.722783] [G loss: 0.491314] [FAKE loss: 0.946820]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 177/1000] [D loss: 0.722957] [G loss: 0.492256] [FAKE loss: 0.946138]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 178/1000] [D loss: 0.723237] [G loss: 0.492188] [FAKE loss: 0.946324]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 179/1000] [D loss: 0.723958] [G loss: 0.492153] [FAKE loss: 0.946664]  tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 180/1000] [D loss: 0.723697] [G loss: 0.492224] [FAKE loss: 0.945829]  tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 181/1000] [D loss: 0.724749] [G loss: 0.491770] [FAKE loss: 0.947290]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 182/1000] [D loss: 0.724729] [G loss: 0.491715] [FAKE loss: 0.947197]  tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 183/1000] [D loss: 0.725095] [G loss: 0.490797] [FAKE loss: 0.947905]  tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 184/1000] [D loss: 0.725394] [G loss: 0.490160] [FAKE loss: 0.949062]  tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 185/1000] [D loss: 0.726352] [G loss: 0.489310] [FAKE loss: 0.950618]  tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 186/1000] [D loss: 0.727337] [G loss: 0.488287] [FAKE loss: 0.952279]  tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 187/1000] [D loss: 0.727941] [G loss: 0.487148] [FAKE loss: 0.954692]  tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 188/1000] [D loss: 0.728917] [G loss: 0.485653] [FAKE loss: 0.956841]  tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 189/1000] [D loss: 0.729345] [G loss: 0.483999] [FAKE loss: 0.959251]  tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 190/1000] [D loss: 0.729726] [G loss: 0.482491] [FAKE loss: 0.960735]  tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 191/1000] [D loss: 0.730817] [G loss: 0.481310] [FAKE loss: 0.963884]  tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 192/1000] [D loss: 0.732000] [G loss: 0.479007] [FAKE loss: 0.967789]  tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 193/1000] [D loss: 0.732937] [G loss: 0.477266] [FAKE loss: 0.970197]  tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 194/1000] [D loss: 0.734239] [G loss: 0.475036] [FAKE loss: 0.974477]  tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 195/1000] [D loss: 0.734848] [G loss: 0.473001] [FAKE loss: 0.977101]  tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 196/1000] [D loss: 0.736716] [G loss: 0.470153] [FAKE loss: 0.981796]  tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 197/1000] [D loss: 0.737478] [G loss: 0.468015] [FAKE loss: 0.985858]  tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 198/1000] [D loss: 0.738373] [G loss: 0.465359] [FAKE loss: 0.989748]  tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 199/1000] [D loss: 0.739953] [G loss: 0.462617] [FAKE loss: 0.994230]  tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 200/1000] [D loss: 0.741383] [G loss: 0.459916] [FAKE loss: 0.999230]  tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 201/1000] [D loss: 0.742463] [G loss: 0.457804] [FAKE loss: 1.003659]  tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 202/1000] [D loss: 0.744065] [G loss: 0.454349] [FAKE loss: 1.009305]  tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 203/1000] [D loss: 0.745208] [G loss: 0.451404] [FAKE loss: 1.014263]  tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 204/1000] [D loss: 0.746905] [G loss: 0.448377] [FAKE loss: 1.019602]  tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 205/1000] [D loss: 0.748230] [G loss: 0.445108] [FAKE loss: 1.024823]  tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 206/1000] [D loss: 0.750441] [G loss: 0.441286] [FAKE loss: 1.031750]  tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 207/1000] [D loss: 0.752228] [G loss: 0.438682] [FAKE loss: 1.038075]  tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 208/1000] [D loss: 0.753833] [G loss: 0.435125] [FAKE loss: 1.044185]  tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 209/1000] [D loss: 0.755713] [G loss: 0.431881] [FAKE loss: 1.050543]  tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 210/1000] [D loss: 0.757959] [G loss: 0.427842] [FAKE loss: 1.057682]  tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 211/1000] [D loss: 0.759937] [G loss: 0.423868] [FAKE loss: 1.064690]  tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 212/1000] [D loss: 0.761506] [G loss: 0.420372] [FAKE loss: 1.071212]  tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 213/1000] [D loss: 0.763509] [G loss: 0.416461] [FAKE loss: 1.078048]  tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 214/1000] [D loss: 0.766016] [G loss: 0.412897] [FAKE loss: 1.086288]  tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 215/1000] [D loss: 0.767786] [G loss: 0.408744] [FAKE loss: 1.093127]  tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 216/1000] [D loss: 0.770617] [G loss: 0.405027] [FAKE loss: 1.101419]  tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 217/1000] [D loss: 0.772715] [G loss: 0.400722] [FAKE loss: 1.109324]  tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 218/1000] [D loss: 0.775159] [G loss: 0.396698] [FAKE loss: 1.117517]  tensor(0.6726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 219/1000] [D loss: 0.778015] [G loss: 0.392983] [FAKE loss: 1.126469]  tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 220/1000] [D loss: 0.780423] [G loss: 0.388742] [FAKE loss: 1.135648]  tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 221/1000] [D loss: 0.783749] [G loss: 0.384032] [FAKE loss: 1.145450]  tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 222/1000] [D loss: 0.786540] [G loss: 0.380011] [FAKE loss: 1.154268]  tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 223/1000] [D loss: 0.788973] [G loss: 0.375800] [FAKE loss: 1.163286]  tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 224/1000] [D loss: 0.792205] [G loss: 0.371357] [FAKE loss: 1.172842]  tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 225/1000] [D loss: 0.795605] [G loss: 0.366937] [FAKE loss: 1.183073]  tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 226/1000] [D loss: 0.798247] [G loss: 0.362273] [FAKE loss: 1.192544]  tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 227/1000] [D loss: 0.802220] [G loss: 0.358262] [FAKE loss: 1.204322]  tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 228/1000] [D loss: 0.805100] [G loss: 0.353687] [FAKE loss: 1.213806]  tensor(0.7022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 229/1000] [D loss: 0.808739] [G loss: 0.349404] [FAKE loss: 1.224452]  tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 230/1000] [D loss: 0.812473] [G loss: 0.344956] [FAKE loss: 1.235155]  tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 231/1000] [D loss: 0.816157] [G loss: 0.340372] [FAKE loss: 1.246584]  tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 232/1000] [D loss: 0.820496] [G loss: 0.335485] [FAKE loss: 1.259095]  tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 233/1000] [D loss: 0.823802] [G loss: 0.330754] [FAKE loss: 1.269690]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 234/1000] [D loss: 0.827496] [G loss: 0.326659] [FAKE loss: 1.280827]  tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 235/1000] [D loss: 0.831836] [G loss: 0.322438] [FAKE loss: 1.293058]  tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 236/1000] [D loss: 0.835769] [G loss: 0.317582] [FAKE loss: 1.304895]  tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 237/1000] [D loss: 0.840003] [G loss: 0.313161] [FAKE loss: 1.317042]  tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 238/1000] [D loss: 0.843761] [G loss: 0.308132] [FAKE loss: 1.328507]  tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 239/1000] [D loss: 0.849146] [G loss: 0.303858] [FAKE loss: 1.343428]  tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 240/1000] [D loss: 0.852970] [G loss: 0.299565] [FAKE loss: 1.354680]  tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 241/1000] [D loss: 0.857414] [G loss: 0.295232] [FAKE loss: 1.367428]  tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 242/1000] [D loss: 0.862773] [G loss: 0.290614] [FAKE loss: 1.381432]  tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 243/1000] [D loss: 0.868035] [G loss: 0.285825] [FAKE loss: 1.395803]  tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 244/1000] [D loss: 0.872566] [G loss: 0.281883] [FAKE loss: 1.408767]  tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 245/1000] [D loss: 0.878074] [G loss: 0.277077] [FAKE loss: 1.423648]  tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 246/1000] [D loss: 0.882926] [G loss: 0.272800] [FAKE loss: 1.437208]  tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 247/1000] [D loss: 0.888553] [G loss: 0.268549] [FAKE loss: 1.452016]  tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 248/1000] [D loss: 0.893335] [G loss: 0.264250] [FAKE loss: 1.465028]  tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 249/1000] [D loss: 0.898688] [G loss: 0.260311] [FAKE loss: 1.479630]  tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 250/1000] [D loss: 0.904207] [G loss: 0.256293] [FAKE loss: 1.494359]  tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 251/1000] [D loss: 0.908703] [G loss: 0.252341] [FAKE loss: 1.506462]  tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 252/1000] [D loss: 0.913321] [G loss: 0.248753] [FAKE loss: 1.519275]  tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 253/1000] [D loss: 0.918996] [G loss: 0.244977] [FAKE loss: 1.534163]  tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 254/1000] [D loss: 0.923498] [G loss: 0.241541] [FAKE loss: 1.546420]  tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 255/1000] [D loss: 0.928216] [G loss: 0.237627] [FAKE loss: 1.559692]  tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 256/1000] [D loss: 0.933405] [G loss: 0.234608] [FAKE loss: 1.573132]  tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 257/1000] [D loss: 0.937883] [G loss: 0.231271] [FAKE loss: 1.585420]  tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 258/1000] [D loss: 0.942059] [G loss: 0.228441] [FAKE loss: 1.596975]  tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 259/1000] [D loss: 0.947710] [G loss: 0.224774] [FAKE loss: 1.611459]  tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 260/1000] [D loss: 0.951690] [G loss: 0.222064] [FAKE loss: 1.621791]  tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 261/1000] [D loss: 0.956235] [G loss: 0.218811] [FAKE loss: 1.634540]  tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 262/1000] [D loss: 0.960146] [G loss: 0.216148] [FAKE loss: 1.645854]  tensor(0.8058, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 263/1000] [D loss: 0.964228] [G loss: 0.213351] [FAKE loss: 1.655885]  tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 264/1000] [D loss: 0.968277] [G loss: 0.211451] [FAKE loss: 1.666426]  tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 265/1000] [D loss: 0.972500] [G loss: 0.208566] [FAKE loss: 1.678252]  tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 266/1000] [D loss: 0.978086] [G loss: 0.206682] [FAKE loss: 1.691496]  tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 267/1000] [D loss: 0.978175] [G loss: 0.204223] [FAKE loss: 1.694756]  tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 268/1000] [D loss: 0.983228] [G loss: 0.201477] [FAKE loss: 1.706844]  tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 269/1000] [D loss: 0.986511] [G loss: 0.199781] [FAKE loss: 1.716196]  tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 270/1000] [D loss: 0.990087] [G loss: 0.198250] [FAKE loss: 1.725365]  tensor(0.8206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 271/1000] [D loss: 0.992842] [G loss: 0.196456] [FAKE loss: 1.733906]  tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 272/1000] [D loss: 0.996190] [G loss: 0.195100] [FAKE loss: 1.742373]  tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 273/1000] [D loss: 0.998609] [G loss: 0.193382] [FAKE loss: 1.749084]  tensor(0.8244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 274/1000] [D loss: 1.000209] [G loss: 0.191451] [FAKE loss: 1.754184]  tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 275/1000] [D loss: 1.001932] [G loss: 0.190782] [FAKE loss: 1.759706]  tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 276/1000] [D loss: 1.005535] [G loss: 0.189430] [FAKE loss: 1.768540]  tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 277/1000] [D loss: 1.005614] [G loss: 0.187930] [FAKE loss: 1.770551]  tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 278/1000] [D loss: 1.008482] [G loss: 0.187144] [FAKE loss: 1.777373]  tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 279/1000] [D loss: 1.010114] [G loss: 0.186822] [FAKE loss: 1.781812]  tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 280/1000] [D loss: 1.010558] [G loss: 0.186191] [FAKE loss: 1.784804]  tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 281/1000] [D loss: 1.012631] [G loss: 0.184970] [FAKE loss: 1.790166]  tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 282/1000] [D loss: 1.012636] [G loss: 0.184448] [FAKE loss: 1.791084]  tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 283/1000] [D loss: 1.013124] [G loss: 0.183650] [FAKE loss: 1.793480]  tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 284/1000] [D loss: 1.013005] [G loss: 0.183601] [FAKE loss: 1.793736]  tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 285/1000] [D loss: 1.012615] [G loss: 0.184208] [FAKE loss: 1.793800]  tensor(0.8324, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 286/1000] [D loss: 1.012786] [G loss: 0.183403] [FAKE loss: 1.794688]  tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 287/1000] [D loss: 1.011971] [G loss: 0.183621] [FAKE loss: 1.794085]  tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 288/1000] [D loss: 1.010384] [G loss: 0.184521] [FAKE loss: 1.791467]  tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 289/1000] [D loss: 1.009007] [G loss: 0.184439] [FAKE loss: 1.789593]  tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 290/1000] [D loss: 1.007606] [G loss: 0.185003] [FAKE loss: 1.786761]  tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 291/1000] [D loss: 1.006850] [G loss: 0.186116] [FAKE loss: 1.785136]  tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 292/1000] [D loss: 1.004406] [G loss: 0.186659] [FAKE loss: 1.780745]  tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 293/1000] [D loss: 1.002834] [G loss: 0.186944] [FAKE loss: 1.777686]  tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 294/1000] [D loss: 1.000191] [G loss: 0.187968] [FAKE loss: 1.772455]  tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 295/1000] [D loss: 0.997386] [G loss: 0.188966] [FAKE loss: 1.766157]  tensor(0.8281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 296/1000] [D loss: 0.995013] [G loss: 0.190000] [FAKE loss: 1.761709]  tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 297/1000] [D loss: 0.991639] [G loss: 0.191455] [FAKE loss: 1.754121]  tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 298/1000] [D loss: 0.988208] [G loss: 0.192882] [FAKE loss: 1.746974]  tensor(0.8246, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 299/1000] [D loss: 0.986053] [G loss: 0.194070] [FAKE loss: 1.741854]  tensor(0.8234, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 300/1000] [D loss: 0.981273] [G loss: 0.196107] [FAKE loss: 1.731804]  tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 301/1000] [D loss: 0.977655] [G loss: 0.198017] [FAKE loss: 1.724155]  tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 302/1000] [D loss: 0.974927] [G loss: 0.200422] [FAKE loss: 1.717419]  tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 303/1000] [D loss: 0.970546] [G loss: 0.201895] [FAKE loss: 1.707684]  tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 304/1000] [D loss: 0.965516] [G loss: 0.204187] [FAKE loss: 1.696947]  tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 305/1000] [D loss: 0.961226] [G loss: 0.206211] [FAKE loss: 1.686785]  tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 306/1000] [D loss: 0.956561] [G loss: 0.208163] [FAKE loss: 1.676612]  tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 307/1000] [D loss: 0.951875] [G loss: 0.211209] [FAKE loss: 1.665532]  tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 308/1000] [D loss: 0.947174] [G loss: 0.213371] [FAKE loss: 1.654855]  tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 309/1000] [D loss: 0.943291] [G loss: 0.216115] [FAKE loss: 1.645411]  tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 310/1000] [D loss: 0.937132] [G loss: 0.218970] [FAKE loss: 1.631459]  tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 311/1000] [D loss: 0.932408] [G loss: 0.221729] [FAKE loss: 1.620515]  tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 312/1000] [D loss: 0.927648] [G loss: 0.224175] [FAKE loss: 1.609006]  tensor(0.7990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 313/1000] [D loss: 0.921815] [G loss: 0.227896] [FAKE loss: 1.595527]  tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 314/1000] [D loss: 0.917233] [G loss: 0.230767] [FAKE loss: 1.584629]  tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 315/1000] [D loss: 0.911430] [G loss: 0.234020] [FAKE loss: 1.570764]  tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 316/1000] [D loss: 0.906861] [G loss: 0.237555] [FAKE loss: 1.559621]  tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 317/1000] [D loss: 0.900360] [G loss: 0.240975] [FAKE loss: 1.544429]  tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 318/1000] [D loss: 0.895775] [G loss: 0.244606] [FAKE loss: 1.533144]  tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 319/1000] [D loss: 0.890280] [G loss: 0.248323] [FAKE loss: 1.519664]  tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 320/1000] [D loss: 0.885404] [G loss: 0.251537] [FAKE loss: 1.507146]  tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 321/1000] [D loss: 0.879788] [G loss: 0.254726] [FAKE loss: 1.493502]  tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 322/1000] [D loss: 0.874130] [G loss: 0.258825] [FAKE loss: 1.479560]  tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 323/1000] [D loss: 0.869289] [G loss: 0.262636] [FAKE loss: 1.467408]  tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 324/1000] [D loss: 0.863950] [G loss: 0.266759] [FAKE loss: 1.454093]  tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 325/1000] [D loss: 0.858855] [G loss: 0.271019] [FAKE loss: 1.440953]  tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 326/1000] [D loss: 0.853755] [G loss: 0.275265] [FAKE loss: 1.427900]  tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 327/1000] [D loss: 0.848167] [G loss: 0.279562] [FAKE loss: 1.413784]  tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 328/1000] [D loss: 0.842578] [G loss: 0.283753] [FAKE loss: 1.399822]  tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 329/1000] [D loss: 0.837794] [G loss: 0.287887] [FAKE loss: 1.387013]  tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 330/1000] [D loss: 0.832664] [G loss: 0.292598] [FAKE loss: 1.373705]  tensor(0.7464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 331/1000] [D loss: 0.827399] [G loss: 0.297232] [FAKE loss: 1.360090]  tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 332/1000] [D loss: 0.822408] [G loss: 0.301123] [FAKE loss: 1.347080]  tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 333/1000] [D loss: 0.816969] [G loss: 0.305949] [FAKE loss: 1.333083]  tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 334/1000] [D loss: 0.812930] [G loss: 0.310641] [FAKE loss: 1.321478]  tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 335/1000] [D loss: 0.808032] [G loss: 0.315599] [FAKE loss: 1.308540]  tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 336/1000] [D loss: 0.803266] [G loss: 0.320054] [FAKE loss: 1.295591]  tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 337/1000] [D loss: 0.798442] [G loss: 0.324620] [FAKE loss: 1.282824]  tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 338/1000] [D loss: 0.794428] [G loss: 0.329523] [FAKE loss: 1.271226]  tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 339/1000] [D loss: 0.789928] [G loss: 0.334490] [FAKE loss: 1.258833]  tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 340/1000] [D loss: 0.785722] [G loss: 0.339245] [FAKE loss: 1.247019]  tensor(0.7122, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 341/1000] [D loss: 0.781461] [G loss: 0.343761] [FAKE loss: 1.234961]  tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 342/1000] [D loss: 0.776875] [G loss: 0.349060] [FAKE loss: 1.222392]  tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 343/1000] [D loss: 0.773189] [G loss: 0.353759] [FAKE loss: 1.211528]  tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 344/1000] [D loss: 0.769212] [G loss: 0.358620] [FAKE loss: 1.200143]  tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 345/1000] [D loss: 0.765203] [G loss: 0.363154] [FAKE loss: 1.188650]  tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 346/1000] [D loss: 0.761184] [G loss: 0.368217] [FAKE loss: 1.177182]  tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 347/1000] [D loss: 0.757867] [G loss: 0.373242] [FAKE loss: 1.166922]  tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 348/1000] [D loss: 0.754153] [G loss: 0.378035] [FAKE loss: 1.155972]  tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 349/1000] [D loss: 0.750273] [G loss: 0.382913] [FAKE loss: 1.144842]  tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 350/1000] [D loss: 0.747166] [G loss: 0.387945] [FAKE loss: 1.135298]  tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 351/1000] [D loss: 0.743863] [G loss: 0.392430] [FAKE loss: 1.125194]  tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 352/1000] [D loss: 0.740736] [G loss: 0.397434] [FAKE loss: 1.115480]  tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 353/1000] [D loss: 0.737485] [G loss: 0.401987] [FAKE loss: 1.105579]  tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 354/1000] [D loss: 0.734579] [G loss: 0.406594] [FAKE loss: 1.096331]  tensor(0.6659, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 355/1000] [D loss: 0.731795] [G loss: 0.411217] [FAKE loss: 1.087373]  tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 356/1000] [D loss: 0.728956] [G loss: 0.415825] [FAKE loss: 1.078509]  tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 357/1000] [D loss: 0.726397] [G loss: 0.420294] [FAKE loss: 1.070024]  tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 358/1000] [D loss: 0.723674] [G loss: 0.424596] [FAKE loss: 1.061475]  tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 359/1000] [D loss: 0.721204] [G loss: 0.429063] [FAKE loss: 1.053298]  tensor(0.6512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 360/1000] [D loss: 0.718642] [G loss: 0.433367] [FAKE loss: 1.045253]  tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 361/1000] [D loss: 0.716431] [G loss: 0.437505] [FAKE loss: 1.037743]  tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 362/1000] [D loss: 0.714308] [G loss: 0.441578] [FAKE loss: 1.030448]  tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 363/1000] [D loss: 0.712218] [G loss: 0.445562] [FAKE loss: 1.023442]  tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 364/1000] [D loss: 0.710151] [G loss: 0.449038] [FAKE loss: 1.016528]  tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 365/1000] [D loss: 0.708286] [G loss: 0.452928] [FAKE loss: 1.010091]  tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 366/1000] [D loss: 0.706411] [G loss: 0.456775] [FAKE loss: 1.003760]  tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 367/1000] [D loss: 0.704702] [G loss: 0.460057] [FAKE loss: 0.997888]  tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 368/1000] [D loss: 0.703135] [G loss: 0.463460] [FAKE loss: 0.992148]  tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 369/1000] [D loss: 0.701398] [G loss: 0.466660] [FAKE loss: 0.986511]  tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 370/1000] [D loss: 0.700051] [G loss: 0.469631] [FAKE loss: 0.981558]  tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 371/1000] [D loss: 0.698652] [G loss: 0.472817] [FAKE loss: 0.976556]  tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 372/1000] [D loss: 0.697472] [G loss: 0.475305] [FAKE loss: 0.972220]  tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 373/1000] [D loss: 0.696177] [G loss: 0.478151] [FAKE loss: 0.967786]  tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 374/1000] [D loss: 0.695002] [G loss: 0.480527] [FAKE loss: 0.964014]  tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 375/1000] [D loss: 0.694069] [G loss: 0.482753] [FAKE loss: 0.960426]  tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 376/1000] [D loss: 0.693351] [G loss: 0.484521] [FAKE loss: 0.957452]  tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 377/1000] [D loss: 0.692384] [G loss: 0.486664] [FAKE loss: 0.954307]  tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 378/1000] [D loss: 0.691520] [G loss: 0.488244] [FAKE loss: 0.951356]  tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 379/1000] [D loss: 0.690982] [G loss: 0.489791] [FAKE loss: 0.949417]  tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 380/1000] [D loss: 0.690300] [G loss: 0.490984] [FAKE loss: 0.947352]  tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 381/1000] [D loss: 0.689840] [G loss: 0.492175] [FAKE loss: 0.945552]  tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 382/1000] [D loss: 0.689213] [G loss: 0.492701] [FAKE loss: 0.943908]  tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 383/1000] [D loss: 0.689075] [G loss: 0.493650] [FAKE loss: 0.943385]  tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 384/1000] [D loss: 0.688667] [G loss: 0.493882] [FAKE loss: 0.942582]  tensor(0.6102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 385/1000] [D loss: 0.688877] [G loss: 0.494214] [FAKE loss: 0.942786]  tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 386/1000] [D loss: 0.688703] [G loss: 0.493718] [FAKE loss: 0.942677]  tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 387/1000] [D loss: 0.688783] [G loss: 0.493858] [FAKE loss: 0.943216]  tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 388/1000] [D loss: 0.688735] [G loss: 0.492877] [FAKE loss: 0.943715]  tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 389/1000] [D loss: 0.689342] [G loss: 0.492324] [FAKE loss: 0.945595]  tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 390/1000] [D loss: 0.689225] [G loss: 0.491321] [FAKE loss: 0.946585]  tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 391/1000] [D loss: 0.690051] [G loss: 0.490153] [FAKE loss: 0.949265]  tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 392/1000] [D loss: 0.690073] [G loss: 0.488916] [FAKE loss: 0.950964]  tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 393/1000] [D loss: 0.691016] [G loss: 0.486535] [FAKE loss: 0.954307]  tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 394/1000] [D loss: 0.691920] [G loss: 0.485056] [FAKE loss: 0.957504]  tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 395/1000] [D loss: 0.692430] [G loss: 0.482656] [FAKE loss: 0.960674]  tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 396/1000] [D loss: 0.693455] [G loss: 0.479675] [FAKE loss: 0.964690]  tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 397/1000] [D loss: 0.694829] [G loss: 0.477339] [FAKE loss: 0.969826]  tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 398/1000] [D loss: 0.696039] [G loss: 0.474510] [FAKE loss: 0.974828]  tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 399/1000] [D loss: 0.697154] [G loss: 0.470639] [FAKE loss: 0.979833]  tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 400/1000] [D loss: 0.698565] [G loss: 0.467782] [FAKE loss: 0.985322]  tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 401/1000] [D loss: 0.700377] [G loss: 0.463646] [FAKE loss: 0.991905]  tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 402/1000] [D loss: 0.701800] [G loss: 0.460370] [FAKE loss: 0.998121]  tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 403/1000] [D loss: 0.703861] [G loss: 0.456166] [FAKE loss: 1.005575]  tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 404/1000] [D loss: 0.705891] [G loss: 0.451463] [FAKE loss: 1.012988]  tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 405/1000] [D loss: 0.708343] [G loss: 0.446924] [FAKE loss: 1.021403]  tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 406/1000] [D loss: 0.710327] [G loss: 0.442281] [FAKE loss: 1.029345]  tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 407/1000] [D loss: 0.712576] [G loss: 0.437455] [FAKE loss: 1.038074]  tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 408/1000] [D loss: 0.715692] [G loss: 0.432233] [FAKE loss: 1.048072]  tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 409/1000] [D loss: 0.718051] [G loss: 0.427318] [FAKE loss: 1.056963]  tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 410/1000] [D loss: 0.721079] [G loss: 0.421679] [FAKE loss: 1.067674]  tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 411/1000] [D loss: 0.724415] [G loss: 0.415666] [FAKE loss: 1.078735]  tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 412/1000] [D loss: 0.727677] [G loss: 0.409876] [FAKE loss: 1.089871]  tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 413/1000] [D loss: 0.731352] [G loss: 0.404217] [FAKE loss: 1.101722]  tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 414/1000] [D loss: 0.735064] [G loss: 0.398068] [FAKE loss: 1.113913]  tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 415/1000] [D loss: 0.738780] [G loss: 0.392195] [FAKE loss: 1.126162]  tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 416/1000] [D loss: 0.743055] [G loss: 0.385769] [FAKE loss: 1.139513]  tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 417/1000] [D loss: 0.746690] [G loss: 0.380030] [FAKE loss: 1.152168]  tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 418/1000] [D loss: 0.751287] [G loss: 0.373519] [FAKE loss: 1.166247]  tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 419/1000] [D loss: 0.755607] [G loss: 0.367439] [FAKE loss: 1.180172]  tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 420/1000] [D loss: 0.760168] [G loss: 0.361086] [FAKE loss: 1.194119]  tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 421/1000] [D loss: 0.764909] [G loss: 0.355022] [FAKE loss: 1.209050]  tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 422/1000] [D loss: 0.769606] [G loss: 0.348540] [FAKE loss: 1.223611]  tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 423/1000] [D loss: 0.774450] [G loss: 0.342451] [FAKE loss: 1.238736]  tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 424/1000] [D loss: 0.779537] [G loss: 0.336161] [FAKE loss: 1.253925]  tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 425/1000] [D loss: 0.785242] [G loss: 0.329910] [FAKE loss: 1.270636]  tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 426/1000] [D loss: 0.790682] [G loss: 0.323534] [FAKE loss: 1.286991]  tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 427/1000] [D loss: 0.796186] [G loss: 0.317258] [FAKE loss: 1.303080]  tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 428/1000] [D loss: 0.801843] [G loss: 0.311015] [FAKE loss: 1.319904]  tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 429/1000] [D loss: 0.808220] [G loss: 0.304741] [FAKE loss: 1.337816]  tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 430/1000] [D loss: 0.814338] [G loss: 0.298688] [FAKE loss: 1.355260]  tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 431/1000] [D loss: 0.820625] [G loss: 0.292382] [FAKE loss: 1.373057]  tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 432/1000] [D loss: 0.827118] [G loss: 0.286450] [FAKE loss: 1.391076]  tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 433/1000] [D loss: 0.833868] [G loss: 0.280045] [FAKE loss: 1.409839]  tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 434/1000] [D loss: 0.840742] [G loss: 0.274295] [FAKE loss: 1.428349]  tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 435/1000] [D loss: 0.847738] [G loss: 0.268381] [FAKE loss: 1.447391]  tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 436/1000] [D loss: 0.854627] [G loss: 0.262917] [FAKE loss: 1.466111]  tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 437/1000] [D loss: 0.861967] [G loss: 0.256823] [FAKE loss: 1.485889]  tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 438/1000] [D loss: 0.869179] [G loss: 0.251323] [FAKE loss: 1.504798]  tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 439/1000] [D loss: 0.876261] [G loss: 0.245744] [FAKE loss: 1.523731]  tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 440/1000] [D loss: 0.884262] [G loss: 0.240188] [FAKE loss: 1.544306]  tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 441/1000] [D loss: 0.891744] [G loss: 0.235188] [FAKE loss: 1.563871]  tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 442/1000] [D loss: 0.899578] [G loss: 0.229961] [FAKE loss: 1.584048]  tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 443/1000] [D loss: 0.907111] [G loss: 0.224951] [FAKE loss: 1.603234]  tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 444/1000] [D loss: 0.914967] [G loss: 0.220087] [FAKE loss: 1.623317]  tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 445/1000] [D loss: 0.922476] [G loss: 0.215536] [FAKE loss: 1.642592]  tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 446/1000] [D loss: 0.929910] [G loss: 0.210776] [FAKE loss: 1.661417]  tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 447/1000] [D loss: 0.937846] [G loss: 0.206095] [FAKE loss: 1.681387]  tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 448/1000] [D loss: 0.945561] [G loss: 0.201888] [FAKE loss: 1.700555]  tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 449/1000] [D loss: 0.953436] [G loss: 0.197751] [FAKE loss: 1.719868]  tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 450/1000] [D loss: 0.960700] [G loss: 0.193674] [FAKE loss: 1.738029]  tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 451/1000] [D loss: 0.967979] [G loss: 0.189696] [FAKE loss: 1.756179]  tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 452/1000] [D loss: 0.975359] [G loss: 0.186028] [FAKE loss: 1.774488]  tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 453/1000] [D loss: 0.982778] [G loss: 0.182405] [FAKE loss: 1.792413]  tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 454/1000] [D loss: 0.989892] [G loss: 0.179324] [FAKE loss: 1.809714]  tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 455/1000] [D loss: 0.996384] [G loss: 0.175789] [FAKE loss: 1.825693]  tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 456/1000] [D loss: 1.003347] [G loss: 0.172945] [FAKE loss: 1.842674]  tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 457/1000] [D loss: 1.009919] [G loss: 0.169904] [FAKE loss: 1.858636]  tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 458/1000] [D loss: 1.015693] [G loss: 0.167142] [FAKE loss: 1.872772]  tensor(0.8461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 459/1000] [D loss: 1.021857] [G loss: 0.164593] [FAKE loss: 1.887626]  tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 460/1000] [D loss: 1.027537] [G loss: 0.161975] [FAKE loss: 1.901434]  tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 461/1000] [D loss: 1.033504] [G loss: 0.159600] [FAKE loss: 1.915792]  tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 462/1000] [D loss: 1.038955] [G loss: 0.157524] [FAKE loss: 1.928883]  tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 463/1000] [D loss: 1.043625] [G loss: 0.155412] [FAKE loss: 1.940364]  tensor(0.8561, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 464/1000] [D loss: 1.049131] [G loss: 0.153418] [FAKE loss: 1.953293]  tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 465/1000] [D loss: 1.053423] [G loss: 0.151525] [FAKE loss: 1.963643]  tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 466/1000] [D loss: 1.057216] [G loss: 0.149883] [FAKE loss: 1.973108]  tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 467/1000] [D loss: 1.061541] [G loss: 0.148447] [FAKE loss: 1.983258]  tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 468/1000] [D loss: 1.065812] [G loss: 0.146845] [FAKE loss: 1.993384]  tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 469/1000] [D loss: 1.068925] [G loss: 0.145392] [FAKE loss: 2.000954]  tensor(0.8647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 470/1000] [D loss: 1.072251] [G loss: 0.144129] [FAKE loss: 2.009099]  tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 471/1000] [D loss: 1.075108] [G loss: 0.143147] [FAKE loss: 2.015944]  tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 472/1000] [D loss: 1.078050] [G loss: 0.142122] [FAKE loss: 2.023107]  tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 473/1000] [D loss: 1.081107] [G loss: 0.141031] [FAKE loss: 2.030020]  tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 474/1000] [D loss: 1.083778] [G loss: 0.140364] [FAKE loss: 2.036211]  tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 475/1000] [D loss: 1.085567] [G loss: 0.139589] [FAKE loss: 2.040611]  tensor(0.8697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 476/1000] [D loss: 1.087691] [G loss: 0.139055] [FAKE loss: 2.045412]  tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 477/1000] [D loss: 1.088507] [G loss: 0.138350] [FAKE loss: 2.047627]  tensor(0.8708, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 478/1000] [D loss: 1.090226] [G loss: 0.137987] [FAKE loss: 2.051388]  tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 479/1000] [D loss: 1.091501] [G loss: 0.137636] [FAKE loss: 2.054384]  tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 480/1000] [D loss: 1.091814] [G loss: 0.137422] [FAKE loss: 2.055292]  tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 481/1000] [D loss: 1.092211] [G loss: 0.137296] [FAKE loss: 2.056231]  tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 482/1000] [D loss: 1.092818] [G loss: 0.137192] [FAKE loss: 2.057451]  tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 483/1000] [D loss: 1.092392] [G loss: 0.137219] [FAKE loss: 2.056413]  tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 484/1000] [D loss: 1.091664] [G loss: 0.137450] [FAKE loss: 2.054796]  tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 485/1000] [D loss: 1.091948] [G loss: 0.137486] [FAKE loss: 2.054917]  tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 486/1000] [D loss: 1.090014] [G loss: 0.137861] [FAKE loss: 2.050774]  tensor(0.8712, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 487/1000] [D loss: 1.089658] [G loss: 0.138119] [FAKE loss: 2.049586]  tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 488/1000] [D loss: 1.089062] [G loss: 0.138654] [FAKE loss: 2.047881]  tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 489/1000] [D loss: 1.086673] [G loss: 0.139239] [FAKE loss: 2.042281]  tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 490/1000] [D loss: 1.085350] [G loss: 0.139830] [FAKE loss: 2.038626]  tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 491/1000] [D loss: 1.083849] [G loss: 0.140721] [FAKE loss: 2.034564]  tensor(0.8689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 492/1000] [D loss: 1.081290] [G loss: 0.141621] [FAKE loss: 2.028689]  tensor(0.8680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 493/1000] [D loss: 1.078872] [G loss: 0.142472] [FAKE loss: 2.022462]  tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 494/1000] [D loss: 1.076084] [G loss: 0.143731] [FAKE loss: 2.015664]  tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 495/1000] [D loss: 1.071997] [G loss: 0.144791] [FAKE loss: 2.006054]  tensor(0.8653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 496/1000] [D loss: 1.070060] [G loss: 0.146135] [FAKE loss: 2.000425]  tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 497/1000] [D loss: 1.066013] [G loss: 0.147325] [FAKE loss: 1.990844]  tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 498/1000] [D loss: 1.062261] [G loss: 0.149045] [FAKE loss: 1.981655]  tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 499/1000] [D loss: 1.058395] [G loss: 0.150564] [FAKE loss: 1.971811]  tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 500/1000] [D loss: 1.054029] [G loss: 0.152198] [FAKE loss: 1.961076]  tensor(0.8586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 501/1000] [D loss: 1.049633] [G loss: 0.154269] [FAKE loss: 1.950117]  tensor(0.8574, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 502/1000] [D loss: 1.044663] [G loss: 0.156230] [FAKE loss: 1.937868]  tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 503/1000] [D loss: 1.038913] [G loss: 0.158630] [FAKE loss: 1.923771]  tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 504/1000] [D loss: 1.033558] [G loss: 0.160549] [FAKE loss: 1.910846]  tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 505/1000] [D loss: 1.028774] [G loss: 0.162996] [FAKE loss: 1.898484]  tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 506/1000] [D loss: 1.023389] [G loss: 0.165542] [FAKE loss: 1.884875]  tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 507/1000] [D loss: 1.017411] [G loss: 0.167871] [FAKE loss: 1.870402]  tensor(0.8454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 508/1000] [D loss: 1.011558] [G loss: 0.171064] [FAKE loss: 1.855455]  tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 509/1000] [D loss: 1.005802] [G loss: 0.173722] [FAKE loss: 1.840568]  tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 510/1000] [D loss: 0.999625] [G loss: 0.176700] [FAKE loss: 1.824733]  tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 511/1000] [D loss: 0.992216] [G loss: 0.180012] [FAKE loss: 1.806629]  tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 512/1000] [D loss: 0.986284] [G loss: 0.183304] [FAKE loss: 1.790951]  tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 513/1000] [D loss: 0.979738] [G loss: 0.186725] [FAKE loss: 1.774633]  tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 514/1000] [D loss: 0.972896] [G loss: 0.190250] [FAKE loss: 1.757094]  tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 515/1000] [D loss: 0.966380] [G loss: 0.193789] [FAKE loss: 1.740009]  tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 516/1000] [D loss: 0.959442] [G loss: 0.197656] [FAKE loss: 1.721881]  tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 517/1000] [D loss: 0.952937] [G loss: 0.201883] [FAKE loss: 1.704569]  tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 518/1000] [D loss: 0.946196] [G loss: 0.206130] [FAKE loss: 1.686748]  tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 519/1000] [D loss: 0.939390] [G loss: 0.209956] [FAKE loss: 1.668904]  tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 520/1000] [D loss: 0.931887] [G loss: 0.214550] [FAKE loss: 1.648939]  tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 521/1000] [D loss: 0.926077] [G loss: 0.218577] [FAKE loss: 1.632394]  tensor(0.8035, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 522/1000] [D loss: 0.918594] [G loss: 0.223269] [FAKE loss: 1.613321]  tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 523/1000] [D loss: 0.912128] [G loss: 0.227996] [FAKE loss: 1.594874]  tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 524/1000] [D loss: 0.905167] [G loss: 0.232716] [FAKE loss: 1.575794]  tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 525/1000] [D loss: 0.899491] [G loss: 0.237454] [FAKE loss: 1.559222]  tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 526/1000] [D loss: 0.893138] [G loss: 0.242218] [FAKE loss: 1.541232]  tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 527/1000] [D loss: 0.887472] [G loss: 0.247148] [FAKE loss: 1.524422]  tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 528/1000] [D loss: 0.880876] [G loss: 0.252440] [FAKE loss: 1.505546]  tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 529/1000] [D loss: 0.874621] [G loss: 0.257133] [FAKE loss: 1.487291]  tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 530/1000] [D loss: 0.869439] [G loss: 0.262023] [FAKE loss: 1.471650]  tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 531/1000] [D loss: 0.863171] [G loss: 0.267317] [FAKE loss: 1.452682]  tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 532/1000] [D loss: 0.858432] [G loss: 0.272714] [FAKE loss: 1.437370]  tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 533/1000] [D loss: 0.852101] [G loss: 0.278362] [FAKE loss: 1.418542]  tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 534/1000] [D loss: 0.846961] [G loss: 0.283857] [FAKE loss: 1.401628]  tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 535/1000] [D loss: 0.841517] [G loss: 0.289472] [FAKE loss: 1.384859]  tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 536/1000] [D loss: 0.836850] [G loss: 0.294681] [FAKE loss: 1.369071]  tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 537/1000] [D loss: 0.830920] [G loss: 0.300595] [FAKE loss: 1.351452]  tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 538/1000] [D loss: 0.825935] [G loss: 0.306894] [FAKE loss: 1.334405]  tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 539/1000] [D loss: 0.821658] [G loss: 0.312463] [FAKE loss: 1.319550]  tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 540/1000] [D loss: 0.817474] [G loss: 0.318408] [FAKE loss: 1.304070]  tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 541/1000] [D loss: 0.811485] [G loss: 0.324769] [FAKE loss: 1.285879]  tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 542/1000] [D loss: 0.807705] [G loss: 0.331069] [FAKE loss: 1.271030]  tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 543/1000] [D loss: 0.802161] [G loss: 0.337210] [FAKE loss: 1.253671]  tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 544/1000] [D loss: 0.798319] [G loss: 0.344005] [FAKE loss: 1.239321]  tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 545/1000] [D loss: 0.793209] [G loss: 0.350364] [FAKE loss: 1.222718]  tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 546/1000] [D loss: 0.789053] [G loss: 0.356884] [FAKE loss: 1.207226]  tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 547/1000] [D loss: 0.784105] [G loss: 0.363631] [FAKE loss: 1.190571]  tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 548/1000] [D loss: 0.780174] [G loss: 0.369809] [FAKE loss: 1.175852]  tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 549/1000] [D loss: 0.776179] [G loss: 0.378550] [FAKE loss: 1.160589]  tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 550/1000] [D loss: 0.771680] [G loss: 0.384378] [FAKE loss: 1.144565]  tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 551/1000] [D loss: 0.768252] [G loss: 0.391547] [FAKE loss: 1.130924]  tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 552/1000] [D loss: 0.764116] [G loss: 0.398406] [FAKE loss: 1.116884]  tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 553/1000] [D loss: 0.760439] [G loss: 0.405516] [FAKE loss: 1.102258]  tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 554/1000] [D loss: 0.756480] [G loss: 0.412998] [FAKE loss: 1.087792]  tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 555/1000] [D loss: 0.752929] [G loss: 0.420288] [FAKE loss: 1.073962]  tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 556/1000] [D loss: 0.749564] [G loss: 0.427850] [FAKE loss: 1.060704]  tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 557/1000] [D loss: 0.746488] [G loss: 0.434127] [FAKE loss: 1.048139]  tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 558/1000] [D loss: 0.742773] [G loss: 0.441182] [FAKE loss: 1.033680]  tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 559/1000] [D loss: 0.739319] [G loss: 0.448511] [FAKE loss: 1.020976]  tensor(0.6386, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 560/1000] [D loss: 0.736150] [G loss: 0.455217] [FAKE loss: 1.007990]  tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 561/1000] [D loss: 0.733245] [G loss: 0.462757] [FAKE loss: 0.996186]  tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 562/1000] [D loss: 0.730322] [G loss: 0.469559] [FAKE loss: 0.984299]  tensor(0.6257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 563/1000] [D loss: 0.727459] [G loss: 0.476832] [FAKE loss: 0.972867]  tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 564/1000] [D loss: 0.724798] [G loss: 0.483281] [FAKE loss: 0.962147]  tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 565/1000] [D loss: 0.722472] [G loss: 0.489645] [FAKE loss: 0.951180]  tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 566/1000] [D loss: 0.719382] [G loss: 0.496067] [FAKE loss: 0.940378]  tensor(0.6090, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 567/1000] [D loss: 0.717727] [G loss: 0.503030] [FAKE loss: 0.931134]  tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 568/1000] [D loss: 0.715606] [G loss: 0.509111] [FAKE loss: 0.921785]  tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 569/1000] [D loss: 0.712857] [G loss: 0.515799] [FAKE loss: 0.911314]  tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 570/1000] [D loss: 0.712078] [G loss: 0.521670] [FAKE loss: 0.904460]  tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 571/1000] [D loss: 0.709706] [G loss: 0.527228] [FAKE loss: 0.895783]  tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 572/1000] [D loss: 0.707419] [G loss: 0.531833] [FAKE loss: 0.886329]  tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 573/1000] [D loss: 0.706401] [G loss: 0.537441] [FAKE loss: 0.879754]  tensor(0.5845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 574/1000] [D loss: 0.705243] [G loss: 0.543102] [FAKE loss: 0.873310]  tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 575/1000] [D loss: 0.703651] [G loss: 0.547923] [FAKE loss: 0.866756]  tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 576/1000] [D loss: 0.701868] [G loss: 0.553275] [FAKE loss: 0.859694]  tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 577/1000] [D loss: 0.700729] [G loss: 0.556615] [FAKE loss: 0.853954]  tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 578/1000] [D loss: 0.700080] [G loss: 0.560775] [FAKE loss: 0.849315]  tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 579/1000] [D loss: 0.698477] [G loss: 0.564369] [FAKE loss: 0.843515]  tensor(0.5695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 580/1000] [D loss: 0.697775] [G loss: 0.568250] [FAKE loss: 0.838729]  tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 581/1000] [D loss: 0.696430] [G loss: 0.571325] [FAKE loss: 0.835010]  tensor(0.5656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 582/1000] [D loss: 0.696116] [G loss: 0.573952] [FAKE loss: 0.831465]  tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 583/1000] [D loss: 0.695363] [G loss: 0.575722] [FAKE loss: 0.828171]  tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 584/1000] [D loss: 0.695408] [G loss: 0.578701] [FAKE loss: 0.826141]  tensor(0.5613, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 585/1000] [D loss: 0.694688] [G loss: 0.580886] [FAKE loss: 0.823540]  tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 586/1000] [D loss: 0.694568] [G loss: 0.581489] [FAKE loss: 0.821612]  tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 587/1000] [D loss: 0.693771] [G loss: 0.582739] [FAKE loss: 0.819976]  tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 588/1000] [D loss: 0.693847] [G loss: 0.582731] [FAKE loss: 0.819107]  tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 589/1000] [D loss: 0.694139] [G loss: 0.583888] [FAKE loss: 0.819055]  tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 590/1000] [D loss: 0.693658] [G loss: 0.583134] [FAKE loss: 0.818470]  tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 591/1000] [D loss: 0.694332] [G loss: 0.583835] [FAKE loss: 0.819728]  tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 592/1000] [D loss: 0.694322] [G loss: 0.582134] [FAKE loss: 0.819739]  tensor(0.5588, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 593/1000] [D loss: 0.694910] [G loss: 0.581135] [FAKE loss: 0.821549]  tensor(0.5593, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 594/1000] [D loss: 0.695554] [G loss: 0.579943] [FAKE loss: 0.824020]  tensor(0.5600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 595/1000] [D loss: 0.695692] [G loss: 0.578894] [FAKE loss: 0.824855]  tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 596/1000] [D loss: 0.695740] [G loss: 0.576765] [FAKE loss: 0.826828]  tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 597/1000] [D loss: 0.696896] [G loss: 0.574745] [FAKE loss: 0.830522]  tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 598/1000] [D loss: 0.697105] [G loss: 0.571596] [FAKE loss: 0.833011]  tensor(0.5648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 599/1000] [D loss: 0.698515] [G loss: 0.569288] [FAKE loss: 0.837734]  tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 600/1000] [D loss: 0.698406] [G loss: 0.566498] [FAKE loss: 0.840231]  tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 601/1000] [D loss: 0.700469] [G loss: 0.563212] [FAKE loss: 0.846155]  tensor(0.5702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 602/1000] [D loss: 0.701512] [G loss: 0.559554] [FAKE loss: 0.850311]  tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 603/1000] [D loss: 0.702425] [G loss: 0.554922] [FAKE loss: 0.855775]  tensor(0.5744, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 604/1000] [D loss: 0.703010] [G loss: 0.551160] [FAKE loss: 0.860947]  tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 605/1000] [D loss: 0.704845] [G loss: 0.546503] [FAKE loss: 0.868111]  tensor(0.5794, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 606/1000] [D loss: 0.706087] [G loss: 0.542099] [FAKE loss: 0.873894]  tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 607/1000] [D loss: 0.708036] [G loss: 0.535970] [FAKE loss: 0.881619]  tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 608/1000] [D loss: 0.710230] [G loss: 0.530537] [FAKE loss: 0.889692]  tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 609/1000] [D loss: 0.712405] [G loss: 0.525341] [FAKE loss: 0.898064]  tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 610/1000] [D loss: 0.715494] [G loss: 0.518302] [FAKE loss: 0.908095]  tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 611/1000] [D loss: 0.717115] [G loss: 0.512520] [FAKE loss: 0.916522]  tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 612/1000] [D loss: 0.720823] [G loss: 0.505726] [FAKE loss: 0.927518]  tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 613/1000] [D loss: 0.723360] [G loss: 0.498539] [FAKE loss: 0.937858]  tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 614/1000] [D loss: 0.727758] [G loss: 0.490318] [FAKE loss: 0.951026]  tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 615/1000] [D loss: 0.731970] [G loss: 0.482658] [FAKE loss: 0.964540]  tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 616/1000] [D loss: 0.735670] [G loss: 0.473751] [FAKE loss: 0.977152]  tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 617/1000] [D loss: 0.741091] [G loss: 0.465633] [FAKE loss: 0.992958]  tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 618/1000] [D loss: 0.746044] [G loss: 0.457057] [FAKE loss: 1.007997]  tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 619/1000] [D loss: 0.751446] [G loss: 0.447881] [FAKE loss: 1.024490]  tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 620/1000] [D loss: 0.756816] [G loss: 0.438509] [FAKE loss: 1.040155]  tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 621/1000] [D loss: 0.763216] [G loss: 0.428352] [FAKE loss: 1.059140]  tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 622/1000] [D loss: 0.769745] [G loss: 0.418758] [FAKE loss: 1.077500]  tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 623/1000] [D loss: 0.776435] [G loss: 0.409013] [FAKE loss: 1.095999]  tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 624/1000] [D loss: 0.783901] [G loss: 0.399434] [FAKE loss: 1.116701]  tensor(0.6713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 625/1000] [D loss: 0.790898] [G loss: 0.388813] [FAKE loss: 1.136803]  tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 626/1000] [D loss: 0.799158] [G loss: 0.380362] [FAKE loss: 1.158826]  tensor(0.6850, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 627/1000] [D loss: 0.808052] [G loss: 0.370252] [FAKE loss: 1.182424]  tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 628/1000] [D loss: 0.815889] [G loss: 0.359939] [FAKE loss: 1.204104]  tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 629/1000] [D loss: 0.824494] [G loss: 0.350448] [FAKE loss: 1.227378]  tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 630/1000] [D loss: 0.832203] [G loss: 0.341066] [FAKE loss: 1.248351]  tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 631/1000] [D loss: 0.841556] [G loss: 0.332161] [FAKE loss: 1.273382]  tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 632/1000] [D loss: 0.850862] [G loss: 0.322029] [FAKE loss: 1.298153]  tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 633/1000] [D loss: 0.861777] [G loss: 0.312037] [FAKE loss: 1.325443]  tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 634/1000] [D loss: 0.871586] [G loss: 0.303630] [FAKE loss: 1.351014]  tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 635/1000] [D loss: 0.881283] [G loss: 0.295730] [FAKE loss: 1.376490]  tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 636/1000] [D loss: 0.891407] [G loss: 0.286289] [FAKE loss: 1.401522]  tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 637/1000] [D loss: 0.901244] [G loss: 0.278564] [FAKE loss: 1.428101]  tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 638/1000] [D loss: 0.910753] [G loss: 0.270778] [FAKE loss: 1.452979]  tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 639/1000] [D loss: 0.921424] [G loss: 0.262323] [FAKE loss: 1.479959]  tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 640/1000] [D loss: 0.932641] [G loss: 0.255350] [FAKE loss: 1.507722]  tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 641/1000] [D loss: 0.943820] [G loss: 0.247153] [FAKE loss: 1.535846]  tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 642/1000] [D loss: 0.954752] [G loss: 0.240739] [FAKE loss: 1.563516]  tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 643/1000] [D loss: 0.964763] [G loss: 0.233101] [FAKE loss: 1.588787]  tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 644/1000] [D loss: 0.974330] [G loss: 0.227101] [FAKE loss: 1.612901]  tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 645/1000] [D loss: 0.986620] [G loss: 0.220653] [FAKE loss: 1.643688]  tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 646/1000] [D loss: 0.995430] [G loss: 0.213633] [FAKE loss: 1.666051]  tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 647/1000] [D loss: 1.007103] [G loss: 0.209368] [FAKE loss: 1.694645]  tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 648/1000] [D loss: 1.015101] [G loss: 0.202614] [FAKE loss: 1.715670]  tensor(0.8170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 649/1000] [D loss: 1.026286] [G loss: 0.198104] [FAKE loss: 1.743485]  tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 650/1000] [D loss: 1.037538] [G loss: 0.192082] [FAKE loss: 1.769815]  tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 651/1000] [D loss: 1.045740] [G loss: 0.186641] [FAKE loss: 1.791007]  tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 652/1000] [D loss: 1.055451] [G loss: 0.182945] [FAKE loss: 1.815130]  tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 653/1000] [D loss: 1.064388] [G loss: 0.178402] [FAKE loss: 1.837510]  tensor(0.8376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 654/1000] [D loss: 1.073025] [G loss: 0.174426] [FAKE loss: 1.859159]  tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 655/1000] [D loss: 1.082540] [G loss: 0.170460] [FAKE loss: 1.883202]  tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 656/1000] [D loss: 1.088147] [G loss: 0.167317] [FAKE loss: 1.898081]  tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 657/1000] [D loss: 1.096623] [G loss: 0.163476] [FAKE loss: 1.918989]  tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 658/1000] [D loss: 1.103362] [G loss: 0.160794] [FAKE loss: 1.936949]  tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 659/1000] [D loss: 1.112296] [G loss: 0.157867] [FAKE loss: 1.957204]  tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 660/1000] [D loss: 1.117203] [G loss: 0.154886] [FAKE loss: 1.971401]  tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 661/1000] [D loss: 1.123097] [G loss: 0.152964] [FAKE loss: 1.986296]  tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 662/1000] [D loss: 1.126482] [G loss: 0.151247] [FAKE loss: 1.996031]  tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 663/1000] [D loss: 1.131539] [G loss: 0.148882] [FAKE loss: 2.009279]  tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 664/1000] [D loss: 1.136913] [G loss: 0.146476] [FAKE loss: 2.023196]  tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 665/1000] [D loss: 1.137915] [G loss: 0.146021] [FAKE loss: 2.027974]  tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 666/1000] [D loss: 1.140416] [G loss: 0.145528] [FAKE loss: 2.036020]  tensor(0.8663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 667/1000] [D loss: 1.142560] [G loss: 0.142942] [FAKE loss: 2.042763]  tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 668/1000] [D loss: 1.141686] [G loss: 0.143003] [FAKE loss: 2.043220]  tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 669/1000] [D loss: 1.141639] [G loss: 0.142922] [FAKE loss: 2.045507]  tensor(0.8677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 670/1000] [D loss: 1.143552] [G loss: 0.142018] [FAKE loss: 2.051786]  tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 671/1000] [D loss: 1.142256] [G loss: 0.141882] [FAKE loss: 2.050254]  tensor(0.8681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 672/1000] [D loss: 1.141717] [G loss: 0.141623] [FAKE loss: 2.050442]  tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 673/1000] [D loss: 1.139356] [G loss: 0.142334] [FAKE loss: 2.048643]  tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 674/1000] [D loss: 1.136634] [G loss: 0.142663] [FAKE loss: 2.044353]  tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 675/1000] [D loss: 1.135218] [G loss: 0.144127] [FAKE loss: 2.042938]  tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 676/1000] [D loss: 1.128762] [G loss: 0.144615] [FAKE loss: 2.031101]  tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 677/1000] [D loss: 1.123970] [G loss: 0.145122] [FAKE loss: 2.022966]  tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 678/1000] [D loss: 1.119542] [G loss: 0.146845] [FAKE loss: 2.014851]  tensor(0.8639, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 679/1000] [D loss: 1.113778] [G loss: 0.148253] [FAKE loss: 2.003887]  tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 680/1000] [D loss: 1.107962] [G loss: 0.149938] [FAKE loss: 1.993065]  tensor(0.8612, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 681/1000] [D loss: 1.099975] [G loss: 0.151096] [FAKE loss: 1.977937]  tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 682/1000] [D loss: 1.093798] [G loss: 0.153944] [FAKE loss: 1.965802]  tensor(0.8579, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 683/1000] [D loss: 1.088088] [G loss: 0.155460] [FAKE loss: 1.954856]  tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 684/1000] [D loss: 1.080104] [G loss: 0.158067] [FAKE loss: 1.939002]  tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 685/1000] [D loss: 1.071256] [G loss: 0.160545] [FAKE loss: 1.921609]  tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 686/1000] [D loss: 1.064593] [G loss: 0.163531] [FAKE loss: 1.907530]  tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 687/1000] [D loss: 1.054787] [G loss: 0.166746] [FAKE loss: 1.888164]  tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 688/1000] [D loss: 1.046156] [G loss: 0.170367] [FAKE loss: 1.870009]  tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 689/1000] [D loss: 1.036608] [G loss: 0.173795] [FAKE loss: 1.850909]  tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 690/1000] [D loss: 1.027124] [G loss: 0.176575] [FAKE loss: 1.831856]  tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 691/1000] [D loss: 1.017721] [G loss: 0.180656] [FAKE loss: 1.811577]  tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 692/1000] [D loss: 1.007688] [G loss: 0.183967] [FAKE loss: 1.791600]  tensor(0.8321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 693/1000] [D loss: 0.998531] [G loss: 0.188462] [FAKE loss: 1.772141]  tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 694/1000] [D loss: 0.988362] [G loss: 0.192716] [FAKE loss: 1.751020]  tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 695/1000] [D loss: 0.978515] [G loss: 0.196706] [FAKE loss: 1.730639]  tensor(0.8218, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 696/1000] [D loss: 0.968687] [G loss: 0.201103] [FAKE loss: 1.709764]  tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 697/1000] [D loss: 0.959300] [G loss: 0.206059] [FAKE loss: 1.689797]  tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 698/1000] [D loss: 0.947742] [G loss: 0.210974] [FAKE loss: 1.665417]  tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 699/1000] [D loss: 0.938375] [G loss: 0.215817] [FAKE loss: 1.645146]  tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 700/1000] [D loss: 0.926462] [G loss: 0.220991] [FAKE loss: 1.620821]  tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 701/1000] [D loss: 0.918593] [G loss: 0.226414] [FAKE loss: 1.603039]  tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 702/1000] [D loss: 0.908067] [G loss: 0.232282] [FAKE loss: 1.580463]  tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 703/1000] [D loss: 0.897188] [G loss: 0.238199] [FAKE loss: 1.557837]  tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 704/1000] [D loss: 0.888187] [G loss: 0.243159] [FAKE loss: 1.536952]  tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 705/1000] [D loss: 0.879056] [G loss: 0.249363] [FAKE loss: 1.517396]  tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 706/1000] [D loss: 0.869419] [G loss: 0.255212] [FAKE loss: 1.496500]  tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 707/1000] [D loss: 0.859131] [G loss: 0.261127] [FAKE loss: 1.474295]  tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 708/1000] [D loss: 0.850035] [G loss: 0.266899] [FAKE loss: 1.454425]  tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 709/1000] [D loss: 0.841415] [G loss: 0.273241] [FAKE loss: 1.435099]  tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 710/1000] [D loss: 0.832506] [G loss: 0.279854] [FAKE loss: 1.414768]  tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 711/1000] [D loss: 0.823984] [G loss: 0.286258] [FAKE loss: 1.396007]  tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 712/1000] [D loss: 0.815258] [G loss: 0.292364] [FAKE loss: 1.376187]  tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 713/1000] [D loss: 0.806707] [G loss: 0.299291] [FAKE loss: 1.356818]  tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 714/1000] [D loss: 0.798790] [G loss: 0.305386] [FAKE loss: 1.339705]  tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 715/1000] [D loss: 0.791319] [G loss: 0.312517] [FAKE loss: 1.321532]  tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 716/1000] [D loss: 0.783640] [G loss: 0.318458] [FAKE loss: 1.304434]  tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 717/1000] [D loss: 0.776089] [G loss: 0.324779] [FAKE loss: 1.287835]  tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 718/1000] [D loss: 0.769397] [G loss: 0.332186] [FAKE loss: 1.271174]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 719/1000] [D loss: 0.761443] [G loss: 0.338672] [FAKE loss: 1.254292]  tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 720/1000] [D loss: 0.755234] [G loss: 0.344385] [FAKE loss: 1.239292]  tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 721/1000] [D loss: 0.749452] [G loss: 0.351830] [FAKE loss: 1.224794]  tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 722/1000] [D loss: 0.742379] [G loss: 0.357534] [FAKE loss: 1.208501]  tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 723/1000] [D loss: 0.736511] [G loss: 0.363691] [FAKE loss: 1.194391]  tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 724/1000] [D loss: 0.730756] [G loss: 0.369624] [FAKE loss: 1.180561]  tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 725/1000] [D loss: 0.724390] [G loss: 0.377016] [FAKE loss: 1.165274]  tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 726/1000] [D loss: 0.719731] [G loss: 0.382958] [FAKE loss: 1.154369]  tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 727/1000] [D loss: 0.714080] [G loss: 0.387943] [FAKE loss: 1.140658]  tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 728/1000] [D loss: 0.710427] [G loss: 0.395496] [FAKE loss: 1.130341]  tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 729/1000] [D loss: 0.703929] [G loss: 0.401183] [FAKE loss: 1.116225]  tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 730/1000] [D loss: 0.700114] [G loss: 0.407906] [FAKE loss: 1.106578]  tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 731/1000] [D loss: 0.695464] [G loss: 0.414229] [FAKE loss: 1.094907]  tensor(0.6621, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 732/1000] [D loss: 0.691233] [G loss: 0.420019] [FAKE loss: 1.083354]  tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 733/1000] [D loss: 0.687539] [G loss: 0.423978] [FAKE loss: 1.074253]  tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 734/1000] [D loss: 0.682619] [G loss: 0.428974] [FAKE loss: 1.062101]  tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 735/1000] [D loss: 0.679376] [G loss: 0.434851] [FAKE loss: 1.054015]  tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 736/1000] [D loss: 0.678511] [G loss: 0.439324] [FAKE loss: 1.049708]  tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 737/1000] [D loss: 0.672819] [G loss: 0.445593] [FAKE loss: 1.036930]  tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 738/1000] [D loss: 0.671609] [G loss: 0.450651] [FAKE loss: 1.031802]  tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 739/1000] [D loss: 0.669019] [G loss: 0.456537] [FAKE loss: 1.025300]  tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 740/1000] [D loss: 0.667255] [G loss: 0.459449] [FAKE loss: 1.019955]  tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 741/1000] [D loss: 0.661607] [G loss: 0.464382] [FAKE loss: 1.007503]  tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 742/1000] [D loss: 0.659765] [G loss: 0.467599] [FAKE loss: 1.002280]  tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 743/1000] [D loss: 0.657617] [G loss: 0.472827] [FAKE loss: 0.996654]  tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 744/1000] [D loss: 0.654794] [G loss: 0.476670] [FAKE loss: 0.989119]  tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 745/1000] [D loss: 0.652977] [G loss: 0.482638] [FAKE loss: 0.984514]  tensor(0.6221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 746/1000] [D loss: 0.653427] [G loss: 0.483002] [FAKE loss: 0.982356]  tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 747/1000] [D loss: 0.650090] [G loss: 0.485685] [FAKE loss: 0.975764]  tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 748/1000] [D loss: 0.648764] [G loss: 0.490037] [FAKE loss: 0.972573]  tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 749/1000] [D loss: 0.648668] [G loss: 0.491442] [FAKE loss: 0.970879]  tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 750/1000] [D loss: 0.647156] [G loss: 0.494758] [FAKE loss: 0.967076]  tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 751/1000] [D loss: 0.647640] [G loss: 0.496089] [FAKE loss: 0.967290]  tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 752/1000] [D loss: 0.647229] [G loss: 0.498534] [FAKE loss: 0.966067]  tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 753/1000] [D loss: 0.645951] [G loss: 0.501095] [FAKE loss: 0.962185]  tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 754/1000] [D loss: 0.648177] [G loss: 0.499149] [FAKE loss: 0.965050]  tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 755/1000] [D loss: 0.647616] [G loss: 0.501852] [FAKE loss: 0.964841]  tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 756/1000] [D loss: 0.644532] [G loss: 0.500195] [FAKE loss: 0.959501]  tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 757/1000] [D loss: 0.647110] [G loss: 0.501774] [FAKE loss: 0.963311]  tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 758/1000] [D loss: 0.648371] [G loss: 0.501750] [FAKE loss: 0.966139]  tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 759/1000] [D loss: 0.651273] [G loss: 0.500063] [FAKE loss: 0.969945]  tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 760/1000] [D loss: 0.650786] [G loss: 0.498249] [FAKE loss: 0.970543]  tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 761/1000] [D loss: 0.652095] [G loss: 0.496584] [FAKE loss: 0.974821]  tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 762/1000] [D loss: 0.653574] [G loss: 0.493651] [FAKE loss: 0.977822]  tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 763/1000] [D loss: 0.657993] [G loss: 0.492074] [FAKE loss: 0.987112]  tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 764/1000] [D loss: 0.660847] [G loss: 0.489604] [FAKE loss: 0.992326]  tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 765/1000] [D loss: 0.661798] [G loss: 0.485266] [FAKE loss: 0.997512]  tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 766/1000] [D loss: 0.665595] [G loss: 0.482536] [FAKE loss: 1.004435]  tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 767/1000] [D loss: 0.668211] [G loss: 0.480294] [FAKE loss: 1.012585]  tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 768/1000] [D loss: 0.673416] [G loss: 0.474984] [FAKE loss: 1.024701]  tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 769/1000] [D loss: 0.675479] [G loss: 0.472027] [FAKE loss: 1.029273]  tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 770/1000] [D loss: 0.679440] [G loss: 0.465577] [FAKE loss: 1.038482]  tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 771/1000] [D loss: 0.685202] [G loss: 0.461325] [FAKE loss: 1.051264]  tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 772/1000] [D loss: 0.688848] [G loss: 0.456873] [FAKE loss: 1.060765]  tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 773/1000] [D loss: 0.693599] [G loss: 0.450316] [FAKE loss: 1.072788]  tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 774/1000] [D loss: 0.699448] [G loss: 0.441552] [FAKE loss: 1.087996]  tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 775/1000] [D loss: 0.705784] [G loss: 0.436189] [FAKE loss: 1.101591]  tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 776/1000] [D loss: 0.710704] [G loss: 0.431614] [FAKE loss: 1.114015]  tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 777/1000] [D loss: 0.717714] [G loss: 0.423740] [FAKE loss: 1.130161]  tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 778/1000] [D loss: 0.724154] [G loss: 0.418626] [FAKE loss: 1.145533]  tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 779/1000] [D loss: 0.730071] [G loss: 0.409780] [FAKE loss: 1.161180]  tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 780/1000] [D loss: 0.736833] [G loss: 0.403865] [FAKE loss: 1.176886]  tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 781/1000] [D loss: 0.745431] [G loss: 0.394873] [FAKE loss: 1.196258]  tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 782/1000] [D loss: 0.754458] [G loss: 0.387391] [FAKE loss: 1.216381]  tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 783/1000] [D loss: 0.758086] [G loss: 0.381322] [FAKE loss: 1.228822]  tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 784/1000] [D loss: 0.770385] [G loss: 0.370697] [FAKE loss: 1.256551]  tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 785/1000] [D loss: 0.775936] [G loss: 0.361914] [FAKE loss: 1.268400]  tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 786/1000] [D loss: 0.784575] [G loss: 0.357575] [FAKE loss: 1.290228]  tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 787/1000] [D loss: 0.792353] [G loss: 0.352725] [FAKE loss: 1.309789]  tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 788/1000] [D loss: 0.804411] [G loss: 0.340860] [FAKE loss: 1.335823]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 789/1000] [D loss: 0.814395] [G loss: 0.336648] [FAKE loss: 1.358470]  tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 790/1000] [D loss: 0.821912] [G loss: 0.327778] [FAKE loss: 1.378500]  tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 791/1000] [D loss: 0.826230] [G loss: 0.322517] [FAKE loss: 1.390370]  tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 792/1000] [D loss: 0.839671] [G loss: 0.312667] [FAKE loss: 1.420765]  tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 793/1000] [D loss: 0.852335] [G loss: 0.307336] [FAKE loss: 1.448367]  tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 794/1000] [D loss: 0.857009] [G loss: 0.300648] [FAKE loss: 1.460989]  tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 795/1000] [D loss: 0.869449] [G loss: 0.296185] [FAKE loss: 1.489520]  tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 796/1000] [D loss: 0.880678] [G loss: 0.288370] [FAKE loss: 1.514555]  tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 797/1000] [D loss: 0.886659] [G loss: 0.282908] [FAKE loss: 1.531072]  tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 798/1000] [D loss: 0.893618] [G loss: 0.275454] [FAKE loss: 1.548810]  tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 799/1000] [D loss: 0.904433] [G loss: 0.270093] [FAKE loss: 1.573707]  tensor(0.7716, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 800/1000] [D loss: 0.913612] [G loss: 0.266530] [FAKE loss: 1.593212]  tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 801/1000] [D loss: 0.922256] [G loss: 0.261264] [FAKE loss: 1.614590]  tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 802/1000] [D loss: 0.931787] [G loss: 0.253891] [FAKE loss: 1.636243]  tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 803/1000] [D loss: 0.933794] [G loss: 0.251660] [FAKE loss: 1.643903]  tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 804/1000] [D loss: 0.944925] [G loss: 0.242343] [FAKE loss: 1.669151]  tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 805/1000] [D loss: 0.952906] [G loss: 0.238714] [FAKE loss: 1.687773]  tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 806/1000] [D loss: 0.961263] [G loss: 0.238377] [FAKE loss: 1.707437]  tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 807/1000] [D loss: 0.969370] [G loss: 0.230777] [FAKE loss: 1.726290]  tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 808/1000] [D loss: 0.972147] [G loss: 0.226251] [FAKE loss: 1.734176]  tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 809/1000] [D loss: 0.979208] [G loss: 0.227447] [FAKE loss: 1.749910]  tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 810/1000] [D loss: 0.985465] [G loss: 0.223556] [FAKE loss: 1.765735]  tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 811/1000] [D loss: 0.985160] [G loss: 0.221909] [FAKE loss: 1.767201]  tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 812/1000] [D loss: 0.987752] [G loss: 0.219132] [FAKE loss: 1.775291]  tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 813/1000] [D loss: 0.992225] [G loss: 0.216053] [FAKE loss: 1.785141]  tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 814/1000] [D loss: 0.993971] [G loss: 0.213604] [FAKE loss: 1.793040]  tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 815/1000] [D loss: 0.998387] [G loss: 0.212354] [FAKE loss: 1.801067]  tensor(0.8142, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 816/1000] [D loss: 0.993986] [G loss: 0.209063] [FAKE loss: 1.795247]  tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 817/1000] [D loss: 0.998711] [G loss: 0.212332] [FAKE loss: 1.805151]  tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 818/1000] [D loss: 0.997371] [G loss: 0.210440] [FAKE loss: 1.804689]  tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 819/1000] [D loss: 0.995643] [G loss: 0.211179] [FAKE loss: 1.801423]  tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 820/1000] [D loss: 0.996786] [G loss: 0.209569] [FAKE loss: 1.806559]  tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 821/1000] [D loss: 0.991062] [G loss: 0.209539] [FAKE loss: 1.794975]  tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 822/1000] [D loss: 0.989023] [G loss: 0.210511] [FAKE loss: 1.792374]  tensor(0.8170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 823/1000] [D loss: 0.988375] [G loss: 0.207982] [FAKE loss: 1.790816]  tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 824/1000] [D loss: 0.986002] [G loss: 0.210271] [FAKE loss: 1.788661]  tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 825/1000] [D loss: 0.982274] [G loss: 0.213501] [FAKE loss: 1.781866]  tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 826/1000] [D loss: 0.975971] [G loss: 0.212602] [FAKE loss: 1.769107]  tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 827/1000] [D loss: 0.975659] [G loss: 0.213320] [FAKE loss: 1.769083]  tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 828/1000] [D loss: 0.967376] [G loss: 0.214827] [FAKE loss: 1.752704]  tensor(0.8113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 829/1000] [D loss: 0.962558] [G loss: 0.215174] [FAKE loss: 1.741871]  tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 830/1000] [D loss: 0.956094] [G loss: 0.219574] [FAKE loss: 1.730754]  tensor(0.8083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 831/1000] [D loss: 0.948000] [G loss: 0.219310] [FAKE loss: 1.714143]  tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 832/1000] [D loss: 0.943283] [G loss: 0.223567] [FAKE loss: 1.705287]  tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 833/1000] [D loss: 0.941585] [G loss: 0.223673] [FAKE loss: 1.702374]  tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 834/1000] [D loss: 0.930526] [G loss: 0.228085] [FAKE loss: 1.678382]  tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 835/1000] [D loss: 0.924348] [G loss: 0.228275] [FAKE loss: 1.666171]  tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 836/1000] [D loss: 0.915415] [G loss: 0.233602] [FAKE loss: 1.647793]  tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 837/1000] [D loss: 0.908688] [G loss: 0.237145] [FAKE loss: 1.634542]  tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 838/1000] [D loss: 0.895875] [G loss: 0.240173] [FAKE loss: 1.607284]  tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 839/1000] [D loss: 0.890072] [G loss: 0.243243] [FAKE loss: 1.595436]  tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 840/1000] [D loss: 0.883740] [G loss: 0.247631] [FAKE loss: 1.582594]  tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 841/1000] [D loss: 0.874548] [G loss: 0.250381] [FAKE loss: 1.562766]  tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 842/1000] [D loss: 0.864464] [G loss: 0.256209] [FAKE loss: 1.539914]  tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 843/1000] [D loss: 0.857863] [G loss: 0.259423] [FAKE loss: 1.526025]  tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 844/1000] [D loss: 0.848372] [G loss: 0.264796] [FAKE loss: 1.505587]  tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 845/1000] [D loss: 0.838410] [G loss: 0.270013] [FAKE loss: 1.485000]  tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 846/1000] [D loss: 0.830366] [G loss: 0.273836] [FAKE loss: 1.465968]  tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 847/1000] [D loss: 0.823244] [G loss: 0.279688] [FAKE loss: 1.450160]  tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 848/1000] [D loss: 0.812517] [G loss: 0.285253] [FAKE loss: 1.426699]  tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 849/1000] [D loss: 0.803678] [G loss: 0.291729] [FAKE loss: 1.406859]  tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 850/1000] [D loss: 0.794672] [G loss: 0.296307] [FAKE loss: 1.386831]  tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 851/1000] [D loss: 0.786824] [G loss: 0.303153] [FAKE loss: 1.368430]  tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 852/1000] [D loss: 0.778563] [G loss: 0.308739] [FAKE loss: 1.350327]  tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 853/1000] [D loss: 0.769919] [G loss: 0.313119] [FAKE loss: 1.330585]  tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 854/1000] [D loss: 0.760875] [G loss: 0.322482] [FAKE loss: 1.309514]  tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 855/1000] [D loss: 0.751526] [G loss: 0.328552] [FAKE loss: 1.290338]  tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 856/1000] [D loss: 0.745095] [G loss: 0.335537] [FAKE loss: 1.273988]  tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 857/1000] [D loss: 0.736552] [G loss: 0.341993] [FAKE loss: 1.254809]  tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 858/1000] [D loss: 0.729085] [G loss: 0.349066] [FAKE loss: 1.236793]  tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 859/1000] [D loss: 0.722060] [G loss: 0.355597] [FAKE loss: 1.219193]  tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 860/1000] [D loss: 0.713763] [G loss: 0.365129] [FAKE loss: 1.202395]  tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 861/1000] [D loss: 0.707250] [G loss: 0.371327] [FAKE loss: 1.184938]  tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 862/1000] [D loss: 0.698450] [G loss: 0.379097] [FAKE loss: 1.163951]  tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 863/1000] [D loss: 0.692557] [G loss: 0.387497] [FAKE loss: 1.149608]  tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 864/1000] [D loss: 0.686405] [G loss: 0.393999] [FAKE loss: 1.133624]  tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 865/1000] [D loss: 0.678357] [G loss: 0.402276] [FAKE loss: 1.116183]  tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 866/1000] [D loss: 0.673723] [G loss: 0.410145] [FAKE loss: 1.102129]  tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 867/1000] [D loss: 0.667790] [G loss: 0.417554] [FAKE loss: 1.087964]  tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 868/1000] [D loss: 0.659737] [G loss: 0.427530] [FAKE loss: 1.068239]  tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 869/1000] [D loss: 0.655123] [G loss: 0.434197] [FAKE loss: 1.056705]  tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 870/1000] [D loss: 0.649505] [G loss: 0.443265] [FAKE loss: 1.041882]  tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 871/1000] [D loss: 0.643315] [G loss: 0.450563] [FAKE loss: 1.025893]  tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 872/1000] [D loss: 0.638715] [G loss: 0.459487] [FAKE loss: 1.012559]  tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 873/1000] [D loss: 0.634118] [G loss: 0.468524] [FAKE loss: 1.001042]  tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 874/1000] [D loss: 0.628760] [G loss: 0.474695] [FAKE loss: 0.986977]  tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 875/1000] [D loss: 0.623507] [G loss: 0.483552] [FAKE loss: 0.972731]  tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 876/1000] [D loss: 0.620941] [G loss: 0.492135] [FAKE loss: 0.963548]  tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 877/1000] [D loss: 0.615281] [G loss: 0.499752] [FAKE loss: 0.950303]  tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 878/1000] [D loss: 0.610202] [G loss: 0.507854] [FAKE loss: 0.937741]  tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 879/1000] [D loss: 0.607707] [G loss: 0.515042] [FAKE loss: 0.929632]  tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 880/1000] [D loss: 0.602047] [G loss: 0.527161] [FAKE loss: 0.916173]  tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 881/1000] [D loss: 0.599226] [G loss: 0.533540] [FAKE loss: 0.906725]  tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 882/1000] [D loss: 0.596349] [G loss: 0.542201] [FAKE loss: 0.899062]  tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 883/1000] [D loss: 0.591998] [G loss: 0.549571] [FAKE loss: 0.886962]  tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 884/1000] [D loss: 0.591036] [G loss: 0.557367] [FAKE loss: 0.883859]  tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 885/1000] [D loss: 0.587576] [G loss: 0.564163] [FAKE loss: 0.874401]  tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 886/1000] [D loss: 0.583176] [G loss: 0.572689] [FAKE loss: 0.862632]  tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 887/1000] [D loss: 0.580251] [G loss: 0.581214] [FAKE loss: 0.855090]  tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 888/1000] [D loss: 0.577707] [G loss: 0.588646] [FAKE loss: 0.849304]  tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 889/1000] [D loss: 0.572715] [G loss: 0.594051] [FAKE loss: 0.838124]  tensor(0.5585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 890/1000] [D loss: 0.570698] [G loss: 0.599959] [FAKE loss: 0.833828]  tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 891/1000] [D loss: 0.570754] [G loss: 0.605003] [FAKE loss: 0.830778]  tensor(0.5522, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 892/1000] [D loss: 0.568910] [G loss: 0.609198] [FAKE loss: 0.826840]  tensor(0.5499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 893/1000] [D loss: 0.567919] [G loss: 0.616283] [FAKE loss: 0.824505]  tensor(0.5485, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 894/1000] [D loss: 0.565691] [G loss: 0.619931] [FAKE loss: 0.820449]  tensor(0.5465, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 895/1000] [D loss: 0.565640] [G loss: 0.621362] [FAKE loss: 0.820840]  tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 896/1000] [D loss: 0.565963] [G loss: 0.622817] [FAKE loss: 0.820421]  tensor(0.5455, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 897/1000] [D loss: 0.565224] [G loss: 0.623674] [FAKE loss: 0.821717]  tensor(0.5442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 898/1000] [D loss: 0.564837] [G loss: 0.626691] [FAKE loss: 0.821719]  tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 899/1000] [D loss: 0.562441] [G loss: 0.623809] [FAKE loss: 0.818649]  tensor(0.5418, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 900/1000] [D loss: 0.563336] [G loss: 0.620407] [FAKE loss: 0.822002]  tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 901/1000] [D loss: 0.564423] [G loss: 0.620321] [FAKE loss: 0.825951]  tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 902/1000] [D loss: 0.566096] [G loss: 0.618023] [FAKE loss: 0.832371]  tensor(0.5479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 903/1000] [D loss: 0.567129] [G loss: 0.610774] [FAKE loss: 0.837378]  tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 904/1000] [D loss: 0.571087] [G loss: 0.609011] [FAKE loss: 0.847267]  tensor(0.5545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 905/1000] [D loss: 0.571303] [G loss: 0.603844] [FAKE loss: 0.850906]  tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 906/1000] [D loss: 0.572198] [G loss: 0.593932] [FAKE loss: 0.857648]  tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 907/1000] [D loss: 0.576095] [G loss: 0.589167] [FAKE loss: 0.870063]  tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 908/1000] [D loss: 0.581325] [G loss: 0.575386] [FAKE loss: 0.885327]  tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 909/1000] [D loss: 0.588040] [G loss: 0.566422] [FAKE loss: 0.902193]  tensor(0.5753, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 910/1000] [D loss: 0.590953] [G loss: 0.553016] [FAKE loss: 0.913089]  tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 911/1000] [D loss: 0.599010] [G loss: 0.543186] [FAKE loss: 0.934854]  tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 912/1000] [D loss: 0.603923] [G loss: 0.530249] [FAKE loss: 0.950016]  tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 913/1000] [D loss: 0.611774] [G loss: 0.518720] [FAKE loss: 0.970489]  tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 914/1000] [D loss: 0.619304] [G loss: 0.503440] [FAKE loss: 0.992940]  tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 915/1000] [D loss: 0.626688] [G loss: 0.486852] [FAKE loss: 1.013312]  tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 916/1000] [D loss: 0.642138] [G loss: 0.473204] [FAKE loss: 1.048313]  tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 917/1000] [D loss: 0.645078] [G loss: 0.460539] [FAKE loss: 1.061445]  tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 918/1000] [D loss: 0.655707] [G loss: 0.441621] [FAKE loss: 1.088328]  tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 919/1000] [D loss: 0.668916] [G loss: 0.424885] [FAKE loss: 1.120880]  tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 920/1000] [D loss: 0.681020] [G loss: 0.411226] [FAKE loss: 1.151174]  tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 921/1000] [D loss: 0.691474] [G loss: 0.396048] [FAKE loss: 1.178225]  tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 922/1000] [D loss: 0.703282] [G loss: 0.382182] [FAKE loss: 1.207729]  tensor(0.6865, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 923/1000] [D loss: 0.719664] [G loss: 0.367491] [FAKE loss: 1.247139]  tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 924/1000] [D loss: 0.732007] [G loss: 0.352859] [FAKE loss: 1.277590]  tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 925/1000] [D loss: 0.748492] [G loss: 0.337457] [FAKE loss: 1.317995]  tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 926/1000] [D loss: 0.766399] [G loss: 0.322337] [FAKE loss: 1.358472]  tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 927/1000] [D loss: 0.777236] [G loss: 0.311125] [FAKE loss: 1.387652]  tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 928/1000] [D loss: 0.797243] [G loss: 0.294247] [FAKE loss: 1.431559]  tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 929/1000] [D loss: 0.814312] [G loss: 0.283595] [FAKE loss: 1.472096]  tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 930/1000] [D loss: 0.833065] [G loss: 0.269704] [FAKE loss: 1.515769]  tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 931/1000] [D loss: 0.844525] [G loss: 0.258190] [FAKE loss: 1.544080]  tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 932/1000] [D loss: 0.865041] [G loss: 0.246574] [FAKE loss: 1.590436]  tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 933/1000] [D loss: 0.883524] [G loss: 0.235317] [FAKE loss: 1.630520]  tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 934/1000] [D loss: 0.903176] [G loss: 0.225152] [FAKE loss: 1.675820]  tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 935/1000] [D loss: 0.919679] [G loss: 0.215160] [FAKE loss: 1.713097]  tensor(0.8081, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 936/1000] [D loss: 0.942048] [G loss: 0.205386] [FAKE loss: 1.763816]  tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 937/1000] [D loss: 0.960040] [G loss: 0.197373] [FAKE loss: 1.803658]  tensor(0.8243, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 938/1000] [D loss: 0.979638] [G loss: 0.187129] [FAKE loss: 1.845835]  tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 939/1000] [D loss: 0.998103] [G loss: 0.179011] [FAKE loss: 1.887953]  tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 940/1000] [D loss: 1.023539] [G loss: 0.171515] [FAKE loss: 1.942368]  tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 941/1000] [D loss: 1.035820] [G loss: 0.163332] [FAKE loss: 1.969737]  tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 942/1000] [D loss: 1.054497] [G loss: 0.156193] [FAKE loss: 2.011184]  tensor(0.8564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 943/1000] [D loss: 1.077179] [G loss: 0.150048] [FAKE loss: 2.059220]  tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 944/1000] [D loss: 1.096675] [G loss: 0.143918] [FAKE loss: 2.101514]  tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 945/1000] [D loss: 1.115924] [G loss: 0.138333] [FAKE loss: 2.142750]  tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 946/1000] [D loss: 1.130344] [G loss: 0.131990] [FAKE loss: 2.175349]  tensor(0.8771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 947/1000] [D loss: 1.150436] [G loss: 0.127748] [FAKE loss: 2.217905]  tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 948/1000] [D loss: 1.162980] [G loss: 0.123271] [FAKE loss: 2.245453]  tensor(0.8848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 949/1000] [D loss: 1.181376] [G loss: 0.117347] [FAKE loss: 2.284653]  tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 950/1000] [D loss: 1.199340] [G loss: 0.115077] [FAKE loss: 2.323044]  tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 951/1000] [D loss: 1.213493] [G loss: 0.110265] [FAKE loss: 2.352812]  tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 952/1000] [D loss: 1.229577] [G loss: 0.106953] [FAKE loss: 2.386823]  tensor(0.8992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 953/1000] [D loss: 1.241097] [G loss: 0.103669] [FAKE loss: 2.411662]  tensor(0.9016, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 954/1000] [D loss: 1.258222] [G loss: 0.100864] [FAKE loss: 2.447697]  tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 955/1000] [D loss: 1.270269] [G loss: 0.098070] [FAKE loss: 2.471833]  tensor(0.9073, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 956/1000] [D loss: 1.284789] [G loss: 0.095852] [FAKE loss: 2.502817]  tensor(0.9094, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 957/1000] [D loss: 1.292503] [G loss: 0.094216] [FAKE loss: 2.519305]  tensor(0.9113, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 958/1000] [D loss: 1.305838] [G loss: 0.091184] [FAKE loss: 2.548678]  tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 959/1000] [D loss: 1.312984] [G loss: 0.090925] [FAKE loss: 2.562851]  tensor(0.9146, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 960/1000] [D loss: 1.326222] [G loss: 0.088241] [FAKE loss: 2.589726]  tensor(0.9166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 961/1000] [D loss: 1.327894] [G loss: 0.087042] [FAKE loss: 2.594419]  tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 962/1000] [D loss: 1.335557] [G loss: 0.085635] [FAKE loss: 2.610150]  tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 963/1000] [D loss: 1.341024] [G loss: 0.084629] [FAKE loss: 2.621918]  tensor(0.9191, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 964/1000] [D loss: 1.344367] [G loss: 0.084505] [FAKE loss: 2.628358]  tensor(0.9201, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 965/1000] [D loss: 1.344642] [G loss: 0.084159] [FAKE loss: 2.629481]  tensor(0.9213, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 966/1000] [D loss: 1.351908] [G loss: 0.084114] [FAKE loss: 2.644196]  tensor(0.9206, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 967/1000] [D loss: 1.350116] [G loss: 0.083226] [FAKE loss: 2.640219]  tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 968/1000] [D loss: 1.355353] [G loss: 0.082656] [FAKE loss: 2.651066]  tensor(0.9210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 969/1000] [D loss: 1.355539] [G loss: 0.083024] [FAKE loss: 2.649827]  tensor(0.9214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 970/1000] [D loss: 1.350307] [G loss: 0.083093] [FAKE loss: 2.639651]  tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 971/1000] [D loss: 1.349008] [G loss: 0.084384] [FAKE loss: 2.636326]  tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 972/1000] [D loss: 1.340036] [G loss: 0.084179] [FAKE loss: 2.617682]  tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 973/1000] [D loss: 1.333389] [G loss: 0.085075] [FAKE loss: 2.603696]  tensor(0.9178, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 974/1000] [D loss: 1.331539] [G loss: 0.087434] [FAKE loss: 2.599223]  tensor(0.9179, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 975/1000] [D loss: 1.323263] [G loss: 0.088168] [FAKE loss: 2.582185]  tensor(0.9163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 976/1000] [D loss: 1.313386] [G loss: 0.089470] [FAKE loss: 2.560096]  tensor(0.9148, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 977/1000] [D loss: 1.306388] [G loss: 0.091448] [FAKE loss: 2.544962]  tensor(0.9132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 978/1000] [D loss: 1.292908] [G loss: 0.093065] [FAKE loss: 2.516174]  tensor(0.9116, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 979/1000] [D loss: 1.280887] [G loss: 0.095541] [FAKE loss: 2.489964]  tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 980/1000] [D loss: 1.270779] [G loss: 0.097651] [FAKE loss: 2.468374]  tensor(0.9077, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 981/1000] [D loss: 1.262621] [G loss: 0.100134] [FAKE loss: 2.449489]  tensor(0.9045, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 982/1000] [D loss: 1.250505] [G loss: 0.103179] [FAKE loss: 2.423711]  tensor(0.9032, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 983/1000] [D loss: 1.229309] [G loss: 0.106611] [FAKE loss: 2.378704]  tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 984/1000] [D loss: 1.217193] [G loss: 0.109789] [FAKE loss: 2.351285]  tensor(0.8962, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 985/1000] [D loss: 1.203915] [G loss: 0.113661] [FAKE loss: 2.322356]  tensor(0.8937, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 986/1000] [D loss: 1.188561] [G loss: 0.118549] [FAKE loss: 2.288255]  tensor(0.8906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 987/1000] [D loss: 1.168707] [G loss: 0.122070] [FAKE loss: 2.244565]  tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 988/1000] [D loss: 1.152013] [G loss: 0.126630] [FAKE loss: 2.208237]  tensor(0.8813, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 989/1000] [D loss: 1.137206] [G loss: 0.131508] [FAKE loss: 2.175003]  tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 990/1000] [D loss: 1.120426] [G loss: 0.136283] [FAKE loss: 2.137195]  tensor(0.8726, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 991/1000] [D loss: 1.103661] [G loss: 0.142085] [FAKE loss: 2.099536]  tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 992/1000] [D loss: 1.088976] [G loss: 0.147606] [FAKE loss: 2.064959]  tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 993/1000] [D loss: 1.071167] [G loss: 0.154133] [FAKE loss: 2.023861]  tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 994/1000] [D loss: 1.055457] [G loss: 0.161493] [FAKE loss: 1.987651]  tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 995/1000] [D loss: 1.037858] [G loss: 0.166089] [FAKE loss: 1.946883]  tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 996/1000] [D loss: 1.018296] [G loss: 0.173356] [FAKE loss: 1.901853]  tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 997/1000] [D loss: 1.003706] [G loss: 0.182161] [FAKE loss: 1.864605]  tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 998/1000] [D loss: 0.985201] [G loss: 0.190077] [FAKE loss: 1.821527]  tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "[Epoch 999/1000] [D loss: 0.967578] [G loss: 0.197818] [FAKE loss: 1.779824]  tensor(0.8217, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdata[990][15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VNqEGGHTf2g",
        "outputId": "3fb8da3c-d5f6-4258-f6c4-64c0add3cf7a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2945, 0.7935, 0.9653, 0.8000, 0.7990, 0.0668, 0.0890, 0.1531, 0.0122])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newday0[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydcAhZJ6jNl2",
        "outputId": "8eebd577-89bd-4a49-ce8c-66df5242dd3f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.65217391, 0.72686896, 0.92376881, 0.39502165, 0.45635057,\n",
              "       0.09213187, 0.15212658, 0.09833333, 0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}