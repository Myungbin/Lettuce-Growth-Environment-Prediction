{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'EPOCHS':500,\n",
    "    'LEARNING_RATE':1e-3,\n",
    "    'BATCH_SIZE':128,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_list = sorted(glob.glob('./data/train_input/*.csv'))\n",
    "all_target_list = sorted(glob.glob('./data/train_target/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a99a2ef1-ba9d-45b1-9581-0bcc82e96b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_list = all_input_list[:25]\n",
    "train_target_list = all_target_list[:25]\n",
    "\n",
    "val_input_list = all_input_list[25:]\n",
    "val_target_list = all_target_list[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5fc30a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('lstm_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ca0edaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = train.drop(['obs_time', 'predicted_weight_g'], axis=1)\n",
    "target_df = train['predicted_weight_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "82f08e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('lstm_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_paths, target_paths, infer_mode, train=True):\n",
    "        self.input_paths = input_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.infer_mode = infer_mode\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.label_list = []\n",
    "        print('Data Pre-processing..')\n",
    "        if train:    \n",
    "            for idx in range(728):\n",
    "                time_series = input_df[24*idx:24*(idx+1)].values\n",
    "                target_value = target_df[24*idx:24*(idx+1)].values.mean()\n",
    "                self.data_list.append(torch.Tensor(time_series))\n",
    "                self.label_list.append(torch.from_numpy(np.array(target_value)))\n",
    "        else:            \n",
    "            for idx in range(728, 782):\n",
    "                time_series = input_df[24*idx:24*(idx+1)].values\n",
    "                target_value = target_df[24*idx:24*(idx+1)].values.mean()\n",
    "                self.data_list.append(torch.Tensor(time_series))\n",
    "                self.label_list.append(torch.from_numpy(np.array(target_value)))    \n",
    "        print('Done.')\n",
    "                      \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        if self.infer_mode == False:\n",
    "            return data, label\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-processing..\n",
      "Done.\n",
      "Data Pre-processing..\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_input_list, train_target_list, False, True)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "val_dataset = CustomDataset(val_input_list, val_target_list, False, False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f5e16e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BaseModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BaseModel, self).__init__()\n",
    "#         self.lstm = nn.LSTM(input_size=35, hidden_size=256, batch_first=True, bidirectional=False)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(256, 1),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         hidden, _ = self.lstm(x)\n",
    "#         output = self.classifier(hidden[:,-1,:])\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "60f5b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_LSTM(nn.Module):\n",
    "    def __init__(self, in_channel=35, out_channel=1):\n",
    "        super(Conv1d_LSTM, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv1d(in_channel, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv1d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv1d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv1d(32, 16, kernel_size=4, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=16,\n",
    "                    hidden_size=64,\n",
    "                    num_layers=1,\n",
    "                    bias=True,\n",
    "                    bidirectional=False,\n",
    "                    batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(64, 32)\n",
    "        self.regressor = nn.Linear(32, out_channel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        # print(f'input_shape: {x.shape}')\n",
    "        # (Batch, 3, 128, 128)\n",
    "        x = self.layer1(x)\n",
    "        # print(f'layer1_shape: {x.shape}')\n",
    "        # (Batch, 8, 64, 64)\n",
    "        x = self.layer2(x)\n",
    "        # print(f'layer2_shape: {x.shape}')\n",
    "        # (Batch, 16, 32, 32)\n",
    "        x = self.layer3(x)\n",
    "        # print(f'layer3_shape: {x.shape}')\n",
    "        # (Batch, 32, 16, 16)\n",
    "        x = self.layer4(x)\n",
    "        # print(f'layer4_shape: {x.shape}')\n",
    "        # (Batch, 64, 7, 7) -> Flatten (Batch, 64*7*7(=3136))\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # print(f'flatten_shape: {x.shape}')\n",
    "        # Regressor (Batch, 3136) -> (Batch, 1)\n",
    "        self.lstm.flatten_parameters()\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        x = hidden[-1]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        out = self.regressor(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "57a3b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for X, Y in iter(val_loader):\n",
    "            X = X.float().to(device)\n",
    "            Y = Y.float().to(device)\n",
    "            \n",
    "            model_pred = model(X)\n",
    "            loss = criterion(model_pred, Y)\n",
    "            # print(f'True: {Y}, \\n prediction: {model_pred}')\n",
    "            # print(f'validation X: {X}, \\n shape: {X.shape}')\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.L1Loss().to(device)\n",
    "    \n",
    "    best_loss = 9999\n",
    "    best_model = None\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for X, Y in iter(train_loader):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(X)\n",
    "            loss = criterion(output, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        val_loss = validation(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f'Train Loss : [{np.mean(train_loss):.5f}] Valid Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
   "metadata": {},
   "source": [
    "## Run!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "86142d9a-68b7-4d04-8423-49d28025411d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : [35.49249] Valid Loss : [21.55723]\n",
      "Train Loss : [35.07952] Valid Loss : [21.13371]\n",
      "Train Loss : [34.68534] Valid Loss : [20.65334]\n",
      "Train Loss : [34.25642] Valid Loss : [20.27967]\n",
      "Train Loss : [34.12166] Valid Loss : [20.02550]\n",
      "Train Loss : [33.67040] Valid Loss : [19.31536]\n",
      "Train Loss : [33.21599] Valid Loss : [18.83912]\n",
      "Train Loss : [32.85073] Valid Loss : [18.33767]\n",
      "Train Loss : [32.52983] Valid Loss : [17.71935]\n",
      "Train Loss : [32.15223] Valid Loss : [17.64507]\n",
      "Train Loss : [31.68595] Valid Loss : [17.26768]\n",
      "Train Loss : [31.31356] Valid Loss : [17.02126]\n",
      "Train Loss : [31.20458] Valid Loss : [17.56978]\n",
      "Train Loss : [31.42249] Valid Loss : [17.41329]\n",
      "Train Loss : [31.31740] Valid Loss : [17.81461]\n",
      "Train Loss : [31.41338] Valid Loss : [17.12337]\n",
      "Train Loss : [30.90468] Valid Loss : [16.81198]\n",
      "Train Loss : [30.52727] Valid Loss : [16.70567]\n",
      "Train Loss : [30.25870] Valid Loss : [16.65165]\n",
      "Train Loss : [30.07626] Valid Loss : [16.64083]\n",
      "Train Loss : [29.91866] Valid Loss : [16.80886]\n",
      "Train Loss : [29.92536] Valid Loss : [16.73855]\n",
      "Train Loss : [29.96209] Valid Loss : [16.79639]\n",
      "Train Loss : [29.89679] Valid Loss : [16.88743]\n",
      "Train Loss : [29.91922] Valid Loss : [16.85781]\n",
      "Train Loss : [29.90978] Valid Loss : [17.02337]\n",
      "Train Loss : [29.78766] Valid Loss : [17.04817]\n",
      "Train Loss : [29.96686] Valid Loss : [17.18301]\n",
      "Train Loss : [30.01889] Valid Loss : [16.79541]\n",
      "Train Loss : [30.13047] Valid Loss : [16.65722]\n",
      "Train Loss : [30.31551] Valid Loss : [16.66000]\n",
      "Train Loss : [30.24730] Valid Loss : [16.66243]\n",
      "Train Loss : [30.17606] Valid Loss : [16.66495]\n",
      "Train Loss : [30.21040] Valid Loss : [16.66747]\n",
      "Train Loss : [30.13814] Valid Loss : [16.67137]\n",
      "Train Loss : [30.19288] Valid Loss : [16.67472]\n",
      "Train Loss : [30.15911] Valid Loss : [16.69100]\n",
      "Train Loss : [30.16423] Valid Loss : [16.69664]\n",
      "Train Loss : [30.09521] Valid Loss : [16.69842]\n",
      "Train Loss : [30.17945] Valid Loss : [16.70114]\n",
      "Train Loss : [30.11102] Valid Loss : [16.70456]\n",
      "Train Loss : [30.10791] Valid Loss : [16.70841]\n",
      "Train Loss : [30.10518] Valid Loss : [16.70851]\n",
      "Train Loss : [30.10021] Valid Loss : [16.70893]\n",
      "Train Loss : [30.11405] Valid Loss : [16.70903]\n",
      "Train Loss : [30.07806] Valid Loss : [16.70932]\n",
      "Train Loss : [30.09182] Valid Loss : [16.70974]\n",
      "Train Loss : [30.13410] Valid Loss : [16.70979]\n",
      "Train Loss : [30.13201] Valid Loss : [16.71029]\n",
      "Train Loss : [30.16040] Valid Loss : [16.71080]\n",
      "Train Loss : [30.04891] Valid Loss : [16.71126]\n",
      "Train Loss : [30.09398] Valid Loss : [16.71167]\n",
      "Train Loss : [30.07636] Valid Loss : [16.71211]\n",
      "Train Loss : [30.10995] Valid Loss : [16.71215]\n",
      "Train Loss : [30.12375] Valid Loss : [16.71220]\n",
      "Train Loss : [30.18243] Valid Loss : [16.71224]\n",
      "Train Loss : [30.12694] Valid Loss : [16.71228]\n",
      "Train Loss : [30.07194] Valid Loss : [16.71231]\n",
      "Train Loss : [30.13270] Valid Loss : [16.71235]\n",
      "Train Loss : [30.13321] Valid Loss : [16.71240]\n",
      "Train Loss : [30.12015] Valid Loss : [16.71244]\n",
      "Train Loss : [30.10206] Valid Loss : [16.71248]\n",
      "Train Loss : [30.16550] Valid Loss : [16.71252]\n",
      "Train Loss : [30.08691] Valid Loss : [16.71256]\n",
      "Train Loss : [30.06112] Valid Loss : [16.71256]\n",
      "Train Loss : [30.09441] Valid Loss : [16.71257]\n",
      "Train Loss : [30.11729] Valid Loss : [16.71257]\n",
      "Train Loss : [30.08004] Valid Loss : [16.71258]\n",
      "Train Loss : [30.17428] Valid Loss : [16.71258]\n",
      "Train Loss : [30.08213] Valid Loss : [16.71259]\n",
      "Train Loss : [30.06154] Valid Loss : [16.71259]\n",
      "Train Loss : [30.11042] Valid Loss : [16.71259]\n",
      "Train Loss : [30.10627] Valid Loss : [16.71259]\n",
      "Train Loss : [30.05386] Valid Loss : [16.71260]\n",
      "Train Loss : [30.08671] Valid Loss : [16.71260]\n",
      "Train Loss : [30.04419] Valid Loss : [16.71260]\n",
      "Train Loss : [30.09182] Valid Loss : [16.71260]\n",
      "Train Loss : [30.15788] Valid Loss : [16.71260]\n",
      "Train Loss : [30.08108] Valid Loss : [16.71260]\n",
      "Train Loss : [30.09856] Valid Loss : [16.71260]\n",
      "Train Loss : [30.09008] Valid Loss : [16.71260]\n",
      "Train Loss : [30.08594] Valid Loss : [16.71260]\n",
      "Train Loss : [30.13483] Valid Loss : [16.71261]\n",
      "Train Loss : [30.08075] Valid Loss : [16.71261]\n",
      "Train Loss : [30.15510] Valid Loss : [16.71261]\n",
      "Train Loss : [30.07713] Valid Loss : [16.71261]\n",
      "Train Loss : [30.07828] Valid Loss : [16.71261]\n",
      "Train Loss : [30.04972] Valid Loss : [16.71261]\n",
      "Train Loss : [30.14800] Valid Loss : [16.71261]\n",
      "Train Loss : [30.18932] Valid Loss : [16.71261]\n",
      "Train Loss : [30.07087] Valid Loss : [16.71261]\n",
      "Train Loss : [30.11230] Valid Loss : [16.71261]\n",
      "Train Loss : [30.15331] Valid Loss : [16.71261]\n",
      "Train Loss : [30.13868] Valid Loss : [16.71261]\n",
      "Train Loss : [30.11963] Valid Loss : [16.71261]\n",
      "Train Loss : [30.08742] Valid Loss : [16.71261]\n",
      "Train Loss : [30.08043] Valid Loss : [16.71261]\n",
      "Train Loss : [30.12298] Valid Loss : [16.71261]\n",
      "Train Loss : [30.07569] Valid Loss : [16.71261]\n",
      "Train Loss : [30.15369] Valid Loss : [16.71261]\n",
      "Train Loss : [30.09568] Valid Loss : [16.71261]\n",
      "Train Loss : [30.03588] Valid Loss : [16.71261]\n",
      "Train Loss : [30.16830] Valid Loss : [16.71261]\n",
      "Train Loss : [30.07487] Valid Loss : [16.71261]\n",
      "Train Loss : [30.05217] Valid Loss : [16.71261]\n",
      "Train Loss : [30.11539] Valid Loss : [16.71261]\n",
      "Train Loss : [30.09159] Valid Loss : [16.71261]\n",
      "Train Loss : [30.03310] Valid Loss : [16.71261]\n",
      "Train Loss : [30.15877] Valid Loss : [16.71261]\n",
      "Train Loss : [30.14730] Valid Loss : [16.71261]\n",
      "Train Loss : [30.10011] Valid Loss : [16.71261]\n",
      "Train Loss : [30.16889] Valid Loss : [16.71261]\n",
      "Train Loss : [30.14798] Valid Loss : [16.71261]\n",
      "Train Loss : [30.10912] Valid Loss : [16.71261]\n",
      "Train Loss : [30.06483] Valid Loss : [16.71261]\n",
      "Train Loss : [30.12688] Valid Loss : [16.71261]\n",
      "Train Loss : [30.12276] Valid Loss : [16.71261]\n",
      "Train Loss : [30.11948] Valid Loss : [16.71261]\n",
      "Train Loss : [30.12124] Valid Loss : [16.71261]\n",
      "Train Loss : [30.15477] Valid Loss : [16.71261]\n",
      "Train Loss : [30.02131] Valid Loss : [16.71261]\n",
      "Train Loss : [30.08155] Valid Loss : [16.71261]\n",
      "Train Loss : [30.12497] Valid Loss : [16.71261]\n",
      "Train Loss : [30.11035] Valid Loss : [16.71261]\n",
      "Train Loss : [30.11660] Valid Loss : [16.71262]\n",
      "Train Loss : [30.08112] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11999] Valid Loss : [16.71262]\n",
      "Train Loss : [30.12494] Valid Loss : [16.71262]\n",
      "Train Loss : [30.15393] Valid Loss : [16.71262]\n",
      "Train Loss : [30.12439] Valid Loss : [16.71262]\n",
      "Train Loss : [30.15907] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11659] Valid Loss : [16.71262]\n",
      "Train Loss : [30.13614] Valid Loss : [16.71262]\n",
      "Train Loss : [30.10097] Valid Loss : [16.71262]\n",
      "Train Loss : [30.10054] Valid Loss : [16.71262]\n",
      "Train Loss : [30.10118] Valid Loss : [16.71262]\n",
      "Train Loss : [30.10726] Valid Loss : [16.71262]\n",
      "Train Loss : [30.08109] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11858] Valid Loss : [16.71262]\n",
      "Train Loss : [30.07404] Valid Loss : [16.71262]\n",
      "Train Loss : [30.08867] Valid Loss : [16.71262]\n",
      "Train Loss : [30.14414] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11503] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11979] Valid Loss : [16.71262]\n",
      "Train Loss : [30.16352] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11987] Valid Loss : [16.71262]\n",
      "Train Loss : [30.14466] Valid Loss : [16.71262]\n",
      "Train Loss : [30.06382] Valid Loss : [16.71262]\n",
      "Train Loss : [30.13187] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11584] Valid Loss : [16.71262]\n",
      "Train Loss : [30.05821] Valid Loss : [16.71262]\n",
      "Train Loss : [30.09457] Valid Loss : [16.71262]\n",
      "Train Loss : [30.15358] Valid Loss : [16.71262]\n",
      "Train Loss : [30.14901] Valid Loss : [16.71262]\n",
      "Train Loss : [30.09146] Valid Loss : [16.71262]\n",
      "Train Loss : [30.07801] Valid Loss : [16.71262]\n",
      "Train Loss : [30.08386] Valid Loss : [16.71262]\n",
      "Train Loss : [30.13688] Valid Loss : [16.71262]\n",
      "Train Loss : [30.10679] Valid Loss : [16.71262]\n",
      "Train Loss : [30.11395] Valid Loss : [16.71262]\n",
      "Train Loss : [30.13098] Valid Loss : [16.71262]\n",
      "Train Loss : [30.15190] Valid Loss : [16.71262]\n",
      "Train Loss : [30.14048] Valid Loss : [16.71262]\n",
      "Train Loss : [30.07695] Valid Loss : [16.71262]\n",
      "Train Loss : [30.07920] Valid Loss : [16.71262]\n",
      "Train Loss : [30.08885] Valid Loss : [16.71262]\n",
      "Train Loss : [30.14065] Valid Loss : [16.71262]\n",
      "Train Loss : [30.06403] Valid Loss : [16.71262]\n",
      "Train Loss : [30.13695] Valid Loss : [16.71263]\n",
      "Train Loss : [30.08719] Valid Loss : [16.71262]\n",
      "Train Loss : [30.08506] Valid Loss : [16.71263]\n",
      "Train Loss : [30.08390] Valid Loss : [16.71262]\n",
      "Train Loss : [30.16765] Valid Loss : [16.71263]\n",
      "Train Loss : [30.09458] Valid Loss : [16.71263]\n",
      "Train Loss : [30.08205] Valid Loss : [16.71263]\n",
      "Train Loss : [30.09609] Valid Loss : [16.71263]\n",
      "Train Loss : [30.07941] Valid Loss : [16.71263]\n",
      "Train Loss : [30.08415] Valid Loss : [16.71263]\n",
      "Train Loss : [30.15028] Valid Loss : [16.71263]\n",
      "Train Loss : [30.08492] Valid Loss : [16.71263]\n",
      "Train Loss : [30.04191] Valid Loss : [16.71263]\n",
      "Train Loss : [30.14303] Valid Loss : [16.71263]\n",
      "Train Loss : [30.12455] Valid Loss : [16.71263]\n",
      "Train Loss : [30.10917] Valid Loss : [16.71263]\n",
      "Train Loss : [30.13430] Valid Loss : [16.71263]\n",
      "Train Loss : [30.06076] Valid Loss : [16.71263]\n",
      "Train Loss : [30.09068] Valid Loss : [16.71263]\n",
      "Train Loss : [30.17254] Valid Loss : [16.71263]\n",
      "Train Loss : [30.14740] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11008] Valid Loss : [16.71263]\n",
      "Train Loss : [30.15610] Valid Loss : [16.71263]\n",
      "Train Loss : [30.13199] Valid Loss : [16.71263]\n",
      "Train Loss : [30.10136] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11047] Valid Loss : [16.71263]\n",
      "Train Loss : [30.12218] Valid Loss : [16.71263]\n",
      "Train Loss : [30.14333] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11691] Valid Loss : [16.71263]\n",
      "Train Loss : [30.10223] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11681] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11413] Valid Loss : [16.71263]\n",
      "Train Loss : [30.10330] Valid Loss : [16.71263]\n",
      "Train Loss : [30.18338] Valid Loss : [16.71263]\n",
      "Train Loss : [30.14570] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11977] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11160] Valid Loss : [16.71263]\n",
      "Train Loss : [30.07965] Valid Loss : [16.71263]\n",
      "Train Loss : [30.07056] Valid Loss : [16.71263]\n",
      "Train Loss : [30.15486] Valid Loss : [16.71263]\n",
      "Train Loss : [30.14351] Valid Loss : [16.71263]\n",
      "Train Loss : [30.12941] Valid Loss : [16.71263]\n",
      "Train Loss : [30.10203] Valid Loss : [16.71263]\n",
      "Train Loss : [30.11837] Valid Loss : [16.71263]\n",
      "Train Loss : [30.06123] Valid Loss : [16.71263]\n",
      "Train Loss : [30.10170] Valid Loss : [16.71263]\n",
      "Train Loss : [30.07268] Valid Loss : [16.71263]\n",
      "Train Loss : [30.08951] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12349] Valid Loss : [16.71263]\n",
      "Train Loss : [30.19837] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12157] Valid Loss : [16.71264]\n",
      "Train Loss : [30.08006] Valid Loss : [16.71264]\n",
      "Train Loss : [30.09028] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11499] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12249] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11417] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10239] Valid Loss : [16.71264]\n",
      "Train Loss : [30.16803] Valid Loss : [16.71264]\n",
      "Train Loss : [30.16108] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11514] Valid Loss : [16.71264]\n",
      "Train Loss : [30.06843] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12542] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10131] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11901] Valid Loss : [16.71264]\n",
      "Train Loss : [30.08780] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10286] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11702] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12770] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10509] Valid Loss : [16.71264]\n",
      "Train Loss : [30.07522] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12747] Valid Loss : [16.71264]\n",
      "Train Loss : [30.14253] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12067] Valid Loss : [16.71264]\n",
      "Train Loss : [30.14069] Valid Loss : [16.71264]\n",
      "Train Loss : [30.13065] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11134] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12502] Valid Loss : [16.71264]\n",
      "Train Loss : [30.09355] Valid Loss : [16.71264]\n",
      "Train Loss : [30.08805] Valid Loss : [16.71264]\n",
      "Train Loss : [30.09984] Valid Loss : [16.71264]\n",
      "Train Loss : [30.07786] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10441] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10037] Valid Loss : [16.71264]\n",
      "Train Loss : [30.09771] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11792] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12304] Valid Loss : [16.71264]\n",
      "Train Loss : [30.15487] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10782] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11656] Valid Loss : [16.71264]\n",
      "Train Loss : [30.13011] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10262] Valid Loss : [16.71264]\n",
      "Train Loss : [30.09666] Valid Loss : [16.71264]\n",
      "Train Loss : [30.06482] Valid Loss : [16.71264]\n",
      "Train Loss : [30.18450] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12788] Valid Loss : [16.71264]\n",
      "Train Loss : [30.14517] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12479] Valid Loss : [16.71264]\n",
      "Train Loss : [30.14878] Valid Loss : [16.71264]\n",
      "Train Loss : [30.09796] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12778] Valid Loss : [16.71264]\n",
      "Train Loss : [30.11591] Valid Loss : [16.71264]\n",
      "Train Loss : [30.10418] Valid Loss : [16.71265]\n",
      "Train Loss : [30.13946] Valid Loss : [16.71264]\n",
      "Train Loss : [30.12877] Valid Loss : [16.71264]\n",
      "Train Loss : [30.07389] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11940] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09250] Valid Loss : [16.71265]\n",
      "Train Loss : [30.07115] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11311] Valid Loss : [16.71265]\n",
      "Train Loss : [30.07171] Valid Loss : [16.71265]\n",
      "Train Loss : [30.14539] Valid Loss : [16.71265]\n",
      "Train Loss : [30.10452] Valid Loss : [16.71265]\n",
      "Train Loss : [30.00986] Valid Loss : [16.71265]\n",
      "Train Loss : [30.17049] Valid Loss : [16.71265]\n",
      "Train Loss : [30.13822] Valid Loss : [16.71265]\n",
      "Train Loss : [30.06497] Valid Loss : [16.71265]\n",
      "Train Loss : [30.12537] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09451] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11222] Valid Loss : [16.71265]\n",
      "Train Loss : [30.10766] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11166] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09523] Valid Loss : [16.71265]\n",
      "Train Loss : [30.19144] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11678] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09255] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09187] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11810] Valid Loss : [16.71265]\n",
      "Train Loss : [30.10970] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11729] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09584] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09714] Valid Loss : [16.71265]\n",
      "Train Loss : [30.14381] Valid Loss : [16.71265]\n",
      "Train Loss : [30.07057] Valid Loss : [16.71265]\n",
      "Train Loss : [30.10317] Valid Loss : [16.71265]\n",
      "Train Loss : [30.11500] Valid Loss : [16.71265]\n",
      "Train Loss : [30.10771] Valid Loss : [16.71265]\n",
      "Train Loss : [30.08911] Valid Loss : [16.71265]\n",
      "Train Loss : [30.15721] Valid Loss : [16.71265]\n",
      "Train Loss : [30.12653] Valid Loss : [16.71265]\n",
      "Train Loss : [30.10949] Valid Loss : [16.71265]\n",
      "Train Loss : [30.09535] Valid Loss : [16.71265]\n",
      "Train Loss : [30.10762] Valid Loss : [16.71265]\n",
      "Train Loss : [30.17950] Valid Loss : [16.71265]\n",
      "Train Loss : [30.12415] Valid Loss : [16.71265]\n",
      "Train Loss : [30.17381] Valid Loss : [16.71265]\n",
      "Train Loss : [30.13019] Valid Loss : [16.71265]\n",
      "Train Loss : [30.13234] Valid Loss : [16.71265]\n",
      "Train Loss : [30.14331] Valid Loss : [16.71265]\n",
      "Train Loss : [30.08007] Valid Loss : [16.71265]\n",
      "Train Loss : [30.12128] Valid Loss : [16.71266]\n",
      "Train Loss : [30.09019] Valid Loss : [16.71266]\n",
      "Train Loss : [30.09353] Valid Loss : [16.71266]\n",
      "Train Loss : [30.09911] Valid Loss : [16.71266]\n",
      "Train Loss : [30.14452] Valid Loss : [16.71266]\n",
      "Train Loss : [30.13105] Valid Loss : [16.71266]\n",
      "Train Loss : [30.10780] Valid Loss : [16.71266]\n",
      "Train Loss : [30.11005] Valid Loss : [16.71266]\n",
      "Train Loss : [30.14455] Valid Loss : [16.71266]\n",
      "Train Loss : [30.12300] Valid Loss : [16.71266]\n",
      "Train Loss : [30.07443] Valid Loss : [16.71266]\n",
      "Train Loss : [30.12368] Valid Loss : [16.71266]\n",
      "Train Loss : [30.17085] Valid Loss : [16.71266]\n",
      "Train Loss : [30.11724] Valid Loss : [16.71266]\n",
      "Train Loss : [30.14298] Valid Loss : [16.71266]\n",
      "Train Loss : [30.13676] Valid Loss : [16.71266]\n",
      "Train Loss : [30.09180] Valid Loss : [16.71266]\n",
      "Train Loss : [30.15164] Valid Loss : [16.71266]\n",
      "Train Loss : [30.07022] Valid Loss : [16.71266]\n",
      "Train Loss : [30.10012] Valid Loss : [16.71266]\n",
      "Train Loss : [30.15824] Valid Loss : [16.71266]\n",
      "Train Loss : [30.13450] Valid Loss : [16.71266]\n",
      "Train Loss : [30.11268] Valid Loss : [16.71266]\n",
      "Train Loss : [30.15048] Valid Loss : [16.71266]\n",
      "Train Loss : [30.13679] Valid Loss : [16.71266]\n",
      "Train Loss : [30.18714] Valid Loss : [16.71266]\n",
      "Train Loss : [30.10114] Valid Loss : [16.71266]\n",
      "Train Loss : [30.15019] Valid Loss : [16.71266]\n",
      "Train Loss : [30.09948] Valid Loss : [16.71266]\n",
      "Train Loss : [30.06714] Valid Loss : [16.71266]\n",
      "Train Loss : [30.18565] Valid Loss : [16.71266]\n",
      "Train Loss : [30.07973] Valid Loss : [16.71266]\n",
      "Train Loss : [30.13263] Valid Loss : [16.71266]\n",
      "Train Loss : [30.11610] Valid Loss : [16.71266]\n",
      "Train Loss : [30.09165] Valid Loss : [16.71266]\n",
      "Train Loss : [30.09280] Valid Loss : [16.71266]\n",
      "Train Loss : [30.13442] Valid Loss : [16.71266]\n",
      "Train Loss : [30.11451] Valid Loss : [16.71266]\n",
      "Train Loss : [30.06452] Valid Loss : [16.71266]\n",
      "Train Loss : [30.08034] Valid Loss : [16.71266]\n",
      "Train Loss : [30.10257] Valid Loss : [16.71267]\n",
      "Train Loss : [30.07532] Valid Loss : [16.71267]\n",
      "Train Loss : [30.10751] Valid Loss : [16.71267]\n",
      "Train Loss : [30.07612] Valid Loss : [16.71267]\n",
      "Train Loss : [30.07874] Valid Loss : [16.71267]\n",
      "Train Loss : [30.13799] Valid Loss : [16.71267]\n",
      "Train Loss : [30.11503] Valid Loss : [16.71267]\n",
      "Train Loss : [30.09417] Valid Loss : [16.71267]\n",
      "Train Loss : [30.13227] Valid Loss : [16.71267]\n",
      "Train Loss : [30.07760] Valid Loss : [16.71267]\n",
      "Train Loss : [30.10498] Valid Loss : [16.71267]\n",
      "Train Loss : [30.09177] Valid Loss : [16.71267]\n",
      "Train Loss : [30.10909] Valid Loss : [16.71267]\n",
      "Train Loss : [30.14562] Valid Loss : [16.71267]\n",
      "Train Loss : [30.13478] Valid Loss : [16.71267]\n",
      "Train Loss : [30.06712] Valid Loss : [16.71267]\n",
      "Train Loss : [30.11180] Valid Loss : [16.71267]\n",
      "Train Loss : [30.12618] Valid Loss : [16.71267]\n",
      "Train Loss : [30.10642] Valid Loss : [16.71267]\n",
      "Train Loss : [30.11355] Valid Loss : [16.71267]\n",
      "Train Loss : [30.07987] Valid Loss : [16.71267]\n",
      "Train Loss : [30.10176] Valid Loss : [16.71267]\n",
      "Train Loss : [30.09896] Valid Loss : [16.71267]\n",
      "Train Loss : [30.09787] Valid Loss : [16.71267]\n",
      "Train Loss : [30.08571] Valid Loss : [16.71267]\n",
      "Train Loss : [30.07489] Valid Loss : [16.71267]\n",
      "Train Loss : [30.11919] Valid Loss : [16.71267]\n",
      "Train Loss : [30.09799] Valid Loss : [16.71267]\n",
      "Train Loss : [30.08605] Valid Loss : [16.71267]\n",
      "Train Loss : [30.18249] Valid Loss : [16.71267]\n",
      "Train Loss : [30.16197] Valid Loss : [16.71267]\n",
      "Train Loss : [30.10664] Valid Loss : [16.71267]\n",
      "Train Loss : [30.13372] Valid Loss : [16.71267]\n",
      "Train Loss : [30.12370] Valid Loss : [16.71267]\n",
      "Train Loss : [30.05437] Valid Loss : [16.71267]\n",
      "Train Loss : [30.12221] Valid Loss : [16.71267]\n",
      "Train Loss : [30.12263] Valid Loss : [16.71267]\n",
      "Train Loss : [30.15600] Valid Loss : [16.71267]\n",
      "Train Loss : [30.09562] Valid Loss : [16.71267]\n",
      "Train Loss : [30.15617] Valid Loss : [16.71267]\n",
      "Train Loss : [30.11999] Valid Loss : [16.71267]\n",
      "Train Loss : [30.06650] Valid Loss : [16.71267]\n",
      "Train Loss : [30.07959] Valid Loss : [16.71268]\n",
      "Train Loss : [30.13684] Valid Loss : [16.71268]\n",
      "Train Loss : [30.10826] Valid Loss : [16.71268]\n",
      "Train Loss : [30.11593] Valid Loss : [16.71268]\n",
      "Train Loss : [30.10527] Valid Loss : [16.71268]\n",
      "Train Loss : [30.11225] Valid Loss : [16.71268]\n",
      "Train Loss : [30.11916] Valid Loss : [16.71268]\n",
      "Train Loss : [30.15964] Valid Loss : [16.71268]\n",
      "Train Loss : [30.12821] Valid Loss : [16.71268]\n",
      "Train Loss : [30.16282] Valid Loss : [16.71268]\n",
      "Train Loss : [30.06436] Valid Loss : [16.71268]\n",
      "Train Loss : [30.09378] Valid Loss : [16.71268]\n",
      "Train Loss : [30.13247] Valid Loss : [16.71268]\n",
      "Train Loss : [30.11986] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08329] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08227] Valid Loss : [16.71268]\n",
      "Train Loss : [30.09706] Valid Loss : [16.71268]\n",
      "Train Loss : [30.04591] Valid Loss : [16.71268]\n",
      "Train Loss : [30.07599] Valid Loss : [16.71268]\n",
      "Train Loss : [30.07220] Valid Loss : [16.71268]\n",
      "Train Loss : [30.16177] Valid Loss : [16.71268]\n",
      "Train Loss : [30.16070] Valid Loss : [16.71268]\n",
      "Train Loss : [30.09428] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08777] Valid Loss : [16.71268]\n",
      "Train Loss : [30.14364] Valid Loss : [16.71268]\n",
      "Train Loss : [30.12438] Valid Loss : [16.71268]\n",
      "Train Loss : [30.15068] Valid Loss : [16.71268]\n",
      "Train Loss : [30.10226] Valid Loss : [16.71268]\n",
      "Train Loss : [30.15571] Valid Loss : [16.71268]\n",
      "Train Loss : [30.09133] Valid Loss : [16.71268]\n",
      "Train Loss : [30.14016] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08724] Valid Loss : [16.71268]\n",
      "Train Loss : [30.10255] Valid Loss : [16.71268]\n",
      "Train Loss : [30.10413] Valid Loss : [16.71268]\n",
      "Train Loss : [30.07394] Valid Loss : [16.71268]\n",
      "Train Loss : [30.10233] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08414] Valid Loss : [16.71268]\n",
      "Train Loss : [30.09408] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08589] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08601] Valid Loss : [16.71268]\n",
      "Train Loss : [30.08846] Valid Loss : [16.71268]\n",
      "Train Loss : [30.11950] Valid Loss : [16.71268]\n",
      "Train Loss : [30.10897] Valid Loss : [16.71268]\n",
      "Train Loss : [30.13640] Valid Loss : [16.71268]\n",
      "Train Loss : [30.17590] Valid Loss : [16.71268]\n",
      "Train Loss : [30.07524] Valid Loss : [16.71269]\n",
      "Train Loss : [30.13022] Valid Loss : [16.71268]\n",
      "Train Loss : [30.12319] Valid Loss : [16.71269]\n",
      "Train Loss : [30.05507] Valid Loss : [16.71269]\n",
      "Train Loss : [30.12534] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07007] Valid Loss : [16.71269]\n",
      "Train Loss : [30.08526] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07368] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07353] Valid Loss : [16.71269]\n",
      "Train Loss : [30.11070] Valid Loss : [16.71269]\n",
      "Train Loss : [30.06020] Valid Loss : [16.71269]\n",
      "Train Loss : [30.15993] Valid Loss : [16.71269]\n",
      "Train Loss : [30.13379] Valid Loss : [16.71269]\n",
      "Train Loss : [30.05880] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07767] Valid Loss : [16.71269]\n",
      "Train Loss : [30.08648] Valid Loss : [16.71269]\n",
      "Train Loss : [30.04579] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07031] Valid Loss : [16.71269]\n",
      "Train Loss : [30.12398] Valid Loss : [16.71269]\n",
      "Train Loss : [30.11593] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07418] Valid Loss : [16.71269]\n",
      "Train Loss : [30.06867] Valid Loss : [16.71269]\n",
      "Train Loss : [30.11995] Valid Loss : [16.71269]\n",
      "Train Loss : [30.10370] Valid Loss : [16.71269]\n",
      "Train Loss : [30.15513] Valid Loss : [16.71269]\n",
      "Train Loss : [30.16393] Valid Loss : [16.71269]\n",
      "Train Loss : [30.08195] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07430] Valid Loss : [16.71269]\n",
      "Train Loss : [30.13378] Valid Loss : [16.71269]\n",
      "Train Loss : [30.15405] Valid Loss : [16.71269]\n",
      "Train Loss : [30.15427] Valid Loss : [16.71269]\n",
      "Train Loss : [30.11093] Valid Loss : [16.71269]\n",
      "Train Loss : [30.09733] Valid Loss : [16.71269]\n",
      "Train Loss : [30.15698] Valid Loss : [16.71269]\n",
      "Train Loss : [30.13087] Valid Loss : [16.71269]\n",
      "Train Loss : [30.05631] Valid Loss : [16.71269]\n",
      "Train Loss : [30.12185] Valid Loss : [16.71269]\n",
      "Train Loss : [30.15130] Valid Loss : [16.71269]\n",
      "Train Loss : [30.13033] Valid Loss : [16.71269]\n",
      "Train Loss : [30.05738] Valid Loss : [16.71269]\n",
      "Train Loss : [30.10786] Valid Loss : [16.71269]\n",
      "Train Loss : [30.13001] Valid Loss : [16.71269]\n",
      "Train Loss : [30.12684] Valid Loss : [16.71269]\n",
      "Train Loss : [30.10629] Valid Loss : [16.71269]\n",
      "Train Loss : [30.07756] Valid Loss : [16.71269]\n",
      "Train Loss : [30.10047] Valid Loss : [16.71269]\n",
      "Train Loss : [30.04450] Valid Loss : [16.71269]\n",
      "Train Loss : [30.14289] Valid Loss : [16.71269]\n",
      "Train Loss : [30.14238] Valid Loss : [16.71269]\n",
      "Train Loss : [30.09599] Valid Loss : [16.71269]\n",
      "Train Loss : [30.03433] Valid Loss : [16.71269]\n",
      "Train Loss : [30.09439] Valid Loss : [16.71269]\n",
      "Train Loss : [30.09264] Valid Loss : [16.71269]\n",
      "Train Loss : [30.13032] Valid Loss : [16.71269]\n",
      "Train Loss : [30.14873] Valid Loss : [16.71269]\n",
      "Train Loss : [30.11656] Valid Loss : [16.71269]\n"
     ]
    }
   ],
   "source": [
    "model =  Conv1d_LSTM()\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold_mode='abs',min_lr=1e-3, verbose=True)\n",
    "\n",
    "best_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93c88c8-95f2-4eae-a9ff-c81becba0d97",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f46d7d60-38d7-44d6-82f2-836738b5a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_list = sorted(glob.glob('./data/test_input/*.csv'))\n",
    "test_target_list = sorted(glob.glob('./data/test_target/*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5071106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_test(Dataset):\n",
    "    def __init__(self, infer_mode):\n",
    "        self.infer_mode = infer_mode\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.val_list = []\n",
    "        self.label_list = []\n",
    "        print('Data Pre-processing..')\n",
    "\n",
    "\n",
    "        for idx in range(140):\n",
    "            time_series = input_df[24*idx:24*(idx+1)].values\n",
    "            target_value = target_df[24*idx:24*(idx+1)].values.mean()\n",
    "            self.data_list.append(torch.Tensor(time_series))\n",
    "            self.label_list.append(torch.from_numpy(np.array(target_value)))\n",
    "        print('Done.')\n",
    "                      \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        if self.infer_mode == False:\n",
    "            return data, label\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "95a48669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-processing..\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset_test(True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ad1defba-fdc0-4fe4-8c59-36d338851f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_per_case(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for X in iter(test_loader):\n",
    "            X = X.float().to(device)\n",
    "            \n",
    "            model_pred = model(X)\n",
    "            \n",
    "            model_pred = model_pred.cpu().numpy().reshape(-1).tolist()\n",
    "            \n",
    "            pred_list += model_pred\n",
    "    \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6f11cb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.920406341552734,\n",
       " 12.77182674407959,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 13.085265159606934,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 10.505683898925781,\n",
       " 13.074836730957031,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 12.967227935791016,\n",
       " 12.967721939086914,\n",
       " 12.967721939086914,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 12.967799186706543,\n",
       " 14.129780769348145,\n",
       " 13.001994132995605,\n",
       " 13.001994132995605,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 12.967227935791016,\n",
       " 13.255587577819824,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.995802879333496,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918,\n",
       " 12.99580192565918]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_per_case(best_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c88e68cb-dec1-439d-9363-03b817230bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-processing..\n",
      "Done.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "inference_per_case() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\mb_job\\project\\Competition\\Lettuce-Growth-Environment-Prediction\\[Baseline] Simple LSTM.ipynb 셀 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mb_job/project/Competition/Lettuce-Growth-Environment-Prediction/%5BBaseline%5D%20Simple%20LSTM.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m CustomDataset([test_input_path], [test_target_path], \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mb_job/project/Competition/Lettuce-Growth-Environment-Prediction/%5BBaseline%5D%20Simple%20LSTM.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size \u001b[39m=\u001b[39m CFG[\u001b[39m'\u001b[39m\u001b[39mBATCH_SIZE\u001b[39m\u001b[39m'\u001b[39m], shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/mb_job/project/Competition/Lettuce-Growth-Environment-Prediction/%5BBaseline%5D%20Simple%20LSTM.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m inference_per_case(best_model, test_loader, test_target_path, device)\n",
      "\u001b[1;31mTypeError\u001b[0m: inference_per_case() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "for test_input_path, test_target_path in zip(test_input_list, test_target_list):\n",
    "    test_dataset = CustomDataset([test_input_path], [test_target_path], True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False)\n",
    "    inference_per_case(best_model, test_loader, test_target_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae208a0-548d-4af6-9798-0e247543b301",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "173e281a-7a9f-4878-b406-4419698f7e0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다: './test_target/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\mb_job\\project\\Competition\\Lettuce-Growth-Environment-Prediction\\[Baseline] Simple LSTM.ipynb 셀 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mb_job/project/Competition/Lettuce-Growth-Environment-Prediction/%5BBaseline%5D%20Simple%20LSTM.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzipfile\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/mb_job/project/Competition/Lettuce-Growth-Environment-Prediction/%5BBaseline%5D%20Simple%20LSTM.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39;49mchdir(\u001b[39m\"\u001b[39;49m\u001b[39m./test_target/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mb_job/project/Competition/Lettuce-Growth-Environment-Prediction/%5BBaseline%5D%20Simple%20LSTM.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m submission \u001b[39m=\u001b[39m zipfile\u001b[39m.\u001b[39mZipFile(\u001b[39m\"\u001b[39m\u001b[39m../submission.zip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mb_job/project/Competition/Lettuce-Growth-Environment-Prediction/%5BBaseline%5D%20Simple%20LSTM.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m test_target_list:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다: './test_target/'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "os.chdir(\"./test_target/\")\n",
    "submission = zipfile.ZipFile(\"../submission.zip\", 'w')\n",
    "for path in test_target_list:\n",
    "    path = path.split('/')[-1]\n",
    "    submission.write(path)\n",
    "submission.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60bc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b081a66ee97bd2b6a16f43955f1d810b7ea816d6eaeb65e157ef9e038445f0c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
